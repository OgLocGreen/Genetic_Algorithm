{
  "0": {
    "0": {
      "name": 0,
      "learningrate": "0.0007250049888798299",
      "dropout": "0.2914063495370561",
      "epoch": "83.47882118397402",
      "batchsize": "38.514813159746325",
      "optimizer": "1.963319621719084",
      "acc": "0.8640185",
      "loss": "0.6322536056692953"
    },
    "1": {
      "name": 1,
      "learningrate": "0.0006915737929666093",
      "dropout": "0.35911721324611867",
      "epoch": "63.65825458529426",
      "batchsize": "50.92512127058096",
      "optimizer": "2.1535443538355805",
      "acc": "0.8608518",
      "loss": "0.527569300280677"
    },
    "2": {
      "name": 2,
      "learningrate": "0.000758372529329202",
      "dropout": "0.08150975199184304",
      "epoch": "78.94217101613044",
      "batchsize": "55.55001456144804",
      "optimizer": "0.004232503709828528",
      "acc": "0.8607778",
      "loss": "0.5855973059866163"
    },
    "3": {
      "name": 3,
      "learningrate": "0.0014281922309132267",
      "dropout": "0.4573409400885241",
      "epoch": "54.71933755794072",
      "batchsize": "56.60235667134053",
      "optimizer": "0.43389038238963573",
      "acc": "0.85903704",
      "loss": "0.47707584272821746"
    },
    "4": {
      "name": 4,
      "learningrate": "0.0013448178134176404",
      "dropout": "0.15682827313726694",
      "epoch": "56.58820615432476",
      "batchsize": "49.42008367852526",
      "optimizer": "0.03901169105169611",
      "acc": "0.8583889",
      "loss": "0.5812216747072008"
    },
    "5": {
      "name": 5,
      "learningrate": "0.00582641698908923",
      "dropout": "0.1281285070358473",
      "epoch": "66.29219793660707",
      "batchsize": "50.03625821451772",
      "optimizer": "2.4045775234302815",
      "acc": "0.85746294",
      "loss": "1.175527765882581"
    },
    "6": {
      "name": 6,
      "learningrate": "0.00984688981815026",
      "dropout": "0.09339475845246455",
      "epoch": "78.42926753500056",
      "batchsize": "35.193240255804405",
      "optimizer": "1.4354092047659064",
      "acc": "0.8571852",
      "loss": "0.4155020617776447"
    },
    "7": {
      "name": 7,
      "learningrate": "0.0036264258193455063",
      "dropout": "0.11230462094018986",
      "epoch": "59.67311220145628",
      "batchsize": "55.34828465316019",
      "optimizer": "0.038268513263151616",
      "acc": "0.8566667",
      "loss": "0.6431656784569776"
    },
    "8": {
      "name": 8,
      "learningrate": "0.004889226805171884",
      "dropout": "0.16334907901392767",
      "epoch": "50.63268738162744",
      "batchsize": "52.1233732847019",
      "optimizer": "0.10012294144078304",
      "acc": "0.856037",
      "loss": "0.583968450292393"
    },
    "9": {
      "name": 9,
      "learningrate": "0.0013642421854580084",
      "dropout": "0.15794760864755605",
      "epoch": "86.19555243803558",
      "batchsize": "34.98733598476504",
      "optimizer": "1.6891022721672755",
      "acc": "0.856",
      "loss": "0.9618820677449306"
    },
    "10": {
      "name": 10,
      "learningrate": "0.007516255808540753",
      "dropout": "0.2021547131833501",
      "epoch": "99.1628481279914",
      "batchsize": "47.482050272435174",
      "optimizer": "0.6868489260493102",
      "acc": "0.8557407",
      "loss": "0.41303835161526997"
    },
    "11": {
      "name": 11,
      "learningrate": "0.008809127491310062",
      "dropout": "0.10812681088673726",
      "epoch": "93.25708089314048",
      "batchsize": "49.87723433572466",
      "optimizer": "1.0611230726941225",
      "acc": "0.85572225",
      "loss": "0.4186800003493274"
    },
    "12": {
      "name": 12,
      "learningrate": "0.0030238606743904243",
      "dropout": "0.3765583208065756",
      "epoch": "51.00101793264832",
      "batchsize": "43.174090965070135",
      "optimizer": "2.477506313451755",
      "acc": "0.8556852",
      "loss": "0.7513995378734889"
    },
    "13": {
      "name": 13,
      "learningrate": "0.0026935519474141495",
      "dropout": "0.3652619001308556",
      "epoch": "58.813545099548534",
      "batchsize": "41.480770831622515",
      "optimizer": "0.2941074537790439",
      "acc": "0.85546297",
      "loss": "0.5580910426974297"
    },
    "14": {
      "name": 14,
      "learningrate": "0.0034913704186690943",
      "dropout": "0.11915674309289019",
      "epoch": "63.944474866031264",
      "batchsize": "55.84370856181387",
      "optimizer": "0.3524675295521543",
      "acc": "0.85524076",
      "loss": "0.6410292702565591"
    },
    "15": {
      "name": 15,
      "learningrate": "0.005317303784570505",
      "dropout": "0.35814594593752147",
      "epoch": "56.28602791575003",
      "batchsize": "49.513523265713296",
      "optimizer": "1.557291759835247",
      "acc": "0.8552222",
      "loss": "0.8380370548058439"
    },
    "16": {
      "name": 16,
      "learningrate": "0.009531288743886797",
      "dropout": "0.14298546379039845",
      "epoch": "89.16512193019165",
      "batchsize": "53.439604123281875",
      "optimizer": "1.327153947758383",
      "acc": "0.855",
      "loss": "0.41339758838106083"
    },
    "17": {
      "name": 17,
      "learningrate": "0.0035384586532027943",
      "dropout": "0.2644668465565093",
      "epoch": "80.86387339874639",
      "batchsize": "51.95654869988466",
      "optimizer": "0.03424780687185314",
      "acc": "0.85485184",
      "loss": "0.6846523522083406"
    },
    "18": {
      "name": 18,
      "learningrate": "0.0013332486227553043",
      "dropout": "0.2701858037294734",
      "epoch": "70.5723897136464",
      "batchsize": "52.423948034167424",
      "optimizer": "1.67339338801338",
      "acc": "0.8546482",
      "loss": "0.7952934323411297"
    },
    "19": {
      "name": 19,
      "learningrate": "0.003906151968905781",
      "dropout": "0.07019832668489402",
      "epoch": "52.73574427849385",
      "batchsize": "63.72479107249835",
      "optimizer": "0.01780728977017254",
      "acc": "0.85425925",
      "loss": "0.6989950595100721"
    },
    "20": {
      "name": 20,
      "learningrate": "0.007769100491309808",
      "dropout": "0.10048435440013219",
      "epoch": "81.96584263026841",
      "batchsize": "48.43173227464578",
      "optimizer": "0.5272270995277154",
      "acc": "0.8539074",
      "loss": "0.423283997381175"
    },
    "21": {
      "name": 21,
      "learningrate": "0.003722829228339923",
      "dropout": "0.16562195024865822",
      "epoch": "69.32274213508735",
      "batchsize": "47.85510807505353",
      "optimizer": "1.9862598770942546",
      "acc": "0.85366666",
      "loss": "1.1309023700706937"
    },
    "22": {
      "name": 22,
      "learningrate": "0.008381540993473359",
      "dropout": "0.28473312786599464",
      "epoch": "79.89618134855529",
      "batchsize": "44.46181926798066",
      "optimizer": "0.857461009993926",
      "acc": "0.8535926",
      "loss": "0.42075110477871364"
    },
    "23": {
      "name": 23,
      "learningrate": "0.008017663975755174",
      "dropout": "0.22251239072837048",
      "epoch": "93.62681810474331",
      "batchsize": "60.98726213343468",
      "optimizer": "0.9384883196787094",
      "acc": "0.85344446",
      "loss": "0.41795212519168856"
    },
    "24": {
      "name": 24,
      "learningrate": "0.0061791181101202575",
      "dropout": "0.14028886845842586",
      "epoch": "96.28313240760343",
      "batchsize": "56.05747418582436",
      "optimizer": "1.6929308611829295",
      "acc": "0.8530741",
      "loss": "1.5777740527287953"
    },
    "25": {
      "name": 25,
      "learningrate": "0.007722494738641764",
      "dropout": "0.16748785664523136",
      "epoch": "74.8580731239724",
      "batchsize": "49.66720092654802",
      "optimizer": "0.7010261950274252",
      "acc": "0.8528889",
      "loss": "0.4264277805840528"
    },
    "26": {
      "name": 26,
      "learningrate": "0.007894638667760943",
      "dropout": "0.4008497767060544",
      "epoch": "83.79804730288217",
      "batchsize": "49.3984790608947",
      "optimizer": "0.8131293033606787",
      "acc": "0.85283333",
      "loss": "0.4215231021951746"
    },
    "27": {
      "name": 27,
      "learningrate": "0.007738423695001325",
      "dropout": "0.29066443701705125",
      "epoch": "76.27386666547413",
      "batchsize": "46.305306049038094",
      "optimizer": "0.808212349412281",
      "acc": "0.8523889",
      "loss": "0.418577009095086"
    },
    "28": {
      "name": 28,
      "learningrate": "0.0030840100379931463",
      "dropout": "0.3299926900034946",
      "epoch": "81.29055873580607",
      "batchsize": "42.51329476622291",
      "optimizer": "0.29628692356573894",
      "acc": "0.8520741",
      "loss": "0.712362613817056"
    },
    "29": {
      "name": 29,
      "learningrate": "0.006753721811601637",
      "dropout": "0.3775700286828686",
      "epoch": "95.12558415331851",
      "batchsize": "60.205985856741336",
      "optimizer": "1.4935867985995581",
      "acc": "0.8517778",
      "loss": "0.42522378753291235"
    },
    "30": {
      "name": 30,
      "learningrate": "0.00657237123464029",
      "dropout": "0.24306692238523586",
      "epoch": "76.82584541212992",
      "batchsize": "50.78240345597338",
      "optimizer": "0.8293848806883286",
      "acc": "0.8513333",
      "loss": "0.42881746643560903"
    },
    "31": {
      "name": 31,
      "learningrate": "0.007400586930958282",
      "dropout": "0.21465962798899402",
      "epoch": "75.51512158323033",
      "batchsize": "47.589637481384656",
      "optimizer": "1.0074882266471974",
      "acc": "0.8511481",
      "loss": "0.4268668559833809"
    },
    "32": {
      "name": 32,
      "learningrate": "0.004351033218501383",
      "dropout": "0.0966798589247671",
      "epoch": "87.82415175861647",
      "batchsize": "34.81901299332622",
      "optimizer": "1.1793183739042439",
      "acc": "0.8508704",
      "loss": "0.434743865357505"
    },
    "33": {
      "name": 33,
      "learningrate": "0.005192738379233336",
      "dropout": "0.1471771610662186",
      "epoch": "87.21147972390395",
      "batchsize": "41.84396367144795",
      "optimizer": "1.4169785904036822",
      "acc": "0.8507778",
      "loss": "0.4330698104920211"
    },
    "34": {
      "name": 34,
      "learningrate": "0.00990702245830781",
      "dropout": "0.0663425725573883",
      "epoch": "52.89450105486429",
      "batchsize": "55.98814420476715",
      "optimizer": "0.7288688701243311",
      "acc": "0.85074073",
      "loss": "0.43185459647355257"
    },
    "35": {
      "name": 35,
      "learningrate": "0.00912826062776219",
      "dropout": "0.468578766724311",
      "epoch": "99.99173362575158",
      "batchsize": "32.826530605659464",
      "optimizer": "2.862456093986107",
      "acc": "0.85",
      "loss": "0.41948031002062336"
    },
    "36": {
      "name": 36,
      "learningrate": "0.005661139808051533",
      "dropout": "0.23912745660334567",
      "epoch": "98.8099521931217",
      "batchsize": "58.02479604492612",
      "optimizer": "0.8990477493361736",
      "acc": "0.85",
      "loss": "0.43522023311809255"
    },
    "37": {
      "name": 37,
      "learningrate": "0.006629187593947107",
      "dropout": "0.3767016462067398",
      "epoch": "97.46189309645513",
      "batchsize": "59.56089537828454",
      "optimizer": "1.2513465901722316",
      "acc": "0.8499074",
      "loss": "0.4252760201471823"
    },
    "38": {
      "name": 38,
      "learningrate": "0.008417989195214196",
      "dropout": "0.23083955114736454",
      "epoch": "98.91445151514188",
      "batchsize": "45.97091980615539",
      "optimizer": "2.698988990044033",
      "acc": "0.8497037",
      "loss": "0.42899634514031587"
    },
    "39": {
      "name": 39,
      "learningrate": "0.006070810089390744",
      "dropout": "0.37237399988565384",
      "epoch": "70.32355701450939",
      "batchsize": "50.28826235612813",
      "optimizer": "0.6161136397716612",
      "acc": "0.84757406",
      "loss": "0.43639060627089604"
    },
    "40": {
      "name": 40,
      "learningrate": "0.005286823908438315",
      "dropout": "0.26994615486065376",
      "epoch": "74.71836037750897",
      "batchsize": "40.564873187586876",
      "optimizer": "1.150364759072625",
      "acc": "0.84742594",
      "loss": "0.4373102176233574"
    },
    "41": {
      "name": 41,
      "learningrate": "0.004966512536420942",
      "dropout": "0.31003712833790764",
      "epoch": "99.78857735049743",
      "batchsize": "59.77315017422005",
      "optimizer": "0.8084336055123894",
      "acc": "0.84727776",
      "loss": "0.4397350659988545"
    },
    "42": {
      "name": 42,
      "learningrate": "0.0032778658955243947",
      "dropout": "0.057549589771741294",
      "epoch": "99.50309268360365",
      "batchsize": "47.2889244651157",
      "optimizer": "0.4680375369795967",
      "acc": "0.847037",
      "loss": "1.031779450836005"
    },
    "43": {
      "name": 43,
      "learningrate": "0.005627442102721012",
      "dropout": "0.38125548414772165",
      "epoch": "66.59512580795668",
      "batchsize": "48.62886696802228",
      "optimizer": "0.5463091760142432",
      "acc": "0.84694445",
      "loss": "0.4411226161541762"
    },
    "44": {
      "name": 44,
      "learningrate": "0.00874558724407123",
      "dropout": "0.262889981625724",
      "epoch": "99.29325487516545",
      "batchsize": "51.05611755821109",
      "optimizer": "2.713546638826008",
      "acc": "0.84683335",
      "loss": "0.4386093102561103"
    },
    "45": {
      "name": 45,
      "learningrate": "0.006693695316660791",
      "dropout": "0.25234197627768423",
      "epoch": "87.8443755412305",
      "batchsize": "54.621177371584224",
      "optimizer": "0.21799522432631413",
      "acc": "0.8467778",
      "loss": "0.6395808067189322"
    },
    "46": {
      "name": 46,
      "learningrate": "0.005237530642859103",
      "dropout": "0.45724126444676416",
      "epoch": "90.28209243577686",
      "batchsize": "50.31280685724858",
      "optimizer": "1.3206950615467679",
      "acc": "0.8466296",
      "loss": "0.43774039078200305"
    },
    "47": {
      "name": 47,
      "learningrate": "0.006869863208342927",
      "dropout": "0.3245735827991127",
      "epoch": "64.19759143866258",
      "batchsize": "37.91827199934015",
      "optimizer": "0.4270215326481728",
      "acc": "0.84646297",
      "loss": "0.6872236252051812"
    },
    "48": {
      "name": 48,
      "learningrate": "0.00694896362133046",
      "dropout": "0.32545663875735914",
      "epoch": "89.79976282271372",
      "batchsize": "59.688708578852",
      "optimizer": "2.3989380330694043",
      "acc": "0.84642595",
      "loss": "1.2765449376216642"
    },
    "49": {
      "name": 49,
      "learningrate": "0.004472548890616813",
      "dropout": "0.30341051845348427",
      "epoch": "98.97308116631618",
      "batchsize": "32.5195599556685",
      "optimizer": "2.782272279987424",
      "acc": "0.84605557",
      "loss": "0.44340050555158544"
    },
    "50": {
      "name": 50,
      "learningrate": "0.008104312630288171",
      "dropout": "0.1266035249788448",
      "epoch": "74.91485139366267",
      "batchsize": "60.612108310251855",
      "optimizer": "0.29455687706524947",
      "acc": "0.84585184",
      "loss": "0.7539768184445522"
    },
    "51": {
      "name": 51,
      "learningrate": "0.003709523783149251",
      "dropout": "0.49151097632071616",
      "epoch": "55.70743112198682",
      "batchsize": "39.91178591745246",
      "optimizer": "0.27436356601661416",
      "acc": "0.84577775",
      "loss": "0.509474332637257"
    },
    "52": {
      "name": 52,
      "learningrate": "0.006626923248532637",
      "dropout": "0.470792230390261",
      "epoch": "54.85656113308077",
      "batchsize": "37.9069436254649",
      "optimizer": "0.7596939466894131",
      "acc": "0.84564817",
      "loss": "0.4405056497476719"
    },
    "53": {
      "name": 53,
      "learningrate": "0.0025484056318667973",
      "dropout": "0.19662215392428356",
      "epoch": "69.74265436538411",
      "batchsize": "40.97346994043228",
      "optimizer": "1.7026843522520214",
      "acc": "0.8453148",
      "loss": "1.2606984929509324"
    },
    "54": {
      "name": 54,
      "learningrate": "0.009840422619900572",
      "dropout": "0.22815790010263315",
      "epoch": "95.96947842000075",
      "batchsize": "61.137713499386386",
      "optimizer": "0.4809300447921019",
      "acc": "0.84346294",
      "loss": "0.7605332049197621"
    },
    "55": {
      "name": 55,
      "learningrate": "0.0059332770631652515",
      "dropout": "0.23271244022606746",
      "epoch": "59.12674866932534",
      "batchsize": "62.563318227947484",
      "optimizer": "1.3627900605949335",
      "acc": "0.84294444",
      "loss": "0.45316373267880194"
    },
    "56": {
      "name": 56,
      "learningrate": "0.007994389111945653",
      "dropout": "0.05710792044363286",
      "epoch": "88.7718963022053",
      "batchsize": "34.307388018146426",
      "optimizer": "0.4850019859124314",
      "acc": "0.84144443",
      "loss": "0.9983961275341334"
    },
    "57": {
      "name": 57,
      "learningrate": "0.005400072345295671",
      "dropout": "0.26800927435158906",
      "epoch": "91.25119976447287",
      "batchsize": "43.257230557995975",
      "optimizer": "2.0525549611299994",
      "acc": "0.84094447",
      "loss": "1.397325613559396"
    },
    "58": {
      "name": 58,
      "learningrate": "0.0072986646557783325",
      "dropout": "0.2731117028333249",
      "epoch": "56.92131898927514",
      "batchsize": "34.99371146564271",
      "optimizer": "2.3194523910053504",
      "acc": "0.84051853",
      "loss": "1.2886439682123838"
    },
    "59": {
      "name": 59,
      "learningrate": "0.004707801330872504",
      "dropout": "0.24709984919020966",
      "epoch": "53.88304552904809",
      "batchsize": "51.29181507933685",
      "optimizer": "0.5351745210726757",
      "acc": "0.8402037",
      "loss": "0.4679680998060438"
    },
    "60": {
      "name": 60,
      "learningrate": "0.007954023383136239",
      "dropout": "0.4134351326402826",
      "epoch": "71.6831849168106",
      "batchsize": "42.70226616977611",
      "optimizer": "0.13802904520253423",
      "acc": "0.8400185",
      "loss": "0.689456719217477"
    },
    "61": {
      "name": 61,
      "learningrate": "0.004989922129276509",
      "dropout": "0.43836809963726936",
      "epoch": "97.84581626248809",
      "batchsize": "59.541876317199176",
      "optimizer": "0.385926695910929",
      "acc": "0.8399444",
      "loss": "0.6600687832788185"
    },
    "62": {
      "name": 62,
      "learningrate": "0.003371960349365607",
      "dropout": "0.394827560178293",
      "epoch": "99.55480155614839",
      "batchsize": "32.75220853810688",
      "optimizer": "2.990616272700504",
      "acc": "0.839537",
      "loss": "0.4645614230985995"
    },
    "63": {
      "name": 63,
      "learningrate": "0.006979729663556469",
      "dropout": "0.4482137922658655",
      "epoch": "86.59439650299348",
      "batchsize": "46.957953785557294",
      "optimizer": "1.910003270442894",
      "acc": "0.83853704",
      "loss": "1.1842429447118883"
    },
    "64": {
      "name": 64,
      "learningrate": "0.007721586567324933",
      "dropout": "0.2186113861251619",
      "epoch": "68.57536337713262",
      "batchsize": "58.288150473377776",
      "optimizer": "2.7970435515815204",
      "acc": "0.83727777",
      "loss": "0.4715214613455313"
    },
    "65": {
      "name": 65,
      "learningrate": "0.00890969287415511",
      "dropout": "0.12935147483859727",
      "epoch": "50.85085450708234",
      "batchsize": "46.99379370743496",
      "optimizer": "1.7217257469363174",
      "acc": "0.8366852",
      "loss": "1.285604390774612"
    },
    "66": {
      "name": 66,
      "learningrate": "0.0037469021107521872",
      "dropout": "0.36105412685255833",
      "epoch": "69.6629737778139",
      "batchsize": "61.84920974953444",
      "optimizer": "0.6558493872317186",
      "acc": "0.83507407",
      "loss": "0.4848314192383378"
    },
    "67": {
      "name": 67,
      "learningrate": "0.0077443813916709524",
      "dropout": "0.4254140450712629",
      "epoch": "82.90755559711465",
      "batchsize": "37.420597923036226",
      "optimizer": "2.0147959982958703",
      "acc": "0.83474076",
      "loss": "1.5606008190727896"
    },
    "68": {
      "name": 68,
      "learningrate": "0.009990414968537786",
      "dropout": "0.16057053869320403",
      "epoch": "52.77193461403304",
      "batchsize": "48.01580561080021",
      "optimizer": "1.926362983399232",
      "acc": "0.83424073",
      "loss": "1.1886671208319841"
    },
    "69": {
      "name": 69,
      "learningrate": "0.0038815256552214286",
      "dropout": "0.3431407751343526",
      "epoch": "56.73017422385084",
      "batchsize": "57.89988168463158",
      "optimizer": "0.7401675162568118",
      "acc": "0.83346295",
      "loss": "0.48708003131548566"
    },
    "70": {
      "name": 70,
      "learningrate": "0.007087406530820883",
      "dropout": "0.4462976927076244",
      "epoch": "88.44382577741291",
      "batchsize": "55.596691105914374",
      "optimizer": "2.242673463427203",
      "acc": "0.8325",
      "loss": "1.4357220172451601"
    },
    "71": {
      "name": 71,
      "learningrate": "0.009312920997267478",
      "dropout": "0.14734972044031142",
      "epoch": "54.938641934493944",
      "batchsize": "46.61270724387832",
      "optimizer": "1.8921426835369397",
      "acc": "0.8324815",
      "loss": "1.3183022430881306"
    },
    "72": {
      "name": 72,
      "learningrate": "0.009174102332684363",
      "dropout": "0.24877961100811002",
      "epoch": "66.75946315948838",
      "batchsize": "44.952782524080845",
      "optimizer": "0.4369687370241957",
      "acc": "0.8319074",
      "loss": "0.7708695007099046"
    },
    "73": {
      "name": 73,
      "learningrate": "0.0025715944010887538",
      "dropout": "0.40845106670933734",
      "epoch": "95.86931315153518",
      "batchsize": "63.52987745190396",
      "optimizer": "0.5211791651844181",
      "acc": "0.8318704",
      "loss": "0.49427693151544644"
    },
    "74": {
      "name": 74,
      "learningrate": "0.0037096403939671048",
      "dropout": "0.4505091144753419",
      "epoch": "52.03595448722015",
      "batchsize": "56.74637928007679",
      "optimizer": "1.3116129654468986",
      "acc": "0.8317963",
      "loss": "0.49502429351983246"
    },
    "75": {
      "name": 75,
      "learningrate": "0.008856994328899836",
      "dropout": "0.08554612040301862",
      "epoch": "95.05366887016864",
      "batchsize": "59.086015506923175",
      "optimizer": "2.3530338628842857",
      "acc": "0.831537",
      "loss": "2.010868570441449"
    },
    "76": {
      "name": 76,
      "learningrate": "0.00639904238379168",
      "dropout": "0.4326964507666492",
      "epoch": "94.35127548984751",
      "batchsize": "39.08389690615719",
      "optimizer": "1.9723827520560673",
      "acc": "0.8315",
      "loss": "1.5791326643032608"
    },
    "77": {
      "name": 77,
      "learningrate": "0.006060737632806642",
      "dropout": "0.4666485077711376",
      "epoch": "75.78911230091671",
      "batchsize": "43.694983211264045",
      "optimizer": "2.0413752571503694",
      "acc": "0.8305",
      "loss": "1.1555720660664417"
    },
    "78": {
      "name": 78,
      "learningrate": "0.009119176017489542",
      "dropout": "0.34873192481165105",
      "epoch": "77.69392184830635",
      "batchsize": "48.128678831438236",
      "optimizer": "0.48791705824548803",
      "acc": "0.83",
      "loss": "0.8021886512526759"
    },
    "79": {
      "name": 79,
      "learningrate": "0.00761899416691629",
      "dropout": "0.4424624944859392",
      "epoch": "94.6678165198073",
      "batchsize": "44.692869343185066",
      "optimizer": "1.6323883530496315",
      "acc": "0.8287778",
      "loss": "1.4460915841835515"
    },
    "80": {
      "name": 80,
      "learningrate": "0.009907200718084248",
      "dropout": "0.4146162336090122",
      "epoch": "67.52906373439026",
      "batchsize": "37.29439331432094",
      "optimizer": "0.43462226804109283",
      "acc": "0.8282037",
      "loss": "0.6430710563770047"
    },
    "81": {
      "name": 81,
      "learningrate": "0.0019483192810740599",
      "dropout": "0.35572456880955283",
      "epoch": "81.73607686959161",
      "batchsize": "55.43521738782988",
      "optimizer": "0.8652424515842022",
      "acc": "0.82503706",
      "loss": "0.5212068060150853"
    },
    "82": {
      "name": 82,
      "learningrate": "0.002191724986721704",
      "dropout": "0.1419296969415012",
      "epoch": "63.906178407962166",
      "batchsize": "61.32600723399658",
      "optimizer": "0.749022839537118",
      "acc": "0.8231111",
      "loss": "0.5221835249794854"
    },
    "83": {
      "name": 83,
      "learningrate": "0.003272627012819798",
      "dropout": "0.07045032442700759",
      "epoch": "66.51444814822962",
      "batchsize": "49.78879979106475",
      "optimizer": "2.718299387561932",
      "acc": "0.82277775",
      "loss": "0.5277735738754272"
    },
    "84": {
      "name": 84,
      "learningrate": "0.009888596810723743",
      "dropout": "0.17575308411589258",
      "epoch": "77.65437076414327",
      "batchsize": "45.748034054454536",
      "optimizer": "0.3644296014918489",
      "acc": "0.8219444",
      "loss": "0.726426962852478"
    },
    "85": {
      "name": 85,
      "learningrate": "0.00905527537619964",
      "dropout": "0.19985935628716162",
      "epoch": "77.71828138795547",
      "batchsize": "32.28707115046603",
      "optimizer": "0.3286249989774682",
      "acc": "0.8209815",
      "loss": "0.918454728576872"
    },
    "86": {
      "name": 86,
      "learningrate": "0.009901573248763942",
      "dropout": "0.49404222720964",
      "epoch": "93.12190963008473",
      "batchsize": "54.21778065931882",
      "optimizer": "0.2141897877118456",
      "acc": "0.82064813",
      "loss": "0.6441049693028132"
    },
    "87": {
      "name": 87,
      "learningrate": "0.0030543900020057117",
      "dropout": "0.46926833203277807",
      "epoch": "97.50208932610093",
      "batchsize": "58.43309830370599",
      "optimizer": "2.6067321132999335",
      "acc": "0.8193704",
      "loss": "0.5356296181590469"
    },
    "88": {
      "name": 88,
      "learningrate": "0.001616559359704522",
      "dropout": "0.33174183744003677",
      "epoch": "57.62094736995993",
      "batchsize": "38.71658144938259",
      "optimizer": "0.8803900592411422",
      "acc": "0.8172778",
      "loss": "0.548234578512333"
    },
    "89": {
      "name": 89,
      "learningrate": "0.0015244168572076894",
      "dropout": "0.28270975634184675",
      "epoch": "61.85235107282994",
      "batchsize": "41.02544256603977",
      "optimizer": "0.9818520068831295",
      "acc": "0.8172037",
      "loss": "0.5533673181533814"
    },
    "90": {
      "name": 90,
      "learningrate": "0.009634583885416367",
      "dropout": "0.2434563574975105",
      "epoch": "50.66679153925841",
      "batchsize": "40.08717785709464",
      "optimizer": "1.8074301387195988",
      "acc": "0.8157963",
      "loss": "1.1762054845403742"
    },
    "91": {
      "name": 91,
      "learningrate": "0.008619286367495824",
      "dropout": "0.33397719800433173",
      "epoch": "78.30592160992727",
      "batchsize": "32.669160243149335",
      "optimizer": "2.2880018849978003",
      "acc": "0.81196296",
      "loss": "1.4745858443776767"
    },
    "92": {
      "name": 92,
      "learningrate": "0.0011737762956047376",
      "dropout": "0.49942262524080244",
      "epoch": "77.44308909351894",
      "batchsize": "38.445975113566675",
      "optimizer": "0.6027973961489754",
      "acc": "0.80222225",
      "loss": "0.5888312635245146"
    },
    "93": {
      "name": 93,
      "learningrate": "0.0006717861901554107",
      "dropout": "0.28843594214201834",
      "epoch": "83.10169398384201",
      "batchsize": "43.98912051863286",
      "optimizer": "0.8228446267154154",
      "acc": "0.79161114",
      "loss": "0.6410265243318346"
    },
    "94": {
      "name": 94,
      "learningrate": "0.0008099002846765565",
      "dropout": "0.2702672149663868",
      "epoch": "60.02457879124981",
      "batchsize": "44.45341848075971",
      "optimizer": "0.643454979909664",
      "acc": "0.78918517",
      "loss": "0.6435321741104126"
    },
    "95": {
      "name": 95,
      "learningrate": "0.00198768475658508",
      "dropout": "0.2748694148995571",
      "epoch": "56.73472184177736",
      "batchsize": "61.5746866607873",
      "optimizer": "2.6293681993421476",
      "acc": "0.7874445",
      "loss": "0.6439437414805095"
    },
    "96": {
      "name": 96,
      "learningrate": "0.0010706716723773695",
      "dropout": "0.22728832564660928",
      "epoch": "88.56796407155846",
      "batchsize": "60.170149818677956",
      "optimizer": "2.8426632597451587",
      "acc": "0.7862222",
      "loss": "0.6598582793518349"
    },
    "97": {
      "name": 97,
      "learningrate": "0.0005579413463852682",
      "dropout": "0.4058106260184798",
      "epoch": "93.64449845551505",
      "batchsize": "48.766293311117195",
      "optimizer": "0.7546450952596313",
      "acc": "0.7806482",
      "loss": "0.674839909500546"
    },
    "98": {
      "name": 98,
      "learningrate": "0.0007568781864775557",
      "dropout": "0.3410083256489509",
      "epoch": "51.54347987856155",
      "batchsize": "36.15085582477286",
      "optimizer": "2.772750502485928",
      "acc": "0.757",
      "loss": "0.7363228425803008"
    },
    "99": {
      "name": 99,
      "learningrate": "0.0008119145067300433",
      "dropout": "0.4600856244652878",
      "epoch": "82.09456976731217",
      "batchsize": "50.21205482757388",
      "optimizer": "2.9243306194233196",
      "acc": "0.75651854",
      "loss": "0.7202159676551819"
    }
  },
  "1": {
    "0": {
      "name": 0,
      "learningrate": "0.0010744736574577634",
      "dropout": "0.26781",
      "epoch": "53.88089",
      "batchsize": "55.97306",
      "optimizer": "0.3604265970806598",
      "acc": "0.8649815",
      "loss": "0.46577809598490044"
    },
    "1": {
      "name": 1,
      "learningrate": "0.0006",
      "dropout": "0.33148",
      "epoch": "81.30132",
      "batchsize": "42.51428",
      "optimizer": "0.37083043378420455",
      "acc": "0.8642778",
      "loss": "0.503758241162256"
    },
    "2": {
      "name": 2,
      "learningrate": "0.00147",
      "dropout": "0.39771",
      "epoch": "66.59846",
      "batchsize": "48.63131",
      "optimizer": "0.3571285087864885",
      "acc": "0.86337036",
      "loss": "0.500862980571058"
    },
    "3": {
      "name": 3,
      "learningrate": "0.0010700031799132001",
      "dropout": "0.22231",
      "epoch": "98.89684",
      "batchsize": "45.96517",
      "optimizer": "0.10387735375087093",
      "acc": "0.86311114",
      "loss": "0.6490274980708405"
    },
    "4": {
      "name": 4,
      "learningrate": "0.000509845443632821",
      "dropout": "0.23416",
      "epoch": "52.74688",
      "batchsize": "63.7388",
      "optimizer": "2.492683845569095",
      "acc": "0.8629074",
      "loss": "0.4446769920874525"
    },
    "5": {
      "name": 5,
      "learningrate": "0.0006915737929666093",
      "dropout": "0.35911721324611867",
      "epoch": "63.65825458529426",
      "batchsize": "50.92512127058096",
      "optimizer": "2.1535443538355805",
      "acc": "0.86266667",
      "loss": "0.5197920561123778"
    },
    "6": {
      "name": 6,
      "learningrate": "0.00159",
      "dropout": "0.49395",
      "epoch": "75.77448",
      "batchsize": "37.90883",
      "optimizer": "0.40374599114765175",
      "acc": "0.86061114",
      "loss": "0.5318702279881194"
    },
    "7": {
      "name": 7,
      "learningrate": "0.00136",
      "dropout": "0.42189",
      "epoch": "54.86732",
      "batchsize": "37.90162",
      "optimizer": "1.8151548451483612",
      "acc": "0.8600741",
      "loss": "0.6633330476184686"
    },
    "8": {
      "name": 8,
      "learningrate": "0.0026976556372965274",
      "dropout": "0.29088",
      "epoch": "80.86776",
      "batchsize": "54.63027",
      "optimizer": "2.270228105792862",
      "acc": "0.8599074",
      "loss": "0.9627552709849896"
    },
    "9": {
      "name": 9,
      "learningrate": "0.00271",
      "dropout": "0.20009",
      "epoch": "68.57395",
      "batchsize": "58.29097",
      "optimizer": "2.3875551333331195",
      "acc": "0.8591296",
      "loss": "0.9117596358745187"
    },
    "10": {
      "name": 10,
      "learningrate": "0.00328",
      "dropout": "0.0831",
      "epoch": "50.86331",
      "batchsize": "46.97429",
      "optimizer": "2.4611664518520886",
      "acc": "0.859",
      "loss": "0.8482483272508339"
    },
    "11": {
      "name": 11,
      "learningrate": "0.0037354662849092665",
      "dropout": "0.15852",
      "epoch": "96.27742",
      "batchsize": "56.06216",
      "optimizer": "1.8478207956379986",
      "acc": "0.8589074",
      "loss": "1.34959125958797"
    },
    "12": {
      "name": 12,
      "learningrate": "0.009348326704290522",
      "dropout": "0.29526",
      "epoch": "99.53916",
      "batchsize": "47.29745",
      "optimizer": "1.2927835176227178",
      "acc": "0.85755557",
      "loss": "0.4052692150186609"
    },
    "13": {
      "name": 13,
      "learningrate": "0.00321",
      "dropout": "0.2485",
      "epoch": "66.75185",
      "batchsize": "44.92863",
      "optimizer": "0.1242406139961465",
      "acc": "0.857",
      "loss": "0.6157197407693774"
    },
    "14": {
      "name": 14,
      "learningrate": "0.00088",
      "dropout": "0.14947",
      "epoch": "74.82986",
      "batchsize": "49.64354",
      "optimizer": "0.47063132192448154",
      "acc": "0.857",
      "loss": "0.6062906779591684"
    },
    "15": {
      "name": 15,
      "learningrate": "0.00898175730559931",
      "dropout": "0.25642",
      "epoch": "76.29511",
      "batchsize": "44.67794",
      "optimizer": "1.4782018904435135",
      "acc": "0.856963",
      "loss": "0.40974067305194006"
    },
    "16": {
      "name": 16,
      "learningrate": "0.004119845665160953",
      "dropout": "0.1255",
      "epoch": "93.25379",
      "batchsize": "49.87136",
      "optimizer": "1.7011070922354925",
      "acc": "0.85627776",
      "loss": "1.5204388358276337"
    },
    "17": {
      "name": 17,
      "learningrate": "0.009035262985712503",
      "dropout": "0.23658",
      "epoch": "95.98491",
      "batchsize": "58.28892",
      "optimizer": "1.1566587238660215",
      "acc": "0.85624075",
      "loss": "0.41249066446445604"
    },
    "18": {
      "name": 18,
      "learningrate": "0.00793",
      "dropout": "0.44496",
      "epoch": "99.29756",
      "batchsize": "51.06535",
      "optimizer": "0.7531772367547729",
      "acc": "0.85605556",
      "loss": "0.4115755671969166"
    },
    "19": {
      "name": 19,
      "learningrate": "0.0015032757614560322",
      "dropout": "0.09637",
      "epoch": "81.97407",
      "batchsize": "46.97636",
      "optimizer": "1.513457406889528",
      "acc": "0.8553889",
      "loss": "1.0155769153055219"
    },
    "20": {
      "name": 20,
      "learningrate": "0.0006855517222746128",
      "dropout": "0.35778",
      "epoch": "56.27864",
      "batchsize": "49.50381",
      "optimizer": "2.401066775114053",
      "acc": "0.8545741",
      "loss": "0.5457509669484916"
    },
    "21": {
      "name": 21,
      "learningrate": "0.005933329476122563",
      "dropout": "0.13941",
      "epoch": "87.82838",
      "batchsize": "34.83556",
      "optimizer": "1.1177528445301852",
      "acc": "0.85444444",
      "loss": "0.4183811238783377"
    },
    "22": {
      "name": 22,
      "learningrate": "0.00906",
      "dropout": "0.06948",
      "epoch": "98.81278",
      "batchsize": "58.04536",
      "optimizer": "0.5035450813470972",
      "acc": "0.8540185",
      "loss": "0.42385272472434576"
    },
    "23": {
      "name": 23,
      "learningrate": "0.00857950555620375",
      "dropout": "0.07993",
      "epoch": "50.87303",
      "batchsize": "48.44233",
      "optimizer": "2.4513986110175483",
      "acc": "0.85344446",
      "loss": "1.1307287571485396"
    },
    "24": {
      "name": 24,
      "learningrate": "0.0027509933710542214",
      "dropout": "0.39217",
      "epoch": "66.60882",
      "batchsize": "48.63103",
      "optimizer": "2.4727682897905296",
      "acc": "0.8522963",
      "loss": "0.8046197027221874"
    },
    "25": {
      "name": 25,
      "learningrate": "0.0083",
      "dropout": "0.44764",
      "epoch": "97.84",
      "batchsize": "59.55209",
      "optimizer": "1.3600756381545205",
      "acc": "0.8522037",
      "loss": "0.4205961015180305"
    },
    "26": {
      "name": 26,
      "learningrate": "0.00793",
      "dropout": "0.43282",
      "epoch": "94.6854",
      "batchsize": "46.29644",
      "optimizer": "1.3109251345464623",
      "acc": "0.85201854",
      "loss": "0.414851521147622"
    },
    "27": {
      "name": 27,
      "learningrate": "0.004270859364778637",
      "dropout": "0.26993",
      "epoch": "56.90435",
      "batchsize": "35.00388",
      "optimizer": "2.454057073935898",
      "acc": "0.8516296",
      "loss": "1.037432160358738"
    },
    "28": {
      "name": 28,
      "learningrate": "0.008357971340589795",
      "dropout": "0.42805",
      "epoch": "54.86263",
      "batchsize": "32.82479",
      "optimizer": "1.4200873431559407",
      "acc": "0.8514444",
      "loss": "0.42130893803525854"
    },
    "29": {
      "name": 29,
      "learningrate": "0.005109195488314367",
      "dropout": "0.28557",
      "epoch": "52.78426",
      "batchsize": "48.01436",
      "optimizer": "2.4456858669673918",
      "acc": "0.85142595",
      "loss": "0.8980997264644613"
    },
    "30": {
      "name": 30,
      "learningrate": "0.0079",
      "dropout": "0.38046",
      "epoch": "99.80878",
      "batchsize": "59.76896",
      "optimizer": "0.5858029209636064",
      "acc": "0.85131484",
      "loss": "0.42216846347738196"
    },
    "31": {
      "name": 31,
      "learningrate": "0.00553",
      "dropout": "0.08503",
      "epoch": "78.44681",
      "batchsize": "35.18936",
      "optimizer": "1.102335149099921",
      "acc": "0.8512222",
      "loss": "0.4298596397461715"
    },
    "32": {
      "name": 32,
      "learningrate": "0.00669",
      "dropout": "0.38383",
      "epoch": "99.53851",
      "batchsize": "32.75976",
      "optimizer": "2.9695805629492056",
      "acc": "0.851037",
      "loss": "0.4291334404150645"
    },
    "33": {
      "name": 33,
      "learningrate": "0.006048940026416727",
      "dropout": "0.45361",
      "epoch": "90.29937",
      "batchsize": "37.91383",
      "optimizer": "0.6493267354946226",
      "acc": "0.8500926",
      "loss": "0.42301118483808303"
    },
    "34": {
      "name": 34,
      "learningrate": "0.006481385859136803",
      "dropout": "0.20856",
      "epoch": "99.17675",
      "batchsize": "47.48317",
      "optimizer": "0.4116517527870768",
      "acc": "0.84974074",
      "loss": "0.7907545288000946"
    },
    "35": {
      "name": 35,
      "learningrate": "0.008976641208740182",
      "dropout": "0.06576",
      "epoch": "52.88903",
      "batchsize": "51.28359",
      "optimizer": "0.9742755835037361",
      "acc": "0.84951854",
      "loss": "0.4367027868827184"
    },
    "36": {
      "name": 36,
      "learningrate": "0.00584",
      "dropout": "0.27949",
      "epoch": "74.71979",
      "batchsize": "40.56434",
      "optimizer": "1.4570846526613952",
      "acc": "0.849463",
      "loss": "0.42853862105917045"
    },
    "37": {
      "name": 37,
      "learningrate": "0.0058",
      "dropout": "0.24139",
      "epoch": "76.81575",
      "batchsize": "50.77158",
      "optimizer": "1.6820255861030367",
      "acc": "0.8492037",
      "loss": "1.2668270966261626"
    },
    "38": {
      "name": 38,
      "learningrate": "0.003364847335122261",
      "dropout": "0.2676779015643279",
      "epoch": "55.67235",
      "batchsize": "43.69861",
      "optimizer": "1.990134481716325",
      "acc": "0.8485",
      "loss": "0.9772024210994994"
    },
    "39": {
      "name": 39,
      "learningrate": "0.006282183999057828",
      "dropout": "0.36802",
      "epoch": "81.74758",
      "batchsize": "55.44135",
      "optimizer": "0.7907363967400883",
      "acc": "0.8483889",
      "loss": "0.43385776351557837"
    },
    "40": {
      "name": 40,
      "learningrate": "0.00984",
      "dropout": "0.25773",
      "epoch": "76.27531",
      "batchsize": "46.30572",
      "optimizer": "2.771523382710943",
      "acc": "0.84812963",
      "loss": "0.43660479895273846"
    },
    "41": {
      "name": 41,
      "learningrate": "0.004507274994174831",
      "dropout": "0.32845",
      "epoch": "99.52179",
      "batchsize": "47.31442",
      "optimizer": "1.0267084988654342",
      "acc": "0.847963",
      "loss": "0.43591126241507355"
    },
    "42": {
      "name": 42,
      "learningrate": "0.006565006376230696",
      "dropout": "0.26094",
      "epoch": "66.30542",
      "batchsize": "50.03451",
      "optimizer": "0.8894253687404573",
      "acc": "0.8478519",
      "loss": "0.43634774506533586"
    },
    "43": {
      "name": 43,
      "learningrate": "0.009909102473330657",
      "dropout": "0.05907",
      "epoch": "89.79492",
      "batchsize": "59.69447",
      "optimizer": "2.85331623870563",
      "acc": "0.8471852",
      "loss": "0.4424916501265985"
    },
    "44": {
      "name": 44,
      "learningrate": "0.00840465449891474",
      "dropout": "0.15779",
      "epoch": "79.9081",
      "batchsize": "44.48728",
      "optimizer": "2.741996205587689",
      "acc": "0.8463889",
      "loss": "0.44355830580216865"
    },
    "45": {
      "name": 45,
      "learningrate": "0.0055575083649943985",
      "dropout": "0.24225",
      "epoch": "87.8403",
      "batchsize": "51.96121",
      "optimizer": "0.2927461506711907",
      "acc": "0.8458704",
      "loss": "0.6823573420930792"
    },
    "46": {
      "name": 46,
      "learningrate": "0.00954",
      "dropout": "0.41599",
      "epoch": "54.86921",
      "batchsize": "32.82616",
      "optimizer": "2.5363851586971324",
      "acc": "0.84555554",
      "loss": "0.43679895595267965"
    },
    "47": {
      "name": 47,
      "learningrate": "0.005214692727145314",
      "dropout": "0.42429",
      "epoch": "86.5961",
      "batchsize": "47.48336",
      "optimizer": "1.1215140130203491",
      "acc": "0.84525925",
      "loss": "0.4424888773891661"
    },
    "48": {
      "name": 48,
      "learningrate": "0.004391019643925069",
      "dropout": "0.12204",
      "epoch": "66.7432",
      "batchsize": "44.92664",
      "optimizer": "0.8179594560096275",
      "acc": "0.84451854",
      "loss": "0.45269354550043744"
    },
    "49": {
      "name": 49,
      "learningrate": "0.00438450247045435",
      "dropout": "0.28508",
      "epoch": "54.87375",
      "batchsize": "32.84044",
      "optimizer": "2.36008773136463",
      "acc": "0.8441852",
      "loss": "1.1181040767017338"
    },
    "50": {
      "name": 50,
      "learningrate": "0.008906215991642902",
      "dropout": "0.24673",
      "epoch": "66.75252",
      "batchsize": "44.92919",
      "optimizer": "2.6176898562899598",
      "acc": "0.84374076",
      "loss": "0.45280235226949056"
    },
    "51": {
      "name": 51,
      "learningrate": "0.0030558738574673274",
      "dropout": "0.21197",
      "epoch": "99.16996",
      "batchsize": "46.95207",
      "optimizer": "1.3023003120678895",
      "acc": "0.8436852",
      "loss": "0.4568181644104145"
    },
    "52": {
      "name": 52,
      "learningrate": "0.005171853157559667",
      "dropout": "0.05618",
      "epoch": "52.88773",
      "batchsize": "51.27562",
      "optimizer": "1.8984178625020927",
      "acc": "0.8429259",
      "loss": "1.0904433611832836"
    },
    "53": {
      "name": 53,
      "learningrate": "0.0027463323009212872",
      "dropout": "0.27546",
      "epoch": "74.71006",
      "batchsize": "40.58366",
      "optimizer": "2.0039282117902215",
      "acc": "0.8423333",
      "loss": "1.0482919988852961"
    },
    "54": {
      "name": 54,
      "learningrate": "0.0030293327554691794",
      "dropout": "0.45512",
      "epoch": "99.9748",
      "batchsize": "37.9092",
      "optimizer": "0.6798197502890992",
      "acc": "0.8422222",
      "loss": "0.4603537997890402"
    },
    "55": {
      "name": 55,
      "learningrate": "0.00856",
      "dropout": "0.21661",
      "epoch": "75.51294",
      "batchsize": "47.58483",
      "optimizer": "2.759438195531626",
      "acc": "0.84196293",
      "loss": "0.4522431699876432"
    },
    "56": {
      "name": 56,
      "learningrate": "0.007029692798196234",
      "dropout": "0.35269",
      "epoch": "70.3218",
      "batchsize": "50.29751",
      "optimizer": "1.6076029021429905",
      "acc": "0.8419074",
      "loss": "1.2676783267899796"
    },
    "57": {
      "name": 57,
      "learningrate": "0.00917",
      "dropout": "0.40362",
      "epoch": "83.80885",
      "batchsize": "49.41076",
      "optimizer": "0.29994501515411687",
      "acc": "0.84037036",
      "loss": "0.6676650668691706"
    },
    "58": {
      "name": 58,
      "learningrate": "0.00459",
      "dropout": "0.44183",
      "epoch": "90.30308",
      "batchsize": "37.91205",
      "optimizer": "2.759702478721774",
      "acc": "0.83924073",
      "loss": "0.4612808048857583"
    },
    "59": {
      "name": 59,
      "learningrate": "0.0043",
      "dropout": "0.268",
      "epoch": "59.12459",
      "batchsize": "62.56674",
      "optimizer": "1.1223169079697155",
      "acc": "0.8388889",
      "loss": "0.47562475007551686"
    },
    "60": {
      "name": 60,
      "learningrate": "0.00301",
      "dropout": "0.16013766266378887",
      "epoch": "75.75242",
      "batchsize": "37.90418",
      "optimizer": "1.3426496682488052",
      "acc": "0.83827776",
      "loss": "0.47079858062885427"
    },
    "61": {
      "name": 61,
      "learningrate": "0.007306720075625231",
      "dropout": "0.24889",
      "epoch": "56.89821",
      "batchsize": "35.00958",
      "optimizer": "1.722676217419672",
      "acc": "0.83731484",
      "loss": "1.1216655625502268"
    },
    "62": {
      "name": 62,
      "learningrate": "0.00717",
      "dropout": "0.30767",
      "epoch": "99.98177",
      "batchsize": "37.90207",
      "optimizer": "2.207820288814581",
      "acc": "0.83725923",
      "loss": "1.6296327539020115"
    },
    "63": {
      "name": 63,
      "learningrate": "0.008998104293277766",
      "dropout": "0.14896",
      "epoch": "87.19485",
      "batchsize": "41.86528",
      "optimizer": "2.153937552534003",
      "acc": "0.8372037",
      "loss": "1.6358824723986565"
    },
    "64": {
      "name": 64,
      "learningrate": "0.0027209961937422204",
      "dropout": "0.23947",
      "epoch": "98.7967",
      "batchsize": "58.03354",
      "optimizer": "0.8658786200236589",
      "acc": "0.8370926",
      "loss": "0.47776996088027956"
    },
    "65": {
      "name": 65,
      "learningrate": "0.006860866830572854",
      "dropout": "0.44267",
      "epoch": "66.6127",
      "batchsize": "48.6324",
      "optimizer": "2.846318330679663",
      "acc": "0.8368889",
      "loss": "0.4693687892313357"
    },
    "66": {
      "name": 66,
      "learningrate": "0.0033829859255424676",
      "dropout": "0.32753",
      "epoch": "64.20374",
      "batchsize": "50.29459",
      "optimizer": "0.8690497360510029",
      "acc": "0.8366111",
      "loss": "0.47824785833888583"
    },
    "67": {
      "name": 67,
      "learningrate": "0.008810246332038973",
      "dropout": "0.11883",
      "epoch": "66.73436",
      "batchsize": "44.93344",
      "optimizer": "1.6866624872119815",
      "acc": "0.8363519",
      "loss": "1.608891351994541"
    },
    "68": {
      "name": 68,
      "learningrate": "0.006694446903510147",
      "dropout": "0.25059",
      "epoch": "59.1324",
      "batchsize": "62.56355",
      "optimizer": "0.44508822105273205",
      "acc": "0.8362037",
      "loss": "0.6889147915972603"
    },
    "69": {
      "name": 69,
      "learningrate": "0.00954",
      "dropout": "0.37059",
      "epoch": "81.74658",
      "batchsize": "55.4393",
      "optimizer": "0.3353764974213268",
      "acc": "0.83496296",
      "loss": "0.7266178782604359"
    },
    "70": {
      "name": 70,
      "learningrate": "0.006377640858789512",
      "dropout": "0.42554",
      "epoch": "82.8911",
      "batchsize": "37.42319",
      "optimizer": "1.6832430122968207",
      "acc": "0.83433336",
      "loss": "1.4610059552148535"
    },
    "71": {
      "name": 71,
      "learningrate": "0.005754891159841527",
      "dropout": "0.24644",
      "epoch": "76.28021",
      "batchsize": "44.68758",
      "optimizer": "0.23954847744186003",
      "acc": "0.8337963",
      "loss": "0.7652719841489085"
    },
    "72": {
      "name": 72,
      "learningrate": "0.00658",
      "dropout": "0.12853",
      "epoch": "93.25676",
      "batchsize": "49.8857",
      "optimizer": "2.195705074765109",
      "acc": "0.83372223",
      "loss": "1.8149017280825863"
    },
    "73": {
      "name": 73,
      "learningrate": "0.002496613647657773",
      "dropout": "0.33335",
      "epoch": "81.28318",
      "batchsize": "42.51916",
      "optimizer": "0.8441495785880946",
      "acc": "0.83335185",
      "loss": "0.4871552678125876"
    },
    "74": {
      "name": 74,
      "learningrate": "0.004891842003763417",
      "dropout": "0.17118",
      "epoch": "74.84814",
      "batchsize": "49.65515",
      "optimizer": "2.5237231952769306",
      "acc": "0.83331484",
      "loss": "0.48445747813030526"
    },
    "75": {
      "name": 75,
      "learningrate": "0.00703426361200161",
      "dropout": "0.42621",
      "epoch": "83.47894",
      "batchsize": "38.51871",
      "optimizer": "0.04784694615359697",
      "acc": "0.8327778",
      "loss": "0.6557451411397369"
    },
    "76": {
      "name": 76,
      "learningrate": "0.008165591111452894",
      "dropout": "0.45507",
      "epoch": "90.29306",
      "batchsize": "37.919",
      "optimizer": "2.162527669120699",
      "acc": "0.8327037",
      "loss": "1.7529034610600382"
    },
    "77": {
      "name": 77,
      "learningrate": "0.008752654700201399",
      "dropout": "0.44206",
      "epoch": "99.80646",
      "batchsize": "59.77192",
      "optimizer": "2.426746755393335",
      "acc": "0.8315926",
      "loss": "1.361176380497438"
    },
    "78": {
      "name": 78,
      "learningrate": "0.009658012240669448",
      "dropout": "0.36159",
      "epoch": "81.74003",
      "batchsize": "55.46043",
      "optimizer": "0.16946979908295545",
      "acc": "0.8315741",
      "loss": "0.6196808932092455"
    },
    "79": {
      "name": 79,
      "learningrate": "0.009975818564425105",
      "dropout": "0.06324",
      "epoch": "99.51061",
      "batchsize": "47.30165",
      "optimizer": "0.1014413631555019",
      "acc": "0.83077776",
      "loss": "1.2171667349095698"
    },
    "80": {
      "name": 80,
      "learningrate": "0.00768581297871827",
      "dropout": "0.09648",
      "epoch": "59.68744",
      "batchsize": "55.35625",
      "optimizer": "1.786844110280203",
      "acc": "0.8301296",
      "loss": "1.2299548599212258"
    },
    "81": {
      "name": 81,
      "learningrate": "0.008066634152781488",
      "dropout": "0.31147",
      "epoch": "99.98409",
      "batchsize": "39.90393",
      "optimizer": "2.233779432340556",
      "acc": "0.82942593",
      "loss": "1.829471277895901"
    },
    "82": {
      "name": 82,
      "learningrate": "0.0021688922676103032",
      "dropout": "0.36388",
      "epoch": "81.74432",
      "batchsize": "55.43999",
      "optimizer": "1.3977643997153701",
      "acc": "0.82533336",
      "loss": "0.5160948350871051"
    },
    "83": {
      "name": 83,
      "learningrate": "0.00729",
      "dropout": "0.44847",
      "epoch": "82.89408",
      "batchsize": "37.4267",
      "optimizer": "2.3444187472042968",
      "acc": "0.82468516",
      "loss": "1.2008322320359726"
    },
    "84": {
      "name": 84,
      "learningrate": "0.0033222265794535474",
      "dropout": "0.27696",
      "epoch": "88.43662",
      "batchsize": "55.58421",
      "optimizer": "2.7036196446314857",
      "acc": "0.8244445",
      "loss": "0.5137751785384285"
    },
    "85": {
      "name": 85,
      "learningrate": "0.002039671112349525",
      "dropout": "0.14718",
      "epoch": "56.58416",
      "batchsize": "49.41905",
      "optimizer": "0.5059029826462982",
      "acc": "0.82438886",
      "loss": "0.5239360056011765"
    },
    "86": {
      "name": 86,
      "learningrate": "0.004246788257413717",
      "dropout": "0.20254",
      "epoch": "68.55503",
      "batchsize": "61.14288",
      "optimizer": "2.66674915621906",
      "acc": "0.8226111",
      "loss": "0.52904919496289"
    },
    "87": {
      "name": 87,
      "learningrate": "0.0019999729314092093",
      "dropout": "0.16677205445930932",
      "epoch": "55.68299",
      "batchsize": "43.69035",
      "optimizer": "0.5431382198647389",
      "acc": "0.82207406",
      "loss": "0.5316105407962093"
    },
    "88": {
      "name": 88,
      "learningrate": "0.00143",
      "dropout": "0.23852",
      "epoch": "96.0066",
      "batchsize": "58.28818",
      "optimizer": "0.7564521345059696",
      "acc": "0.8209444",
      "loss": "0.5339025790691376"
    },
    "89": {
      "name": 89,
      "learningrate": "0.009506002147557807",
      "dropout": "0.47304",
      "epoch": "75.78683",
      "batchsize": "39.90511",
      "optimizer": "1.645736461966517",
      "acc": "0.82055557",
      "loss": "1.7684467110413091"
    },
    "90": {
      "name": 90,
      "learningrate": "0.00808555560234612",
      "dropout": "0.26415",
      "epoch": "96.01174",
      "batchsize": "58.26554",
      "optimizer": "1.5506127429340362",
      "acc": "0.81964815",
      "loss": "2.07683140977886"
    },
    "91": {
      "name": 91,
      "learningrate": "0.00181",
      "dropout": "0.32484",
      "epoch": "64.19346",
      "batchsize": "50.30808",
      "optimizer": "1.4653074840123457",
      "acc": "0.8196296",
      "loss": "0.5403391264191381"
    },
    "92": {
      "name": 92,
      "learningrate": "0.0017",
      "dropout": "0.07328",
      "epoch": "50.87875",
      "batchsize": "48.43782",
      "optimizer": "1.1233351781518444",
      "acc": "0.8172407",
      "loss": "0.5489060612254673"
    },
    "93": {
      "name": 93,
      "learningrate": "0.00131",
      "dropout": "0.28696",
      "epoch": "80.85313",
      "batchsize": "51.95784",
      "optimizer": "0.5914271233895129",
      "acc": "0.8123518",
      "loss": "0.5653043712510003"
    },
    "94": {
      "name": 94,
      "learningrate": "0.002518186635630785",
      "dropout": "0.1973",
      "epoch": "68.56185",
      "batchsize": "61.14057",
      "optimizer": "2.712472787373293",
      "acc": "0.8091111",
      "loss": "0.5799307105982745"
    },
    "95": {
      "name": 95,
      "learningrate": "0.00838",
      "dropout": "0.26532",
      "epoch": "91.26124",
      "batchsize": "43.24965",
      "optimizer": "0.2939632488730106",
      "acc": "0.8044074",
      "loss": "0.7313780162290291"
    },
    "96": {
      "name": 96,
      "learningrate": "0.0007718111972470072",
      "dropout": "0.23821",
      "epoch": "93.62049",
      "batchsize": "60.99227",
      "optimizer": "1.222225616592047",
      "acc": "0.7933148",
      "loss": "0.6190628991127014"
    },
    "97": {
      "name": 97,
      "learningrate": "0.02431",
      "dropout": "0.28508",
      "epoch": "54.87375",
      "batchsize": "32.84044",
      "optimizer": "1.9689",
      "acc": "0.76503706",
      "loss": "1.9955454070479781"
    }
  },
  "2": {
    "0": {
      "name": 0,
      "learningrate": "0.0017499576501079635",
      "dropout": "0.32852",
      "epoch": "83.82111",
      "batchsize": "42.51638",
      "optimizer": "0.09098897097958736",
      "acc": "0.86396295",
      "loss": "0.62152508020401"
    },
    "1": {
      "name": 1,
      "learningrate": "0.0010744736574577634",
      "dropout": "0.26781",
      "epoch": "53.88089",
      "batchsize": "55.97306",
      "optimizer": "0.3604265970806598",
      "acc": "0.8615185",
      "loss": "0.4764835876579638"
    },
    "2": {
      "name": 2,
      "learningrate": "0.0019972788098930635",
      "dropout": "0.47347",
      "epoch": "99.79678",
      "batchsize": "58.03999",
      "optimizer": "1.9077390021505152",
      "acc": "0.86061114",
      "loss": "0.8086326377518751"
    },
    "3": {
      "name": 3,
      "learningrate": "0.0018801445350574313",
      "dropout": "0.24507",
      "epoch": "55.685",
      "batchsize": "43.72267",
      "optimizer": "0.1644307923814209",
      "acc": "0.8599815",
      "loss": "0.5572910484881313"
    },
    "4": {
      "name": 4,
      "learningrate": "0.002526248889298822",
      "dropout": "0.43405",
      "epoch": "81.28285",
      "batchsize": "42.52684",
      "optimizer": "2.344379380990902",
      "acc": "0.8599259",
      "loss": "0.9003800471496802"
    },
    "5": {
      "name": 5,
      "learningrate": "0.00237",
      "dropout": "0.36487",
      "epoch": "70.32059",
      "batchsize": "50.31001",
      "optimizer": "0.2357917099183312",
      "acc": "0.8583889",
      "loss": "0.550934971080886"
    },
    "6": {
      "name": 6,
      "learningrate": "0.00114",
      "dropout": "0.223",
      "epoch": "82.89288",
      "batchsize": "37.43847",
      "optimizer": "1.8397288403392063",
      "acc": "0.8579074",
      "loss": "0.8801358011524987"
    },
    "7": {
      "name": 7,
      "learningrate": "0.0021263628264993123",
      "dropout": "0.20923",
      "epoch": "82.89006",
      "batchsize": "37.45364",
      "optimizer": "1.9862320692228024",
      "acc": "0.8577963",
      "loss": "0.993695722196941"
    },
    "8": {
      "name": 8,
      "learningrate": "0.007217247314881162",
      "dropout": "0.4006",
      "epoch": "99.81174",
      "batchsize": "35.0032",
      "optimizer": "0.937680911289515",
      "acc": "0.8577778",
      "loss": "0.4066154249465024"
    },
    "9": {
      "name": 9,
      "learningrate": "0.0096701540232603",
      "dropout": "0.0643920968515479",
      "epoch": "75.76121",
      "batchsize": "32.79352",
      "optimizer": "0.7528788977715014",
      "acc": "0.8574259",
      "loss": "0.41182098451808646"
    },
    "10": {
      "name": 10,
      "learningrate": "0.00087",
      "dropout": "0.27161",
      "epoch": "54.87223",
      "batchsize": "32.84277",
      "optimizer": "2.1199263518491427",
      "acc": "0.8572963",
      "loss": "0.6545942214926084"
    },
    "11": {
      "name": 11,
      "learningrate": "0.00853124995035524",
      "dropout": "0.41214",
      "epoch": "99.82621",
      "batchsize": "58.02988",
      "optimizer": "1.4487482212065728",
      "acc": "0.8563333",
      "loss": "0.41025299478901756"
    },
    "12": {
      "name": 12,
      "learningrate": "0.0018082232511929404",
      "dropout": "0.36239",
      "epoch": "99.51337",
      "batchsize": "47.32111",
      "optimizer": "1.7355322703777594",
      "acc": "0.85583335",
      "loss": "0.9617119658953613"
    },
    "13": {
      "name": 13,
      "learningrate": "0.004",
      "dropout": "0.29343",
      "epoch": "70.33292",
      "batchsize": "48.02615",
      "optimizer": "2.101737751980971",
      "acc": "0.85575926",
      "loss": "1.0072672314423101"
    },
    "14": {
      "name": 14,
      "learningrate": "0.00278",
      "dropout": "0.35696",
      "epoch": "90.26915",
      "batchsize": "37.91633",
      "optimizer": "2.18285",
      "acc": "0.85566664",
      "loss": "1.1807811984960679"
    },
    "15": {
      "name": 15,
      "learningrate": "0.008413304798539483",
      "dropout": "0.41154",
      "epoch": "86.60783",
      "batchsize": "47.4871",
      "optimizer": "0.9367593901746303",
      "acc": "0.8550926",
      "loss": "0.41141448663340674"
    },
    "16": {
      "name": 16,
      "learningrate": "0.00357",
      "dropout": "0.25259",
      "epoch": "66.76267",
      "batchsize": "44.92595",
      "optimizer": "2.1867417070715782",
      "acc": "0.8550556",
      "loss": "0.9505377740371559"
    },
    "17": {
      "name": 17,
      "learningrate": "0.009079824532506603",
      "dropout": "0.43236",
      "epoch": "90.2992",
      "batchsize": "37.92098",
      "optimizer": "1.3534131939689162",
      "acc": "0.85503703",
      "loss": "0.41212966400164147"
    },
    "18": {
      "name": 18,
      "learningrate": "0.00673288823264067",
      "dropout": "0.23159",
      "epoch": "98.79214",
      "batchsize": "35.00112",
      "optimizer": "0.5240614646025582",
      "acc": "0.85492593",
      "loss": "0.412207729405827"
    },
    "19": {
      "name": 19,
      "learningrate": "0.008492052378625372",
      "dropout": "0.38269",
      "epoch": "81.74849",
      "batchsize": "55.45321",
      "optimizer": "1.3155715715319574",
      "acc": "0.8536481",
      "loss": "0.4160737076997757"
    },
    "20": {
      "name": 20,
      "learningrate": "0.0028038163406917858",
      "dropout": "0.08592",
      "epoch": "78.45844",
      "batchsize": "35.19304",
      "optimizer": "0.3946770658740558",
      "acc": "0.85346293",
      "loss": "0.8218841530040458"
    },
    "21": {
      "name": 21,
      "learningrate": "0.002220220869853252",
      "dropout": "0.40404",
      "epoch": "54.87502",
      "batchsize": "32.83924",
      "optimizer": "2.4486178100107603",
      "acc": "0.8532407",
      "loss": "0.8056527044171536"
    },
    "22": {
      "name": 22,
      "learningrate": "0.00338",
      "dropout": "0.40369",
      "epoch": "66.60543",
      "batchsize": "48.62861",
      "optimizer": "0.36728395457450425",
      "acc": "0.853",
      "loss": "0.535344228386879"
    },
    "23": {
      "name": 23,
      "learningrate": "0.009579955195137461",
      "dropout": "0.09745",
      "epoch": "50.84715",
      "batchsize": "50.78244",
      "optimizer": "1.3011397102436892",
      "acc": "0.8511852",
      "loss": "0.42910219484346884"
    },
    "24": {
      "name": 24,
      "learningrate": "0.00636",
      "dropout": "0.23449",
      "epoch": "96.00833",
      "batchsize": "55.43351",
      "optimizer": "0.9539837942533779",
      "acc": "0.8510926",
      "loss": "0.4238176888624827"
    },
    "25": {
      "name": 25,
      "learningrate": "0.00938",
      "dropout": "0.25134",
      "epoch": "59.14049",
      "batchsize": "62.54679",
      "optimizer": "0.9172963535286573",
      "acc": "0.850463",
      "loss": "0.43021021255298897"
    },
    "26": {
      "name": 26,
      "learningrate": "0.0051925449865171495",
      "dropout": "0.34759",
      "epoch": "99.5186",
      "batchsize": "47.3077",
      "optimizer": "2.47906531898737",
      "acc": "0.8501296",
      "loss": "1.2695046948445616"
    },
    "27": {
      "name": 27,
      "learningrate": "0.0049456776616011305",
      "dropout": "0.43091",
      "epoch": "96.01669",
      "batchsize": "55.40857",
      "optimizer": "0.41255220854448815",
      "acc": "0.8501111",
      "loss": "0.6272557757739667"
    },
    "28": {
      "name": 28,
      "learningrate": "0.00453388999199052",
      "dropout": "0.2705",
      "epoch": "55.68671",
      "batchsize": "43.72233",
      "optimizer": "0.24938951896276773",
      "acc": "0.84937036",
      "loss": "0.6027819497850206"
    },
    "29": {
      "name": 29,
      "learningrate": "0.0038154755417298784",
      "dropout": "0.07787",
      "epoch": "81.97313",
      "batchsize": "46.97758",
      "optimizer": "0.4571304098827942",
      "acc": "0.84907407",
      "loss": "0.8940241372706713"
    },
    "30": {
      "name": 30,
      "learningrate": "0.003672306603710376",
      "dropout": "0.24801",
      "epoch": "56.91102",
      "batchsize": "35.01624",
      "optimizer": "0.46288816502939045",
      "acc": "0.84875923",
      "loss": "0.5753986089715252"
    },
    "31": {
      "name": 31,
      "learningrate": "0.00397",
      "dropout": "0.30996",
      "epoch": "99.97298",
      "batchsize": "37.90319",
      "optimizer": "1.85809966766646",
      "acc": "0.84875923",
      "loss": "1.3847476706822162"
    },
    "32": {
      "name": 32,
      "learningrate": "0.007477968755608433",
      "dropout": "0.05094",
      "epoch": "89.82392",
      "batchsize": "59.70018",
      "optimizer": "2.380762105112521",
      "acc": "0.84825927",
      "loss": "1.499427681149156"
    },
    "33": {
      "name": 33,
      "learningrate": "0.00466",
      "dropout": "0.43131",
      "epoch": "94.68331",
      "batchsize": "49.44393",
      "optimizer": "1.9097733024440897",
      "acc": "0.8482222",
      "loss": "1.1133325889274754"
    },
    "34": {
      "name": 34,
      "learningrate": "0.0026784539940806302",
      "dropout": "0.08856",
      "epoch": "81.97051",
      "batchsize": "46.95581",
      "optimizer": "0.3267481970816787",
      "acc": "0.8480926",
      "loss": "0.8609745408760177"
    },
    "35": {
      "name": 35,
      "learningrate": "0.00557",
      "dropout": "0.45358",
      "epoch": "90.27787",
      "batchsize": "37.91778",
      "optimizer": "0.5295070148258778",
      "acc": "0.8477963",
      "loss": "0.4303060940724832"
    },
    "36": {
      "name": 36,
      "learningrate": "0.007534936306960997",
      "dropout": "0.16616659114158622",
      "epoch": "52.87687",
      "batchsize": "51.25105",
      "optimizer": "1.1709286337299247",
      "acc": "0.8472963",
      "loss": "0.43867512825241795"
    },
    "37": {
      "name": 37,
      "learningrate": "0.00794",
      "dropout": "0.05998",
      "epoch": "89.8033",
      "batchsize": "59.69594",
      "optimizer": "2.109081493025173",
      "acc": "0.84727776",
      "loss": "1.6198230428756386"
    },
    "38": {
      "name": 38,
      "learningrate": "0.004734748693180382",
      "dropout": "0.15857",
      "epoch": "74.84877",
      "batchsize": "49.651",
      "optimizer": "0.6044916095245673",
      "acc": "0.84712964",
      "loss": "0.44579248212001943"
    },
    "39": {
      "name": 39,
      "learningrate": "0.0055170237893438934",
      "dropout": "0.38971",
      "epoch": "99.55522",
      "batchsize": "32.75612",
      "optimizer": "2.438203116127427",
      "acc": "0.84694445",
      "loss": "1.6437815571835748"
    },
    "40": {
      "name": 40,
      "learningrate": "0.0050986806117344595",
      "dropout": "0.23629",
      "epoch": "66.73187",
      "batchsize": "44.94677",
      "optimizer": "2.2664383253055553",
      "acc": "0.8469259",
      "loss": "1.1615062995045273"
    },
    "41": {
      "name": 41,
      "learningrate": "0.004142293518429293",
      "dropout": "0.38285",
      "epoch": "99.53908",
      "batchsize": "37.89585",
      "optimizer": "1.2785532378951254",
      "acc": "0.8465185",
      "loss": "0.44202059140470296"
    },
    "42": {
      "name": 42,
      "learningrate": "0.00749",
      "dropout": "0.44697",
      "epoch": "90.28636",
      "batchsize": "37.93009",
      "optimizer": "2.664118747769496",
      "acc": "0.8464444",
      "loss": "0.43053643483144266"
    },
    "43": {
      "name": 43,
      "learningrate": "0.005974827934812467",
      "dropout": "0.25707",
      "epoch": "76.81456",
      "batchsize": "46.99176",
      "optimizer": "2.112640455404464",
      "acc": "0.8463889",
      "loss": "1.1988453515790127"
    },
    "44": {
      "name": 44,
      "learningrate": "0.009768464966793641",
      "dropout": "0.09145",
      "epoch": "50.89099",
      "batchsize": "48.44449",
      "optimizer": "0.18104665133545073",
      "acc": "0.8461111",
      "loss": "0.6616002316695673"
    },
    "45": {
      "name": 45,
      "learningrate": "0.003770004496747874",
      "dropout": "0.32933",
      "epoch": "83.81044",
      "batchsize": "42.52332",
      "optimizer": "0.7553058136034098",
      "acc": "0.84596294",
      "loss": "0.44699531567979744"
    },
    "46": {
      "name": 46,
      "learningrate": "0.00452",
      "dropout": "0.34994",
      "epoch": "99.8153",
      "batchsize": "58.04503",
      "optimizer": "1.1547715357631998",
      "acc": "0.84562963",
      "loss": "0.44063292186790043"
    },
    "47": {
      "name": 47,
      "learningrate": "0.0067",
      "dropout": "0.36088",
      "epoch": "56.27368",
      "batchsize": "49.51236",
      "optimizer": "0.7758486003484082",
      "acc": "0.8455741",
      "loss": "0.4464599848235095"
    },
    "48": {
      "name": 48,
      "learningrate": "0.0037176261061535936",
      "dropout": "0.12488",
      "epoch": "81.26595",
      "batchsize": "44.90333",
      "optimizer": "0.789729668398002",
      "acc": "0.8446481",
      "loss": "0.45429413303622496"
    },
    "49": {
      "name": 49,
      "learningrate": "0.0075922817212551",
      "dropout": "0.22538",
      "epoch": "96.00936",
      "batchsize": "55.42927",
      "optimizer": "2.874988022054986",
      "acc": "0.84394443",
      "loss": "0.44369336571075296"
    },
    "50": {
      "name": 50,
      "learningrate": "0.0034",
      "dropout": "0.21095",
      "epoch": "82.89069",
      "batchsize": "37.45568",
      "optimizer": "0.6278448203964497",
      "acc": "0.8437037",
      "loss": "0.45618004137939877"
    },
    "51": {
      "name": 51,
      "learningrate": "0.00758471630210863",
      "dropout": "0.27621",
      "epoch": "59.12716",
      "batchsize": "62.58182",
      "optimizer": "1.0834273812644397",
      "acc": "0.8436852",
      "loss": "0.445325167744248"
    },
    "52": {
      "name": 52,
      "learningrate": "0.005661771818132561",
      "dropout": "0.42533",
      "epoch": "66.76386",
      "batchsize": "49.43394",
      "optimizer": "0.3960775488591952",
      "acc": "0.8434259",
      "loss": "0.6237001698966379"
    },
    "53": {
      "name": 53,
      "learningrate": "0.0036672063875435768",
      "dropout": "0.17309",
      "epoch": "75.75459",
      "batchsize": "37.89671",
      "optimizer": "2.421972050992351",
      "acc": "0.84312963",
      "loss": "1.5101205705696785"
    },
    "54": {
      "name": 54,
      "learningrate": "0.007187822912759415",
      "dropout": "0.40834",
      "epoch": "54.86226",
      "batchsize": "37.89212",
      "optimizer": "0.40912269697039105",
      "acc": "0.8429259",
      "loss": "0.6027882583825677"
    },
    "55": {
      "name": 55,
      "learningrate": "0.005693919997433242",
      "dropout": "0.45636",
      "epoch": "90.29406",
      "batchsize": "37.92487",
      "optimizer": "2.6313766921168043",
      "acc": "0.8428889",
      "loss": "0.44846556678524724"
    },
    "56": {
      "name": 56,
      "learningrate": "0.0074740837113283585",
      "dropout": "0.29164",
      "epoch": "54.89325",
      "batchsize": "32.83283",
      "optimizer": "2.805302026620397",
      "acc": "0.8428148",
      "loss": "0.455953792364509"
    },
    "57": {
      "name": 57,
      "learningrate": "0.007829271451255518",
      "dropout": "0.28246",
      "epoch": "59.14949",
      "batchsize": "62.59224",
      "optimizer": "2.045406178664188",
      "acc": "0.84231484",
      "loss": "1.0322417352552766"
    },
    "58": {
      "name": 58,
      "learningrate": "0.006665203603849165",
      "dropout": "0.45012",
      "epoch": "97.8164",
      "batchsize": "59.54685",
      "optimizer": "2.2949049774409938",
      "acc": "0.84205556",
      "loss": "1.248732846311949"
    },
    "59": {
      "name": 59,
      "learningrate": "0.0049",
      "dropout": "0.21657",
      "epoch": "99.1775",
      "batchsize": "46.96197",
      "optimizer": "2.559687822928884",
      "acc": "0.8415",
      "loss": "0.4598380582774127"
    },
    "60": {
      "name": 60,
      "learningrate": "0.00834",
      "dropout": "0.13489",
      "epoch": "83.81292",
      "batchsize": "42.53276",
      "optimizer": "0.3065194629942478",
      "acc": "0.8414074",
      "loss": "0.7840638997466476"
    },
    "61": {
      "name": 61,
      "learningrate": "0.00526",
      "dropout": "0.45652",
      "epoch": "90.29403",
      "batchsize": "37.92544",
      "optimizer": "2.6558639363971905",
      "acc": "0.8405741",
      "loss": "0.45582726778365945"
    },
    "62": {
      "name": 62,
      "learningrate": "0.00807",
      "dropout": "0.43422",
      "epoch": "96.01179",
      "batchsize": "55.41315",
      "optimizer": "1.5635023798359953",
      "acc": "0.8404259",
      "loss": "1.3469935512769002"
    },
    "63": {
      "name": 63,
      "learningrate": "0.003511733319461981",
      "dropout": "0.26549",
      "epoch": "74.7277",
      "batchsize": "40.58586",
      "optimizer": "1.4719195970296575",
      "acc": "0.83951855",
      "loss": "0.4676013206331818"
    },
    "64": {
      "name": 64,
      "learningrate": "0.009601856246312681",
      "dropout": "0.33353",
      "epoch": "79.89608",
      "batchsize": "44.48157",
      "optimizer": "0.37994718848272346",
      "acc": "0.8390926",
      "loss": "0.7438598038918443"
    },
    "65": {
      "name": 65,
      "learningrate": "0.004303614539028705",
      "dropout": "0.2335",
      "epoch": "99.20203",
      "batchsize": "46.97134",
      "optimizer": "2.6959452609363304",
      "acc": "0.83883333",
      "loss": "0.4664191625957136"
    },
    "66": {
      "name": 66,
      "learningrate": "0.00684",
      "dropout": "0.27207",
      "epoch": "99.55573",
      "batchsize": "48.6336",
      "optimizer": "0.19481308082632798",
      "acc": "0.837963",
      "loss": "0.8505567269821962"
    },
    "67": {
      "name": 67,
      "learningrate": "0.00917",
      "dropout": "0.21997",
      "epoch": "99.19081",
      "batchsize": "46.95495",
      "optimizer": "1.8100936894731192",
      "acc": "0.83694446",
      "loss": "1.7769222742684738"
    },
    "68": {
      "name": 68,
      "learningrate": "0.005668914816153687",
      "dropout": "0.23036",
      "epoch": "76.28851",
      "batchsize": "44.68902",
      "optimizer": "2.7430406068534756",
      "acc": "0.8366296",
      "loss": "0.47326945838221796"
    },
    "69": {
      "name": 69,
      "learningrate": "0.00872",
      "dropout": "0.11428",
      "epoch": "66.75339",
      "batchsize": "44.92748",
      "optimizer": "2.231505351374499",
      "acc": "0.83603704",
      "loss": "1.4328294214534538"
    },
    "70": {
      "name": 70,
      "learningrate": "0.00918",
      "dropout": "0.35686",
      "epoch": "52.78667",
      "batchsize": "50.28795",
      "optimizer": "0.17758044354203506",
      "acc": "0.8356481",
      "loss": "0.6153855450914966"
    },
    "71": {
      "name": 71,
      "learningrate": "0.009553384332703278",
      "dropout": "0.05988",
      "epoch": "52.89083",
      "batchsize": "51.26445",
      "optimizer": "1.8279507491869316",
      "acc": "0.8350185",
      "loss": "1.139388219345499"
    },
    "72": {
      "name": 72,
      "learningrate": "0.008979080458756597",
      "dropout": "0.16673029077849733",
      "epoch": "52.87651",
      "batchsize": "51.24927",
      "optimizer": "2.7576082596889178",
      "acc": "0.83474076",
      "loss": "0.4785215273521565"
    },
    "73": {
      "name": 73,
      "learningrate": "0.007796148063182361",
      "dropout": "0.13188",
      "epoch": "87.82491",
      "batchsize": "34.8441",
      "optimizer": "0.17359130116911659",
      "acc": "0.8343889",
      "loss": "0.9765607759102627"
    },
    "74": {
      "name": 74,
      "learningrate": "0.007816146416888613",
      "dropout": "0.20301107310068994",
      "epoch": "75.77133",
      "batchsize": "32.7808",
      "optimizer": "0.041409962237689224",
      "acc": "0.8337407",
      "loss": "0.773778079804447"
    },
    "75": {
      "name": 75,
      "learningrate": "0.009376292468295532",
      "dropout": "0.35909",
      "epoch": "81.74117",
      "batchsize": "58.2865",
      "optimizer": "1.6756260928602336",
      "acc": "0.83353704",
      "loss": "1.2495637682897074"
    },
    "76": {
      "name": 76,
      "learningrate": "0.0031194721324198",
      "dropout": "0.43668",
      "epoch": "66.6085",
      "batchsize": "47.30274",
      "optimizer": "0.7414573751133856",
      "acc": "0.83316666",
      "loss": "0.4896120282014211"
    },
    "77": {
      "name": 77,
      "learningrate": "0.007988826990139673",
      "dropout": "0.25116",
      "epoch": "59.156",
      "batchsize": "62.54373",
      "optimizer": "2.7024142640509368",
      "acc": "0.83305556",
      "loss": "0.48495070224338105"
    },
    "78": {
      "name": 78,
      "learningrate": "0.0077564475618845385",
      "dropout": "0.25059",
      "epoch": "99.19094",
      "batchsize": "46.95535",
      "optimizer": "2.331411032679482",
      "acc": "0.8329074",
      "loss": "1.8618525490076454"
    },
    "79": {
      "name": 79,
      "learningrate": "0.007796259778530422",
      "dropout": "0.08653",
      "epoch": "50.84528",
      "batchsize": "46.97536",
      "optimizer": "1.9663112691290239",
      "acc": "0.8325185",
      "loss": "1.1599794570317974"
    },
    "80": {
      "name": 80,
      "learningrate": "0.007894385327486689",
      "dropout": "0.4081",
      "epoch": "83.81761",
      "batchsize": "49.41835",
      "optimizer": "2.1414799190840794",
      "acc": "0.8322037",
      "loss": "1.4940829857499511"
    },
    "81": {
      "name": 81,
      "learningrate": "0.008980681161044758",
      "dropout": "0.22211",
      "epoch": "52.75325",
      "batchsize": "63.74303",
      "optimizer": "2.593691690827655",
      "acc": "0.83194447",
      "loss": "0.4868564173998656"
    },
    "82": {
      "name": 82,
      "learningrate": "0.007173043058974732",
      "dropout": "0.46109",
      "epoch": "99.79384",
      "batchsize": "58.0419",
      "optimizer": "1.7595753585518272",
      "acc": "0.83194447",
      "loss": "1.6090205577159369"
    },
    "83": {
      "name": 83,
      "learningrate": "0.007515201743410449",
      "dropout": "0.25878",
      "epoch": "76.81221",
      "batchsize": "46.98973",
      "optimizer": "1.9136465229335977",
      "acc": "0.8318148",
      "loss": "1.537688138042335"
    },
    "84": {
      "name": 84,
      "learningrate": "0.004716737247079075",
      "dropout": "0.41139",
      "epoch": "81.27138",
      "batchsize": "49.42926",
      "optimizer": "2.891810252612567",
      "acc": "0.8311296",
      "loss": "0.49219942801970024"
    },
    "85": {
      "name": 85,
      "learningrate": "0.00213",
      "dropout": "0.42929",
      "epoch": "82.89019",
      "batchsize": "37.43502",
      "optimizer": "0.9908239463553254",
      "acc": "0.831",
      "loss": "0.5012550911726775"
    },
    "86": {
      "name": 86,
      "learningrate": "0.00278",
      "dropout": "0.35696",
      "epoch": "90.26915",
      "batchsize": "37.91633",
      "optimizer": "2.9291483468120916",
      "acc": "0.83005553",
      "loss": "0.495996631692957"
    },
    "87": {
      "name": 87,
      "learningrate": "0.00635",
      "dropout": "0.27171",
      "epoch": "56.89765",
      "batchsize": "59.76808",
      "optimizer": "2.6764645203105046",
      "acc": "0.82964814",
      "loss": "0.5051627566726119"
    },
    "88": {
      "name": 88,
      "learningrate": "0.0037136374251888916",
      "dropout": "0.4994",
      "epoch": "75.77317",
      "batchsize": "37.89947",
      "optimizer": "2.597101218440832",
      "acc": "0.8274259",
      "loss": "0.5019963658650716"
    },
    "89": {
      "name": 89,
      "learningrate": "0.009629177055374192",
      "dropout": "0.24862",
      "epoch": "76.29099",
      "batchsize": "44.67822",
      "optimizer": "0.32844962807763023",
      "acc": "0.82659256",
      "loss": "0.7611696320948778"
    },
    "90": {
      "name": 90,
      "learningrate": "0.00884",
      "dropout": "0.13333",
      "epoch": "56.57816",
      "batchsize": "46.30477",
      "optimizer": "1.5608080589706714",
      "acc": "0.82633334",
      "loss": "1.3923024787199165"
    },
    "91": {
      "name": 91,
      "learningrate": "0.0021241684118314622",
      "dropout": "0.3722",
      "epoch": "81.73813",
      "batchsize": "58.27725",
      "optimizer": "0.7840592712790481",
      "acc": "0.8260555",
      "loss": "0.5204821864852199"
    },
    "92": {
      "name": 92,
      "learningrate": "0.0020814460331728957",
      "dropout": "0.089",
      "epoch": "52.88751",
      "batchsize": "51.29117",
      "optimizer": "0.7654658131548612",
      "acc": "0.82416666",
      "loss": "0.5275273044639164"
    },
    "93": {
      "name": 93,
      "learningrate": "0.0052586735839247264",
      "dropout": "0.26999",
      "epoch": "56.90431",
      "batchsize": "59.759",
      "optimizer": "2.5353926729125815",
      "acc": "0.82398146",
      "loss": "0.5204440179224368"
    },
    "94": {
      "name": 94,
      "learningrate": "0.00168",
      "dropout": "0.13117",
      "epoch": "74.84686",
      "batchsize": "49.65027",
      "optimizer": "0.6069422148446917",
      "acc": "0.82170373",
      "loss": "0.5296140403129437"
    },
    "95": {
      "name": 95,
      "learningrate": "0.0009397910303547767",
      "dropout": "0.41785",
      "epoch": "86.59597",
      "batchsize": "47.48772",
      "optimizer": "0.8306251545508464",
      "acc": "0.8004074",
      "loss": "0.6061451922081135"
    },
    "96": {
      "name": 96,
      "learningrate": "0.00088",
      "dropout": "0.18737",
      "epoch": "68.56374",
      "batchsize": "58.29604",
      "optimizer": "0.9139881857255009",
      "acc": "0.79101855",
      "loss": "0.6241359808180067"
    },
    "97": {
      "name": 97,
      "learningrate": "0.0015877994881267699",
      "dropout": "0.2507568037238139",
      "epoch": "52.88521",
      "batchsize": "51.2617",
      "optimizer": "2.5439300500254607",
      "acc": "0.7815741",
      "loss": "0.6625622092706186"
    }
  },
  "3": {
    "0": {
      "name": 0,
      "learningrate": "0.0005433672601452142",
      "dropout": "0.44285",
      "epoch": "94.68204",
      "batchsize": "37.43865",
      "optimizer": "1.7424363358783563",
      "acc": "0.86377776",
      "loss": "0.5735626117620203"
    },
    "1": {
      "name": 1,
      "learningrate": "0.0017499576501079635",
      "dropout": "0.32852",
      "epoch": "83.82111",
      "batchsize": "42.51638",
      "optimizer": "0.09098897097958736",
      "acc": "0.86216664",
      "loss": "0.6284999275190962"
    },
    "2": {
      "name": 2,
      "learningrate": "0.001593786921762549",
      "dropout": "0.42593",
      "epoch": "99.18645",
      "batchsize": "47.48577",
      "optimizer": "0.3722194113236388",
      "acc": "0.86175925",
      "loss": "0.6396395218074322"
    },
    "3": {
      "name": 3,
      "learningrate": "0.009668833460945828",
      "dropout": "0.23911",
      "epoch": "98.79276",
      "batchsize": "34.9937",
      "optimizer": "1.093309580522848",
      "acc": "0.86164814",
      "loss": "0.40330847678802634"
    },
    "4": {
      "name": 4,
      "learningrate": "0.001890631401351253",
      "dropout": "0.16435",
      "epoch": "75.73248",
      "batchsize": "46.99369",
      "optimizer": "0.3972342733947122",
      "acc": "0.86101854",
      "loss": "0.6910177041286671"
    },
    "5": {
      "name": 5,
      "learningrate": "0.0014754333703039103",
      "dropout": "0.2168",
      "epoch": "82.88947",
      "batchsize": "59.70912",
      "optimizer": "0.24703575358803698",
      "acc": "0.8601852",
      "loss": "0.6262430513821267"
    },
    "6": {
      "name": 6,
      "learningrate": "0.0022280368796481504",
      "dropout": "0.18568",
      "epoch": "75.7499",
      "batchsize": "44.95478",
      "optimizer": "1.7319350036357082",
      "acc": "0.8595185",
      "loss": "0.9381600077345416"
    },
    "7": {
      "name": 7,
      "learningrate": "0.00113",
      "dropout": "0.255",
      "epoch": "90.29278",
      "batchsize": "37.9333",
      "optimizer": "1.9504003886447339",
      "acc": "0.8591296",
      "loss": "0.8670580586978682"
    },
    "8": {
      "name": 8,
      "learningrate": "0.0031",
      "dropout": "0.16138",
      "epoch": "99.55879",
      "batchsize": "51.239",
      "optimizer": "0.1605415165145082",
      "acc": "0.85907406",
      "loss": "0.7536897227107375"
    },
    "9": {
      "name": 9,
      "learningrate": "0.0029493773985151857",
      "dropout": "0.34611",
      "epoch": "79.89639",
      "batchsize": "44.48396",
      "optimizer": "1.5699519712258536",
      "acc": "0.85870373",
      "loss": "1.0473421881055391"
    },
    "10": {
      "name": 10,
      "learningrate": "0.003583748885077467",
      "dropout": "0.22451",
      "epoch": "96.00374",
      "batchsize": "55.42443",
      "optimizer": "2.342427301746806",
      "acc": "0.8581667",
      "loss": "1.2066222479001238"
    },
    "11": {
      "name": 11,
      "learningrate": "0.001886534737120305",
      "dropout": "0.08876",
      "epoch": "81.25434",
      "batchsize": "44.90891",
      "optimizer": "0.34994360269713765",
      "acc": "0.85814816",
      "loss": "0.7939097840940511"
    },
    "12": {
      "name": 12,
      "learningrate": "0.00317",
      "dropout": "0.26629",
      "epoch": "59.1392",
      "batchsize": "62.58741",
      "optimizer": "2.449254979063724",
      "acc": "0.8574259",
      "loss": "0.8611841912324781"
    },
    "13": {
      "name": 13,
      "learningrate": "0.0010744736574577634",
      "dropout": "0.26781",
      "epoch": "53.88089",
      "batchsize": "55.97306",
      "optimizer": "0.3604265970806598",
      "acc": "0.8574074",
      "loss": "0.53033170443111"
    },
    "14": {
      "name": 14,
      "learningrate": "0.007552083415173029",
      "dropout": "0.10429",
      "epoch": "81.97012",
      "batchsize": "48.61654",
      "optimizer": "1.4591992860600782",
      "acc": "0.85635185",
      "loss": "0.41753858764524815"
    },
    "15": {
      "name": 15,
      "learningrate": "0.009389963250944138",
      "dropout": "0.10949",
      "epoch": "81.23687",
      "batchsize": "44.90219",
      "optimizer": "1.307564786815195",
      "acc": "0.8562222",
      "loss": "0.41279909484033234"
    },
    "16": {
      "name": 16,
      "learningrate": "0.0023861452011397087",
      "dropout": "0.23135",
      "epoch": "82.88999",
      "batchsize": "37.44884",
      "optimizer": "2.099187248206477",
      "acc": "0.85564816",
      "loss": "1.15036201250222"
    },
    "17": {
      "name": 17,
      "learningrate": "0.0027011346668718095",
      "dropout": "0.25292",
      "epoch": "66.77498",
      "batchsize": "44.92571",
      "optimizer": "0.2887324725964996",
      "acc": "0.85544443",
      "loss": "0.6521397009900323"
    },
    "18": {
      "name": 18,
      "learningrate": "0.0033744448949032647",
      "dropout": "0.28411",
      "epoch": "54.87736",
      "batchsize": "44.92248",
      "optimizer": "1.9921569500509473",
      "acc": "0.8550556",
      "loss": "0.8974909467597803"
    },
    "19": {
      "name": 19,
      "learningrate": "0.00806",
      "dropout": "0.33979",
      "epoch": "83.81562",
      "batchsize": "42.53103",
      "optimizer": "0.9420782373871274",
      "acc": "0.85503703",
      "loss": "0.4146773916416698"
    },
    "20": {
      "name": 20,
      "learningrate": "0.004084973611812504",
      "dropout": "0.24189",
      "epoch": "66.72172",
      "batchsize": "44.95641",
      "optimizer": "0.3733969533709911",
      "acc": "0.8540556",
      "loss": "0.6656925573194469"
    },
    "21": {
      "name": 21,
      "learningrate": "0.007042063496794667",
      "dropout": "0.23223",
      "epoch": "96.01775",
      "batchsize": "55.42228",
      "optimizer": "1.0499156353804229",
      "acc": "0.8538333",
      "loss": "0.4197843298735442"
    },
    "22": {
      "name": 22,
      "learningrate": "0.00860341074848479",
      "dropout": "0.06352",
      "epoch": "75.75448",
      "batchsize": "48.63435",
      "optimizer": "1.1064740402855762",
      "acc": "0.8537037",
      "loss": "0.4210881405406528"
    },
    "23": {
      "name": 23,
      "learningrate": "0.006902584503257371",
      "dropout": "0.18009",
      "epoch": "75.75267",
      "batchsize": "37.90456",
      "optimizer": "0.7585643151408904",
      "acc": "0.85366666",
      "loss": "0.4217484006660956"
    },
    "24": {
      "name": 24,
      "learningrate": "0.00796437929713992",
      "dropout": "0.47878",
      "epoch": "99.81949",
      "batchsize": "58.02282",
      "optimizer": "1.4649598012589113",
      "acc": "0.8535",
      "loss": "0.4172379973994361"
    },
    "25": {
      "name": 25,
      "learningrate": "0.00815",
      "dropout": "0.09273",
      "epoch": "81.96934",
      "batchsize": "48.61709",
      "optimizer": "1.106607487660579",
      "acc": "0.8529815",
      "loss": "0.42551603602480004"
    },
    "26": {
      "name": 26,
      "learningrate": "0.006006273640295637",
      "dropout": "0.0574",
      "epoch": "75.74739",
      "batchsize": "46.95973",
      "optimizer": "1.5602407013461952",
      "acc": "0.8529815",
      "loss": "1.5184144391469934"
    },
    "27": {
      "name": 27,
      "learningrate": "0.0035613308670755573",
      "dropout": "0.2384",
      "epoch": "98.77482",
      "batchsize": "34.97774",
      "optimizer": "1.6555544497656594",
      "acc": "0.85285187",
      "loss": "1.523468421946521"
    },
    "28": {
      "name": 28,
      "learningrate": "0.0069",
      "dropout": "0.16911",
      "epoch": "75.72531",
      "batchsize": "37.9057",
      "optimizer": "1.1575951706944165",
      "acc": "0.85285187",
      "loss": "0.42038936434410235"
    },
    "29": {
      "name": 29,
      "learningrate": "0.004730810392523521",
      "dropout": "0.31085",
      "epoch": "99.98122",
      "batchsize": "37.89603",
      "optimizer": "0.2755811691620337",
      "acc": "0.8527222",
      "loss": "0.7740183415608826"
    },
    "30": {
      "name": 30,
      "learningrate": "0.004320368454181948",
      "dropout": "0.39897",
      "epoch": "82.88269",
      "batchsize": "59.70157",
      "optimizer": "1.5630014580716918",
      "acc": "0.8524815",
      "loss": "0.9936869615051481"
    },
    "31": {
      "name": 31,
      "learningrate": "0.007110754802582556",
      "dropout": "0.26405",
      "epoch": "76.82649",
      "batchsize": "46.97533",
      "optimizer": "0.8878676771934965",
      "acc": "0.85235184",
      "loss": "0.42403920993981536"
    },
    "32": {
      "name": 32,
      "learningrate": "0.00578987583026342",
      "dropout": "0.27926",
      "epoch": "99.55302",
      "batchsize": "32.79403",
      "optimizer": "0.8257698399840856",
      "acc": "0.8521482",
      "loss": "0.4198893500257421"
    },
    "33": {
      "name": 33,
      "learningrate": "0.008349389969255206",
      "dropout": "0.10238",
      "epoch": "66.74763",
      "batchsize": "32.78241",
      "optimizer": "1.0386989386962246",
      "acc": "0.8521111",
      "loss": "0.4216869640438645"
    },
    "34": {
      "name": 34,
      "learningrate": "0.0034933692470870826",
      "dropout": "0.21115",
      "epoch": "66.59638",
      "batchsize": "48.58654",
      "optimizer": "0.3813131413625821",
      "acc": "0.8514074",
      "loss": "0.6788089404172367"
    },
    "35": {
      "name": 35,
      "learningrate": "0.00648",
      "dropout": "0.17519",
      "epoch": "66.77169",
      "batchsize": "44.92598",
      "optimizer": "0.3544161068241414",
      "acc": "0.8508889",
      "loss": "0.7048319791919655"
    },
    "36": {
      "name": 36,
      "learningrate": "0.009358922160792864",
      "dropout": "0.35709",
      "epoch": "56.26634",
      "batchsize": "49.52473",
      "optimizer": "1.3826720382941065",
      "acc": "0.8507963",
      "loss": "0.42579988810751174"
    },
    "37": {
      "name": 37,
      "learningrate": "0.00462",
      "dropout": "0.41713",
      "epoch": "66.78106",
      "batchsize": "46.96451",
      "optimizer": "2.044091868506822",
      "acc": "0.8502778",
      "loss": "0.9197416921302124"
    },
    "38": {
      "name": 38,
      "learningrate": "0.004280440154689262",
      "dropout": "0.09534",
      "epoch": "99.80763",
      "batchsize": "35.20384",
      "optimizer": "0.7532445319916156",
      "acc": "0.85007405",
      "loss": "0.43443440673527894"
    },
    "39": {
      "name": 39,
      "learningrate": "0.00421",
      "dropout": "0.42995",
      "epoch": "94.67941",
      "batchsize": "59.7009",
      "optimizer": "2.3292307283721345",
      "acc": "0.84966666",
      "loss": "1.1018776578519631"
    },
    "40": {
      "name": 40,
      "learningrate": "0.00636",
      "dropout": "0.10552",
      "epoch": "99.797",
      "batchsize": "35.19721",
      "optimizer": "2.0851900020471796",
      "acc": "0.8492407",
      "loss": "1.974113893205093"
    },
    "41": {
      "name": 41,
      "learningrate": "0.00954",
      "dropout": "0.20945",
      "epoch": "75.78061",
      "batchsize": "44.93025",
      "optimizer": "2.515549519300134",
      "acc": "0.8482222",
      "loss": "0.4366130240449199"
    },
    "42": {
      "name": 42,
      "learningrate": "0.004452059996929292",
      "dropout": "0.2725",
      "epoch": "99.53151",
      "batchsize": "32.80907",
      "optimizer": "0.35346487997343445",
      "acc": "0.84805554",
      "loss": "0.8011359122925334"
    },
    "43": {
      "name": 43,
      "learningrate": "0.00858",
      "dropout": "0.22374",
      "epoch": "76.28229",
      "batchsize": "44.68191",
      "optimizer": "2.627812235574723",
      "acc": "0.8476111",
      "loss": "0.43963794394334155"
    },
    "44": {
      "name": 44,
      "learningrate": "0.004499195472753381",
      "dropout": "0.26505",
      "epoch": "76.82982",
      "batchsize": "46.96322",
      "optimizer": "1.0003718703323765",
      "acc": "0.8467037",
      "loss": "0.4435122060422544"
    },
    "45": {
      "name": 45,
      "learningrate": "0.00751189786476048",
      "dropout": "0.35399",
      "epoch": "99.80082",
      "batchsize": "58.05455",
      "optimizer": "1.7494494029900554",
      "acc": "0.84655553",
      "loss": "1.390708448631896"
    },
    "46": {
      "name": 46,
      "learningrate": "0.007379110089711004",
      "dropout": "0.06189",
      "epoch": "81.96213",
      "batchsize": "37.91448",
      "optimizer": "2.7199154491216273",
      "acc": "0.84646297",
      "loss": "0.4428466683361265"
    },
    "47": {
      "name": 47,
      "learningrate": "0.008108748154456022",
      "dropout": "0.07744",
      "epoch": "81.9592",
      "batchsize": "48.61255",
      "optimizer": "1.8083239023612183",
      "acc": "0.8462037",
      "loss": "1.7108431470029883"
    },
    "48": {
      "name": 48,
      "learningrate": "0.00749",
      "dropout": "0.24185",
      "epoch": "86.59859",
      "batchsize": "46.96973",
      "optimizer": "0.01552096366163025",
      "acc": "0.84614813",
      "loss": "0.6903784103139683"
    },
    "49": {
      "name": 49,
      "learningrate": "0.005661110217056245",
      "dropout": "0.26472",
      "epoch": "55.69188",
      "batchsize": "43.73408",
      "optimizer": "0.7091726207034496",
      "acc": "0.8458148",
      "loss": "0.4436781938031868"
    },
    "50": {
      "name": 50,
      "learningrate": "0.004095522218383305",
      "dropout": "0.17876",
      "epoch": "66.77451",
      "batchsize": "32.85403",
      "optimizer": "0.7717651959947212",
      "acc": "0.8456111",
      "loss": "0.4480544818948816"
    },
    "51": {
      "name": 51,
      "learningrate": "0.0013378635973233634",
      "dropout": "0.35373",
      "epoch": "90.26127",
      "batchsize": "37.91118",
      "optimizer": "1.9517585192477105",
      "acc": "0.845463",
      "loss": "0.9142134573349247"
    },
    "52": {
      "name": 52,
      "learningrate": "0.007275579444368279",
      "dropout": "0.33576",
      "epoch": "83.8043",
      "batchsize": "42.52595",
      "optimizer": "2.8374160268695467",
      "acc": "0.8452037",
      "loss": "0.44434575854848934"
    },
    "53": {
      "name": 53,
      "learningrate": "0.006781909579290821",
      "dropout": "0.29892",
      "epoch": "50.87011",
      "batchsize": "50.77247",
      "optimizer": "1.4911375392753012",
      "acc": "0.8442778",
      "loss": "0.4490536890294817"
    },
    "54": {
      "name": 54,
      "learningrate": "0.00423",
      "dropout": "0.40757",
      "epoch": "90.30029",
      "batchsize": "37.92806",
      "optimizer": "1.4917148409080183",
      "acc": "0.8435",
      "loss": "0.4461061965977704"
    },
    "55": {
      "name": 55,
      "learningrate": "0.003855039850953474",
      "dropout": "0.08612816852297275",
      "epoch": "75.75007",
      "batchsize": "46.96439",
      "optimizer": "0.8030122932186419",
      "acc": "0.8432593",
      "loss": "0.460315319025958"
    },
    "56": {
      "name": 56,
      "learningrate": "0.009256456003911335",
      "dropout": "0.20594",
      "epoch": "66.59775",
      "batchsize": "48.59757",
      "optimizer": "2.9984068922924534",
      "acc": "0.8429259",
      "loss": "0.4531221121152242"
    },
    "57": {
      "name": 57,
      "learningrate": "0.004855251824877685",
      "dropout": "0.39718",
      "epoch": "78.43982",
      "batchsize": "58.03561",
      "optimizer": "0.9859307248571815",
      "acc": "0.84253705",
      "loss": "0.4529964594531942"
    },
    "58": {
      "name": 58,
      "learningrate": "0.00342",
      "dropout": "0.07378",
      "epoch": "81.98314",
      "batchsize": "46.97236",
      "optimizer": "1.201612448190302",
      "acc": "0.8423704",
      "loss": "0.4616072549201824"
    },
    "59": {
      "name": 59,
      "learningrate": "0.00482766664467873",
      "dropout": "0.34487",
      "epoch": "52.79219",
      "batchsize": "50.2873",
      "optimizer": "0.10040316344101474",
      "acc": "0.84153706",
      "loss": "0.5772967087692684"
    },
    "60": {
      "name": 60,
      "learningrate": "0.00689",
      "dropout": "0.27682",
      "epoch": "54.8823",
      "batchsize": "32.84357",
      "optimizer": "2.9439536180240635",
      "acc": "0.8412963",
      "loss": "0.45323076830969916"
    },
    "61": {
      "name": 61,
      "learningrate": "0.00596",
      "dropout": "0.3894",
      "epoch": "54.86435",
      "batchsize": "37.87446",
      "optimizer": "2.1719291451664624",
      "acc": "0.84125924",
      "loss": "1.0109857944595042"
    },
    "62": {
      "name": 62,
      "learningrate": "0.006384798207392838",
      "dropout": "0.22196",
      "epoch": "82.89867",
      "batchsize": "37.45918",
      "optimizer": "2.20409504819854",
      "acc": "0.84114814",
      "loss": "1.5418941250686293"
    },
    "63": {
      "name": 63,
      "learningrate": "0.008686033511846096",
      "dropout": "0.10931",
      "epoch": "66.73793",
      "batchsize": "32.78745",
      "optimizer": "0.27098878847917673",
      "acc": "0.84107405",
      "loss": "0.7679973114218425"
    },
    "64": {
      "name": 64,
      "learningrate": "0.00662",
      "dropout": "0.05922",
      "epoch": "81.97884",
      "batchsize": "46.97907",
      "optimizer": "0.2461963161984001",
      "acc": "0.84085184",
      "loss": "0.8843568904245341"
    },
    "65": {
      "name": 65,
      "learningrate": "0.007830201668121149",
      "dropout": "0.42368",
      "epoch": "81.27951",
      "batchsize": "49.45358",
      "optimizer": "1.9643004864511933",
      "acc": "0.8407037",
      "loss": "1.3966352855232027"
    },
    "66": {
      "name": 66,
      "learningrate": "0.00275",
      "dropout": "0.25808",
      "epoch": "59.14155",
      "batchsize": "62.52364",
      "optimizer": "2.1257997000091073",
      "acc": "0.8406111",
      "loss": "0.8695121689339479"
    },
    "67": {
      "name": 67,
      "learningrate": "0.0037340761719452946",
      "dropout": "0.42714",
      "epoch": "66.77734",
      "batchsize": "46.96145",
      "optimizer": "2.4228739788165394",
      "acc": "0.84055555",
      "loss": "0.999112376479087"
    },
    "68": {
      "name": 68,
      "learningrate": "0.002591803104724626",
      "dropout": "0.09138",
      "epoch": "70.34879",
      "batchsize": "48.0094",
      "optimizer": "0.3273709645783123",
      "acc": "0.83974075",
      "loss": "0.7512572303044576"
    },
    "69": {
      "name": 69,
      "learningrate": "0.00879184299945145",
      "dropout": "0.43391",
      "epoch": "99.19787",
      "batchsize": "47.48203",
      "optimizer": "1.8772315804237165",
      "acc": "0.8396852",
      "loss": "1.721231438188641"
    },
    "70": {
      "name": 70,
      "learningrate": "0.005698186854452754",
      "dropout": "0.4381887577909111",
      "epoch": "89.83521",
      "batchsize": "49.45661",
      "optimizer": "2.8323002461397446",
      "acc": "0.8387963",
      "loss": "0.4646014467433647"
    },
    "71": {
      "name": 71,
      "learningrate": "0.00291",
      "dropout": "0.24715",
      "epoch": "96.01927",
      "batchsize": "55.4294",
      "optimizer": "1.3214555738347125",
      "acc": "0.83857405",
      "loss": "0.4752553417152829"
    },
    "72": {
      "name": 72,
      "learningrate": "0.00564",
      "dropout": "0.09427",
      "epoch": "81.97177",
      "batchsize": "48.60698",
      "optimizer": "1.8873553167915835",
      "acc": "0.8377778",
      "loss": "1.5944260977771547"
    },
    "73": {
      "name": 73,
      "learningrate": "0.005348983988952477",
      "dropout": "0.1939",
      "epoch": "75.77229",
      "batchsize": "44.93928",
      "optimizer": "2.606427479999704",
      "acc": "0.8374444",
      "loss": "0.47427717298048516"
    },
    "74": {
      "name": 74,
      "learningrate": "0.00568",
      "dropout": "0.43804",
      "epoch": "96.02147",
      "batchsize": "55.41133",
      "optimizer": "2.5312184883481645",
      "acc": "0.83685184",
      "loss": "0.4705245335587749"
    },
    "75": {
      "name": 75,
      "learningrate": "0.00971",
      "dropout": "0.29746",
      "epoch": "70.31036",
      "batchsize": "48.01778",
      "optimizer": "0.48028250175489984",
      "acc": "0.83675927",
      "loss": "0.7227596338523758"
    },
    "76": {
      "name": 76,
      "learningrate": "0.00714065280571184",
      "dropout": "0.4140783917364833",
      "epoch": "52.89503",
      "batchsize": "51.26893",
      "optimizer": "2.1821694416510953",
      "acc": "0.83675927",
      "loss": "0.9668816368193538"
    },
    "77": {
      "name": 77,
      "learningrate": "0.008204956970205486",
      "dropout": "0.25633",
      "epoch": "52.90111",
      "batchsize": "51.27081",
      "optimizer": "0.4473815311664595",
      "acc": "0.8367222",
      "loss": "0.6030678073211952"
    },
    "78": {
      "name": 78,
      "learningrate": "0.00353",
      "dropout": "0.13442",
      "epoch": "50.89094",
      "batchsize": "48.45868",
      "optimizer": "0.5228654955024649",
      "acc": "0.83474076",
      "loss": "0.48787569453098156"
    },
    "79": {
      "name": 79,
      "learningrate": "0.0020927795413158597",
      "dropout": "0.3882",
      "epoch": "99.5419",
      "batchsize": "37.93507",
      "optimizer": "0.8718116569815799",
      "acc": "0.8340185",
      "loss": "0.4889849407143063"
    },
    "80": {
      "name": 80,
      "learningrate": "0.0076",
      "dropout": "0.1824",
      "epoch": "52.88814",
      "batchsize": "51.25451",
      "optimizer": "2.669653917616757",
      "acc": "0.8335185",
      "loss": "0.4884037257609544"
    },
    "81": {
      "name": 81,
      "learningrate": "0.009621702238663817",
      "dropout": "0.13377",
      "epoch": "87.82023",
      "batchsize": "34.83131",
      "optimizer": "2.48158034925998",
      "acc": "0.8323333",
      "loss": "1.9095404908568772"
    },
    "82": {
      "name": 82,
      "learningrate": "0.002476900518992589",
      "dropout": "0.12896",
      "epoch": "87.82279",
      "batchsize": "34.83355",
      "optimizer": "2.805351514138366",
      "acc": "0.8306481",
      "loss": "0.4972806272241804"
    },
    "83": {
      "name": 83,
      "learningrate": "0.0019500549897645387",
      "dropout": "0.18928",
      "epoch": "75.76301",
      "batchsize": "44.94445",
      "optimizer": "0.5802663458755505",
      "acc": "0.8300185",
      "loss": "0.5049593455703171"
    },
    "84": {
      "name": 84,
      "learningrate": "0.009570160535001702",
      "dropout": "0.40482",
      "epoch": "54.8696",
      "batchsize": "37.87171",
      "optimizer": "0.19307505143814063",
      "acc": "0.8295",
      "loss": "0.5816706401860272"
    },
    "85": {
      "name": 85,
      "learningrate": "0.0036729516803102455",
      "dropout": "0.43175",
      "epoch": "96.02401",
      "batchsize": "55.39796",
      "optimizer": "2.674843487764816",
      "acc": "0.82674074",
      "loss": "0.5060798143810696"
    },
    "86": {
      "name": 86,
      "learningrate": "0.00739",
      "dropout": "0.45919",
      "epoch": "90.28972",
      "batchsize": "37.89997",
      "optimizer": "1.7647805961384817",
      "acc": "0.82581484",
      "loss": "1.6334752640911827"
    },
    "87": {
      "name": 87,
      "learningrate": "0.00976",
      "dropout": "0.43673",
      "epoch": "94.6718",
      "batchsize": "59.70027",
      "optimizer": "2.3475953104878817",
      "acc": "0.8238148",
      "loss": "1.5084396848805526"
    },
    "88": {
      "name": 88,
      "learningrate": "0.0018782569552881446",
      "dropout": "0.31529",
      "epoch": "99.97216",
      "batchsize": "37.87909",
      "optimizer": "2.9391989579585096",
      "acc": "0.82325923",
      "loss": "0.521465303323887"
    },
    "89": {
      "name": 89,
      "learningrate": "0.0015072580769258574",
      "dropout": "0.35296",
      "epoch": "99.51671",
      "batchsize": "47.31559",
      "optimizer": "1.1441451397568714",
      "acc": "0.8228889",
      "loss": "0.5295074878710287"
    },
    "90": {
      "name": 90,
      "learningrate": "0.004355799269956429",
      "dropout": "0.09795",
      "epoch": "50.84857",
      "batchsize": "50.78755",
      "optimizer": "2.51673034470973",
      "acc": "0.82233334",
      "loss": "0.5244574569772791"
    },
    "91": {
      "name": 91,
      "learningrate": "0.00692157320731916",
      "dropout": "0.47153",
      "epoch": "56.90158",
      "batchsize": "35.01451",
      "optimizer": "2.109786284068454",
      "acc": "0.82225925",
      "loss": "1.1435416165060468"
    },
    "92": {
      "name": 92,
      "learningrate": "0.007570871281207266",
      "dropout": "0.29213",
      "epoch": "54.88783",
      "batchsize": "32.86757",
      "optimizer": "2.363201164475005",
      "acc": "0.8212963",
      "loss": "1.149948340340897"
    },
    "93": {
      "name": 93,
      "learningrate": "0.001580048775598222",
      "dropout": "0.39173",
      "epoch": "52.87255",
      "batchsize": "32.73776",
      "optimizer": "0.9221627312539051",
      "acc": "0.817",
      "loss": "0.5564684281437485"
    },
    "94": {
      "name": 94,
      "learningrate": "0.0012302492391651687",
      "dropout": "0.12854",
      "epoch": "83.81089",
      "batchsize": "42.52542",
      "optimizer": "2.511440869498341",
      "acc": "0.8075926",
      "loss": "0.5856816452785775"
    },
    "95": {
      "name": 95,
      "learningrate": "0.0013658611547557589",
      "dropout": "0.20424",
      "epoch": "99.17559",
      "batchsize": "49.44066",
      "optimizer": "2.8695758680879386",
      "acc": "0.8073518",
      "loss": "0.5786179015724747"
    },
    "96": {
      "name": 96,
      "learningrate": "0.0012075635631929788",
      "dropout": "0.40449",
      "epoch": "66.60157",
      "batchsize": "48.60782",
      "optimizer": "1.3254174525247193",
      "acc": "0.80233335",
      "loss": "0.5979683996306525"
    },
    "97": {
      "name": 97,
      "learningrate": "0.0006509872456938882",
      "dropout": "0.20375",
      "epoch": "66.58771",
      "batchsize": "48.59293",
      "optimizer": "0.9552620974933398",
      "acc": "0.7857222",
      "loss": "0.6562026806937323"
    }
  }
}