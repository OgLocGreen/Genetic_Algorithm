\section{Fazit}
Mit Hinblick auf die zu Beginn der Arbeit definierten Ziele, kann ein abschließendes positives Fazit gezogen werden. Zur Umsetzung dieser Ziele wurde ein automatisierter Traininigs- und Auswerte- Prozess für künstliche neuronale Netze erstellt. Anschließend wurde ein Genetischer Algorithmus zur Optimierung von Hyperparametern künstlicher neuronaler Netze konzipiert. Dazu wurden Versuche durchgeführt, in welchen die Methoden des Genetischen Algorithmus verglichen wurden. Um diese Versuche durchzuführen, wurden alle State-of-the-Art Methoden implementiert. Die zielführendsten Methoden wurden anschließend in der Evaluierung verwendet. Des Weiteren wurde die Zufallssuche als Algorithmus zum Vergleichen der Ergebnisse ausgewählt und implementiert. Abschließend wurden diese beiden Algorithmen evaluiert. In den Ergebnissen zeigte der Genetische Algorithmus nicht die erhofften Verbesserungen in der Klassifikationsgenauigkeit gegenüber der Zufallssuche. Obwohl der Genetische Algorithmus wesentlich mehr Individuen findet die eine hohe Qualität aufweisen. Bei den Individuen des GA konnte sich jedoch kein Individuum deutlich von den anderen absetzen bzw. eine Verbesserung der Klassifikationsgenauigkeit erbringen. Dies liegt daran, dass kleine Veränderungen der Hyperparameter keine messbaren Unterschiede auf DIE Endergebnisse haben. Dennoch hat sich in der Evaluierung gezeigt, dass sich die Hyperparameter in einem bestimmten Intervall befinden müssen, sonst liefert das künstliche neuronale Netz keine brauchbaren Ergebnisse. Dieser bestimme Bereich kann über das Dichte-Diagramm des Genetischen Algorithmus sichtbar gemacht werden. Dieser Bereich ist für jedes Netz bzw. Modell-Architektur individuell und kann sogar von den Trainingsdaten abhängen. Der Genetische Algorithmus, ist in Bezug auf das Finden der besten Hyperparameter, vergleichbar mit der Zufallssuche. Zusätzlich hat der GA den Vorteil, dass er Zusatzinformationen besitzt. Somit kann er ein bestimmtes Intervall angeben, in welchem sich die Hyperparameter befinden müssen, um gute Ergebnisse zu erreichen. Zusammengefasst kann gesagt werden, dass bei einem kleinen Suchraum oder wenn nur wenig Rechenressourcen zur Verfügung stehen, eine Zufallssuche ausreichend ist. Doch wenn der Suchraum für die Hyperparameter groß ist oder ein leistungsstarker Rechner zur Verfügung steht, hat der Genetische Algorithmus durchaus seine Vorteile.


\section{Ausblick} \label{ausblick}
Die Optimierung von Hyperparametern mit Hilfe eines Genetischen Algorithmus hat nur bedingt Verbesserungen erbracht. Weswegen eine Optimierung der Hyperparameter mit Hilfe eines anderen Optimierungsalgorithmus denkbar wäre. Hierfür ist eine Optimierung mit dem Bayesian Optimierer oder dem HyperOPt (Distributed Asynchronous Hyper-parameter Optimization) denkbar. 

Neben der Optimierung von Hyperparametern könnte in einer weiteren Arbeit auf die Optimierung der Modell-Architektur eingegangen werden. Zu diesem Thema wurden in dieser Arbeit bereits erste Versuche durchgeführt. Die Ergebnisse des Versuches \ref{versuch_modell} zeigten bei der Optimierung eine Tendenz zu größeren Modell-Architekturen. Um dieser Tendenz entgegenzuwirken müsste eine geeignete Fitnessfunktion entwickelt werden. Hierfür könnte beispielsweise die Gesamtanzahl an Parametern als negativer Faktor mit einbezogen werden. Generell ist ein Finden spezieller Netze über das Erstellen einer speziellen Fitnessfunktion möglich. Eine spezielle Fintessfunktion ist nicht nur für die trainierbaren Parameter denkbar. Sie könnte auch zur Findung von Netzen mit hoher Interferenz genutzt werden. 

Zudem könnten noch andere Parameter als Gene umgesetzt werden. In dieser Arbeit ging es nur um die gängigen Hyperparameter \ref{sec:Grundlagen_Hyperparamete}. Diese Hyperparameter haben aber nur einen geringen Einfluss auf das Klassifizierungsergebnis. Es wäre durchaus denkbar eine Optimierung mit anderen oder mehreren Parametern durchzuführen. Somit kann der Genetische Algortihmus seine Vorteile im großen Suchraum ausspielen.
