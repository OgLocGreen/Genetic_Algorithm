\section{Motivation}
\label{sec:Motivation}
In den letzten Jahren zeigte sich ein enormer Zuwachs an Publikationen und Forschungen zum Thema "Maschinelles Lernen". Die künstlichen neuronalen Netze dominieren dieses Feld, aber ihr Training und ihr Erfolg hängt noch immer von empirisch ausgesuchten Anfangsparametern, den sogenannten Hyperparametern, ab. Zu diesen Hyperparametern können Modell-Architektur, Verlustfunktion, Optimierung Algorithmen, Batchsize, Dropout und Lernrate gezählt werden. Momentan werden diese Hyperparameter meist nach Ermessen des Entwicklers ausgewählt, denn es gibt keine formalen Regeln. Dieses Auswählen und Testen der Hyperparameter beansprucht sehr viel Zeit und Mühe, da die anfängliche Auswahl der Parameter meist suboptimal ist und diese noch einige Male angepasst und getestet werden müssen. Dieses Optimieren der Hyperparameter sollte jedoch nicht zu den Aufgabe des Entwicklers gehören und sollte von Maschinen übernommen werden, welche in Bereich der Optimierung wesentlich effizienter arbeiten. \cite[p.~337]{francois2017deep}

\section{Aufgabenstellung}
\label{sec:Aufgabenstellung}
Ziel dieser Arbeit ist es die Optimierung von Hyperparametern für künstliche neuronale Netze zu automatisieren. Diese Optimierung soll Mithilfe des Genetischen Algorithmus erfolgen. Dafür muss als erstes ein automatisierter Trainings- und Auswerte-Prozess der künstlichen neuronalen Netze erstellt werden. Anschließend soll ein Konzept zur Optimierung von Hyperparametern mit Hilfe des Genetischen Algorithmus entwickelt und implementiert werde, wozu der automatische Trainings- und Auswerte-Prozess verwendet werden soll. Die Ergebnisse des Genetischen Algorithmus sollen anschließend mit den Ergebnissen des State-of-the-Art Algorithmus zur Optimierung von Hyperparametern gegenübergestellt und ausgewertet werden. Darüber hinaus soll eine Optimierung der Hyperparameter unter Betrachtung geringer Datenmengen durchgeführt werden. 

\section{Aufbau der Arbeit}
\label{sec:Aufbau der Arbeit}
Im zweiten Kapitel wird auf die Grundlagen der künstlichen neuronalen Netze eingegangen. Anschließend werden die zu optimierenden Hyperparameter definiert. Nachfolgend werden die Optimierungsalgortihmen erläutert, dazu gehören der Genetische Algorithmus mit seinen 5 Schritten und die Rastersuche bzw. die Zufallssuche.

Im dritten Kapitel wird auf den Stand der Technik eingegangen. Dazu werden die neusten Forschungsergebnisse erläutert. Zu diesen gehört das Populations Basierte Training(PBT) von Google und die NeuroEvolution of Augmenting Topologies(NEAT). Zudem werden Anwendungsbeispiele des Genetischen Algorithmus, welche in der Forschung als auch in der Industrie verwendetet werden aufgezeigt. 

Im vierten Kapitel wird auf das Konzept zur Optimierung der Hyperparameter eingegangen. Hierfür wird ein Konzept zum Genetischen Algorithmus zur Optimierung der Hyperparameter eines künstlichen neuronalen Netzes vorgestellt. Anschließend wird auf das Konzept zur Evaluierung und Auswertung mit Hilfe des Dichte-Diagramms eingegangen. 

Im fünften Kapitel wird der Systemaufbau erklärt. Es wird auf die verwendete Hardware eingegangen. Anschließend wird die exakte Implementierung des Genetischen Algorithmus, der Zufallssuche und der Evaluation sowie die Auswertung beschrieben.

Im sechsten Kapitel werden die Ergebnisse der Optimierung dargestellt und besprochen. Zudem wird die visuelle Auswertung zu jedem Hyperparameter aufgezeigt und erläutert. 

Im siebten und letzten Kapitel werden alle vorherigen Kapitel als Fazit zusammengefasst. Der Ausblick zum Thema bildet den Abschluss der Arbeit. 


