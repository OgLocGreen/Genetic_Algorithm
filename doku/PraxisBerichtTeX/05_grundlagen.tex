\section{Grundlagen}
\label{sec:Grundlagen}
In diesem Kapitel werden die theoretischen Grundlagen, welche zum Verständnis, der vorliegende Arbeit wichtig sind, beschrieben. Zubeginn erfolgt ein kurzer Einstieg in die Optimierungsgrundlagen. Dann folgt die Einführung in die Grundlagen der Genetischen Algorithmen. Anschließend werden die wichtigen Grundlagen der Künstlichen Neuronalen Netzen erklärt. Zum Schluss wird kurz auf die Hyperparameter und ihre Besonderheiten eingegangen.

\subsection{Optimierungsgrundlagen}
Angenommen es soll ein Künstliches Neuronales Netz mit k Layern und L Neuronen zur Klassifizierung von einfachen handgeschriebenen Zahlen erstellt werden. Der Entwickler entscheidet sich für ein 3 Layern Netz mit jeweils 3 Neuronen. Nach dem Training hat es die Genauigkeit von 85 Prozent. Nun kann man nicht sicher sagen, ob für k = 3 und l = 3  die optimale Lösung gefunden wurde. Um dies beurteilen zu können. Müssen viele Experimente durchgeführt werden. Die Frage ist, wie kann man die besten Werte für k und j finden, um die Klassifizierung zu maximieren. Dieser Vorgang speziell im Zusammenhang mit Künstlichen Neuronalen Netzen wird als Hyperparameter-Optimierung bezeichnet. Bei der Optimierung wird mit einem Initialwert gestartet, dieser ist in den seltensten Fällen die exakte Lösung. Dieser Initialwert muss einige Male verändert werden um auf einen Optimum zu kommen. Manchmal ist dieses Anpassen/optimieren so Komplex, dass es durch eine Funktion ersetz werden muss. In diese Arbeit ist dafür der Genetische Algorithmus notwendig.


\subsection{Genetische Algorithmen}

Die Inhalte des folgenden Abschnittes sind, sofern nicht anderweitig angeführt aus den Gurndlagen büchern xxxx und xxxx übernommen. 




Genetische Algorithmen sind heuristische Suchansätze. Im wesentliche zeichnet sie eine probabilistische Eltern Selektion als primären Suchoperator aus. Als weitern Suchoperator kann noch auf die Mutation zurückgegriffen werden, dieser garantiert eine Erreichbarkeit aller Punkte im Suchraum und erhält die Grunddiversität in der Population. Es gibt zwei verschiedene Algorithmen der Standart-GA tauscht nach einer Generation die komplette Elternpopulation durch die Kinderpopulation aus. Und bestehen in der Regel immer aus fünf gleichen Schritten wie in Abb. \ref{fig:Ablauf_kurz} zusehen ist.Im Gegensatz dazu gibt es den Steady-State-GA welcher durch seine überlappende Population auszeichnet, dieser Algorithmus wird in der Arbeit nicht verwendet und wird deswegen nicht weiter erklärt. 

\noindent%
\begin{figure}[H]
  \centering  
  \includegraphics[scale=0.7]{img/Ablauf_kurz.png}
  \caption{Ablaufdiagramm eines Genetischen Algorithmuses mit 5 Schritten}
  \label{fig:Ablauf_kurz}
\end{figure}


Der Standard genetische Algorithmus \ref{fig:Ablauf_kurz} besteht aus folgenden 5 Schritte:
Schritt 1, Initialisieren der Anfangspopulation.
Schritt 2, Fitness berechnen mit Hilfe der Fitnessfunktion.
Schritt 3, Selektieren der Eltern.
Schritt 4, Vermehren durch Cross-over und Mutation.
Schritt 5, Austausch der Populationen.
In den nachfolgenden Unterkapiteln werden auf die einzelnen Schritte genauer eingegangen.

<--
entweder oder
-->

\begin{algorithm}
\caption{Basic Genetic Algorithm }
\begin{algorithmic}[1]
\State Initialisieren der Anfangspopulation   \Comment{put some comments here}
\While{$ Fitness \leq Abbruchbedingung$}
	\State Fitness aller Individuen Berechnen
	\State Selektieren der Eltern
	\State Vermehren durch Cross-over und Mutation
	\State Austausch der Populationen
\EndWhile

\label{GA}
\end{algorithmic}
\end{algorithm}



\iffalse
oder 

Der Standart Genetische Algortithmus \ref{Alorthm 1}besteht meist aus immer den gleichen Schritte:
Schritt 1 Inizialisieren einer Population.
Schritt 2 Fittness brechnen mit hilfe der Fitnessfunktion.
Schritt 3 Evolution (Weiterentwicken), hier werden zuerst die passenden Eltern ausgesucht und anschließend mit Crossover und Mutation die Kinder Population erstellt. 
Schritt 4 Elternpopulation durch die neue Kinderpopulation ausgetauscht.
Hier noch einamal als Pseudocode.


Algorithm 1 Basic Genetic Algorithm \\
1: initialize population \\
2: repeat \\
3: 		repeat \\
4:			fitness computation \\
5:			parent selection \\
6:			breed \\
7:		until population complete \\
8:		selection of parental population \\
9: until termination condition \\

Im nachfolgenden Unterkaptitel wird auf diese einzelnen Schritte genauer eingegangen.

\fi

\iffalse
Genetische Algorithmen sind im Wesentlichen durch eine probabilistische Eltern selektion und die Rekombination als primären Suchoperator gekennzeichnet.Die Mutation ist meist nur ein Hintergrundoperator, der mit einer geringen Wahrschenlichkeit zur anwendungkommt. Er garantiert die Erreichbarkeit aller Punkte im Suchraum und erhält eine Drunddiversitöt in der Population.

Evolutionäre Algo -- s.128


Genetische Algorithmen sind heuristische Suchansätzem, die auf einer breitenbasis von Optimierungsproblemen angewendet werden können. Diese Flexibiliät macht sie für die Praxis für viele sehr attraktiv.Die Evulution ist Grundlage des Genetischen Aglorithmuses. durch die aktuelle Vielfalt und der Erfolg der Arten ist dies schon alleine ein guter Grund sich diesen Optimierungs Algortihmus näher anzuschauen. Denn sdiese Arten sind in der lage sich an ihre Umgebung anzupassen und sich zu zu komplexen Strukturen zuentwickelen, und somit das überleben in verschiedesten Umgebungen eröglichen. Hierbei ist die Paarung und Entwicklung von Nachkommen eine der Hauptprinipen des Erfolges der Evolution. In diesem Kapitel werden wir die Grundlage der GEnetischen Algorithmen näher anzuschauen. Beginnen wir mit der grundlage das es sich bei den Genetischen Algorithmen um einen Polulations ansatz handelt. Anschließend wird auf die wichtigesten genetischen Operatioren vorstellen darunter gehöhren, Selektion, Crossover und Muttation

Seite - 11 Genetic Algorithm Essentials


Algorithmus 1 zeigt den Pseudocode des grundlegenden genetischen Algorithmus, der Folgendes kann dienen als Blaupause für viele verwandte Ansätze. Am Anfang eine Reihe von Lösungen,die als Population bezeichnet wird, wird initialisiert. Diese Initialisierung wird empfohlen.um zufällig den gesamten Lösungsraum abzudecken oder um Experten zu modellieren und einzubinden. Wissen. Die Darstellung bestimmt den Initialisierungsprozess. Für BitfolgeDarstellungen ist eine zufällige Kombination von Nullen und Einsen sinnvoll, z.B.das anfängliche Zufallschromosom 1001001001001 als typische Bitfolge der Länge 10. Der Hauptgenerationskreislauf des Genetischen Algorithmus erzeugt neue Nachkommen.Kandidatenlösungen mit Crossover und Mutation, bis die Bevölkerung vollständig ist.

Algorithm 1 Basic Genetic Algorithm
1: initialize population
2: repeat
3: 		repeat
4:			fitness computation
5:			crossover
6:			mutation
7:			phenotype mapping
8:		until population complete
9:		selection of parental population
10: until termination condition

Seite - 11 Genetic Algorithm Essentials
\fi 

\subsubsection{Aufbau und Initzialisierung der Population}
Der klassische genetische Algorithmus basiert auf einer Reihe von Kandidatenlösungen. Die Größe der Population ist somit auch die Anzahl der Lösungen. Jede Lösung kann als einzelnes Individuum gesehen werden und wird durch ein Chromosomenstrang repräsentiert. Ein Chromosom besteht wiederum aus vielen Genen, welche die Parameter/hyperparameter repräsentieren. Der Aufbau ist grafisch in Abbildung \ref{fig:population} dargestellt. Es gibt verschiedene Möglichkeiten, diese Gene dazustellen. Wie Binär oder Dezimal, um die Grundlagen nahe des später folgenden Konzepts zuhalten, wird der Ablauf per Dezimal-Genen erklärt.




\noindent%
\begin{figure}[H]
  \centering  
  \includegraphics[scale=0.7]{img/population.png}
  \caption{Beispiel einer Population mit 4 Induviduen (Chromsomen) welche 6 dezimale Gene besitzen}
  \label{fig:population}
\end{figure}

Diese Anfangspopulation(Generation 0) wird zufällig initialisiert, um die größt mögliche Abdeckung des Suchraums zu gewähren. 

Die erste Generation besitzt (dadurch) eine sehr geringe Fitness, dies verbessert sich aber im Lauf des Trainings.
Die erste Generation besitzt eine sehr geringe Fittnes, welche im verlauf des Trainings stetig steigert bis sie das Maximum erreicht. (XXXFachbegriffxx)

--- würde ich weglassen
Durch Selection werde die nicht unnötigen/Contra-produktiven Individumen oder auch Unfittesten Inidividuen aussotiert.
Dafür wird die Fittneswert benötig, welches im nächsten Punkt erklärt wird.
----


\subsubsection{Fittnesfunktion}
Die Fitnessfunktion (eng. Fitnessfunction) bewertet das Individuum anhand seiner Funktionstauglichkeit, bezogen auf die vorhandene Aufgabe. Dabei werden nicht einzelnen Gene bewertet, sondern das ganze Genom/Chromosom/Individuum. Es gibt keine universelle Fitnessfunktion, diese muss also für jede Anwendung speziell geschrieben werden. Es wird nicht berücksichtigt welches Gene sich positiv bzw. negativ auswirken. Als Rückgabewert gibt die Fitnessfunktion uns einen dezimalen/float Fitnesswert, dabei steht ein höherer Fitnesswert stehst für eine höher Qualität an Individuum sprich bessere Lösung.

\iffalse
Nun besteht die erste Generation(Generation 0) aus einer Population mit völlig zufälligen Induviduen. Es gibt keine universelle funktionierende Fitnessfuntion, diese muss für jeden Algorithmus neu geschrieben werden. Die Fittnesfunktion bewertet das Individum anhand seiner Funktionstauglichkeit bezogen auf die gestellte Aufgabe. Dabei werden nicht einzelnen Gene bewertet sondern das ganze Genom/Chromoson/Idividum. Es wird also nicht berücksichtigt welches Gene sich positiv bzw. negativ auswirken. Als Rückgabewert gibt die Fittnesfunktion uns einen Fittneswert, dabei steht ein höherer Fittnesswert stehts für eine höher Qualität an Individum sprich bessere Lösung.

Da nun alle Individuen der Population bewertet wurden kann eine neue Generation erstellt werden.

\fi


\iffalse
\subsubsection{Evolution (eng. Evolve) Fällt raus}

Bei dem Schritt Evulution geht es darum aus der Alten Population eine neue bessere Population zu erstellen. Dafür muss zu erst einen Elternpool (eng. matingpool), mit hilfe der eltern Selektion, erstellt werden. Aus diesem Elternpool wird mit Crossover und Mutation die neue Generation erstellt. 
Dazu  werden aus zwei Elternpaaren ein neues Kind erstellt.
Um die Elternpaare auszusuchen gibt es verschiedene Optionen. Da nun die Eltern fest stehen, wird per Crossover aus den beiden Elternpaaren oder aus dem Elternpool ein neues Kind generiert. Um bei den Genen eine höhere diversität zu gelangen werden die Kindergene noch mit einer Mutation versehen. Somit kann man einen höheren Suchraum(Abdeckungsgrad) abdecken. Nach dem eine neue Kind generation erstellt wurde wird der ganze vorgang so lange wiederhollt bis die geforderte Fintess ereicht wurde.

\fi

\subsubsection{Selektion der Eltern}
Bei dem Schritt Selektion(eng. Select Parents) geht es, darum einen Elternpool zu erstellen, aus welchem die neue Generation erstellt wird. Deshalb ist es wichtig, nur die besten, geeignetesten Individuen auszuwählen. Es gibt verschiedene Ansätze bei der Selektion, die bedeuteten werden genannt und erläutert.

Informationen wurden aus dem Paper \cite{shukla15} entnommen.


\begin{itemize}
\item \textbf{Auswahl proportional zur Fittnes (eng. Fitness Proportonal Selction(FPS))}, hierbei spielt die im vorigen Schritt berechnete Fitness eine große Rolle. Die Eltern werden nach ihrer Fitness proportional ausgewählt und zum Elternpool hinzugefügt. Wenn $f(a_i)$ die Fitness des Individuell $a_i$ in der Population ist, dann ist die Warscheinlichkeit selektiert/ausgewählt zu werden:
\begin{equation}
	ps(a_i) = \frac{f(a_i)}{\sum_{i=1}^n f(a_j)}; j\in{1,2,...,n} \label{eq:1}
\end{equation}
wobei n die Anzahl der Individuen einer Population ist.
Diese Warscheinlichkeit $ps$ kann man sich, als Anteil auf einem Rouletterad, wie in Abblidung \ref{fig:roulette_wheel}, vorstellen. Auf dem Zufällig die Eltern aus den Idividuen a1,..,an \glqq ausgedreht \grqq werden. Dieser Ansaatz hat leider das Problem das Individuen die am Anfang sich als gut beweisen schnell die ganze Population übernehmmen. Das kann dazuführen, dass eine mögliche bessere lösung durch den Algorithmus im Suchraum nicht gefunden wird.

\begin{figure}[htb]
  \centering  
  \includegraphics[scale=0.5]{img/roulette_wheel.png}
  \caption{Rouletterad mit Proportinalen Anteil der Individuen anhand ihrere Fitness}
  \label{fig:roulette_wheel}
\end{figure}

introduction to evolutionary comp s80

\iffalse
Ein weiteres Problem ist es wenn die Lösungen nahe bei bei einandern liegen gibt es fast keine selections druck mehr herscht. DIes geschied gegen ende der Optimierung und führt zu einem sehr langsamen verlauf gegen ende. 

introduction to evolutionary comp s80
\fi




\item \textbf{Ranking Selektion}, diese Selktion wurde von Backer als Verbesserung der Fitness Proportonal Selection entwickelt \cite{baker1985adaptive}. Dabei werden die Eltern nicht direkt nach ihrer Fitness ausgewählt. Die Fitness dient nur zum einteilen in eine Rangliste. Anhand dieser Rangliste wird dann wieder mit Hilfe des Rouletterades ausgewählt. Dabei gibt es verschiedene Verfahren wie diese Verteilung aussehen kann, einmal ein Lineare Ranking verfahren:
\begin{equation}	
	p_i = \frac{1}{N}(n^- + (n^+ - n^- ) \frac{i-1}{N-1}; i\in{1,...,N} \label{eq:2}
\end{equation}
Wobei $p_i$ die Warscheinlichkeit des Individums ist selektiert zu werden. $\frac{n^-}{N}$ ist die Warscheinlichkeit des Schlechtesten Indiviudums selektiert zu werden und  $\frac{n^+}{N}$ ist die Warscheinlichkeit des Besten Individums selektiert zu werden.

oder das expontienelle Ranking:
\begin{equation}
	p_i = \frac{c^{N-i}}{\sum_{j=1}^N c^{N-j}}; i\in{1,...,N} \label{eq:3}
\end{equation}
die Summe $\sum_{j=1}^N c^{N-j}$ normalisiert die Wahrscheilichkeit um sicherzustellen das $\sum_{i=1}^N p_i = 1$
Wobei die Berechnungen \ref{eq:2} und \ref{eq:3} nur den Anteil eines Individums auf dem Rouletterades verändern.

\iffalse
Sie werden nach ihrer Fitness sotiert und einem Rang Rk , k = 1, ...,N wobei N die anteil der individuen einer Population ist. Der beste kandidat erhält den besten Rang wobei der schrlechtestet den Rang N-1 erhält. Die fitness 

\fi

\item \textbf{Tunier selektion}, in diesem Verfahren werden züfällig k Induviduen der Population ausgewählt. Diese k Induviuen  tretten wie in einem Tunier gegeneinander an. Der Gewinner ist das Individuum mit dem besten Fittneswert,dieser wird dann auch als Elternteil ausgewählt. Hierbei wird auf den Elternpool verzichtet und direkt ein Kind aus zwei Gewinnern erstellt. Eingesetzt wird dies bei kleineren Populationen mit weniger als 20 Individuen.

\begin{figure}[htb]
  \centering  
  \includegraphics[scale=0.7]{img/tunier.png}
  \caption{Tunier Selektion mit k = 3 Individuen und dem Gewinner Individuum 3}
  \label{fig:roulette_wheel}
\end{figure}


\end{itemize}


\subsubsection{Vermehrung (eng. Breed)}
Aus dem Elternpool/Paarungspool werden nun Nachkommen(Kinder) geschaffen. Alleine durch die Paarung(eng. Crossover) von qualitativ hochwertigen Individuen wird erwartet, dass die Nachkommen eine bessere Qualität besitzen als die ihrer Eltern. Als zweite Verbesserung wird noch die Mutation einzelner Gene angewendet. Für Crossover und Mutation gibt es verschiedene Ansätze, die in diesem Abschnitt genauer erklärt werden.



\iffalse
Dennoch kann es zu negative man nur die Eigenschaften der Eltern übernimmt kann es sogar dazu kommen das negative eigenschaften mit übernommen werden. Da dies natürlich nicht gewollt ist gibt es eine einfach Verbesserungs möglichkeit. Die Muation, hier wird jedes Gen noch einmal mit einer zufälligen Muation versehen welches ähnliche aber andere Lösungen hervorbringt. Nun gehen wir noch einmal genauer auf Operation Chrossover und Muation ein.

Somit müsste sich die Finttnes der nächsten generation verbessern. Um dies zu ereichen werden die  Gene noch modifiziert, durch corssover oder mutation. Somit wird der suchraum noch einmal vergrößert aber nur in der nähe der für gut empfunden Individuem bzw. dieser Gene.
Um aus den Einzelnen elternpaaren neue Individuen zu generieren wird das Verfahren/algorithmus Crossover verwendet. Bei Crossover kann es nun auch verschiedene möglichkeiten geben.
\fi


\paragraph{Crossover}, nennt man die Operation, bei der die Chromostränge der Kinder Individuen zusammengesetzt werden.
Beim Crossover gibt es mehrer Varianten, die One-Point-Crossover in welchem zufällig ein Punkt im Chromsomenstrang festgelegt wird.
Ab diesem Punkt wird der Chromosomenstrang dann aufgeteilt und anschließend mit dem Crossover des anderen Elternteils wieder zusammen gesetzt. Ein einfaches Beispiel ist im Oberenteil der Abbildung \ref{fig:chromoson_crossover} zu sehen.

Eine Abwandlung des ein-punkt-crossover ist das zwei-punkt-crossover oder k-punkt-crossover. Hier wird der Chromsomenstrang an k Punkten aufgeteilt und anschließend mit dem Anteil des zweiten Elternteil wieder zusammengesetzt.
In mittleren Teil der Abbildung \ref{fig:chromoson_crossover}
ist ein k = 2 Crossover oder auch zwei-punkt-crossover (eng. two-point-crossover) zu sehen.

Eine weite Grundlegende Operation beim Crossover ist die Uniform-crossover \cite{Syswerda1989} in welcher es keine festgelegte Anzahl an Punkten gibt. Hier wird für jedes Gen zufällig entschieden aus welchem Elternteil das Gen entnommen wird.
Dies im unteren Teil der Abbildung\ref{fig:chromoson_crossover} noch einmal veranschaulicht.

\begin{figure}[H]
  \centering  
  \includegraphics[scale=0.5]{img/crossover_gene.png}
  \caption{Wichtigsten drei Crossover Operationen. Oben die One-point Crossover, mitte Two-point Crossover, unten Uniform Crossover. Auf der linken Seite sind Eltern abgebildet und auf der Rechtenseite die neu erzeugten Kinder}
  \label{fig:chromoson_crossover}
\end{figure}

Crossover nach dem Paper \cite{Umbarkar2015}.




\paragraph{Mutation},hierbei wird jedes Gen des Individuums zufällig mit einer zufälligen Mutation versehen. Durch diese Mutation wird eine höhere Diversität in die nachfolgende Generation übergeben. Diese Mutation macht es möglich einen größeren Suchraum abzudecken und somit die Werte genauer anzupassen, um so auf die Optimale Lösung zu kommen. 

\iffalse
Bei der Muatation wird jedes Gen des Individuums zufällig mit einer zufälligen Mutation versehen. Dies macht es möglich eine höhere Diversität in die nachfolgende Generation zu übergeben. Daruch kann einen größer Suchraum abgedeckt werden. Somit werden die Werte genauer angepasst, um so auf die Optimale Lösung zu bekommen.
\fi

\begin{figure}[H]
  \centering  
  \includegraphics[scale=0.7]{img/mutation.png}
  \caption{Muation von Genen um eine höhere diversität zu erhalten}
  \label{fig:chromoson_mutation}
\end{figure}


\subsubsection{Neue Generation}
Der letzte Schritt des Genetischen Algorithmuses besteht aus dem Austausch der Generationen. Die neue Kind Generation tauscht nun die alte Eltern Generation aus. Anschließend folgen die gleichen 4 Schritte so lange bis die gewünschte Abbruchbedingung/ Fitnesswert erreicht ist. Wenn dies geschied, kann aus der letzten Generation das qualitativ hochwertigste Individuum ausgesucht werden und als Lösung verwendet werden.

\newpage

\subsection{Künstliche Neuronale Netze}

Künstliche Neuronale Netze sind dem natürlichen Vorbild der neuronalen Netze im Gehirn nach empfunden. Beide Netze setzen sich aus einzelnen Neuronen zusammen, welche mit einandern verbunden sind und somit ein großes Netz entstehen lassen. Wie man in Figure \ref{fig:neural_network} sieht ist jede Schicht aus einzelnen Neuronen aufgebaut, welche mit den Neuronen der nächsten Schicht verbunden sind. Diese Verbindungen repräsentieren die Gewichte, über diese kann einem Netz verschiedene Zusammenhänge von Input und Output antrainiert bzw. angelernt werden.

\begin{figure}[htb]
  \centering  
  \includegraphics[scale=0.5]{img/S36_Buildyourown.png}
  \caption{Künstliches Neuronales Netz mit drei Schichten je drei Neuronen \cite{Rashid2017} }
  \label{fig:neural_network}
\end{figure}


Im folgenden Kapitel wird zuerst der Aufbau eines Neurons/Perseptron erklärt. Anschließend wird auf den strukturellen Aufbau eines Künstlichen Neuronalen Netzes nähergebracht. Zum Schluss werden noch wichtige Eigenschaften wie die Verlustfunktion und der Gradientenabstieg eingegangen, sowie auf die Hyperparameter, welche für die Arbeit essenziell sind.



Grundlagen aus dem buch ArificalNeuroalNetworks s.11 


\subsubsection{Aufbau eines Neurons}
Ein Neuron besteht immer aus dem gleichen Aufbau: Eingänge, Gewichte, Schwellwert, Aktivierungsfunktion und einem Ausgang.
Nachfolgenden Unterkapitel werden diese Ausführlich erklärt.
\begin{figure}[htb]
  \centering  
  \includegraphics[scale=0.5]{img/S41_Buildyourown.png}
  \caption{Aufbau eines Neurons \cite{Rashid2017}}
  \label{fig:neuron}
\end{figure}





\paragraph{Eingang}
Bei den Eingnangswerten $i_1, ..., i_n$ handelt es sich um einfache xxxFloatwertxxx, diese werden mit den Gewichten $w_1, ..., w_n$ verrechnet. Ein Neuron hat meist mehrere Eingangsgrößen, welche alle zusammen mit den Gewichten und Schwellwert(xxxxschwellert hier schon genanntxxxx) aufsummiert werden. Diese Werte werden zufällig initialisiert und per Training verbessert, somit handelt es sich um einen angelernten Werte, welche durch die Fehlerrückführung (eng. Backproagation) verbessert werden.

\paragraph{Schwellwert}
Auf dieses Aufsummiertes Ergebniss wird anschließend ein Bias $w_0$ gerechnet, dieser führt zu einem besseren Verhalten beim Trainieren. Bei diesen Werten handelt es sich auch um angelernte Werte und helfen die Flexibitlität der Netze erhöht.

\begin{equation}
	x = \sum_{k=1}^n i_k * w_k + w_0 \label{eq:4}
\end{equation}

\paragraph{Aktivierungsfunktion}
Die Aktivierungsfunktion kann man sich als Schwellwertfunktion vorstellen, ab wann das Neuron den Eingang weiter gibt.
Die entschandenen Summe x wird Aktivierung genannt und anschließend über eine Aktivierungsfunktion transformiert:
\begin{equation}
	o = f(x) \label{eq:5}
\end{equation}
Die Aktivierungsfunktion kann dabei verschiedene Formen haben. Für einfache Aufgaben kann Beispielsweise eine Sprungfunktion verwendet werden:
\begin{subnumcases}
{\sigma(t) = }
1, & wenn $t \geq 0$\\ \label{eq:6a}
0, & sonst $t < 0$		\label{eq:6b}
\end{subnumcases}

Für das approximieren von wertkontinuierlichen Funktionen wird die Sigmoid Funktion verwendet.
\begin{equation}
	sig(t) = \frac{1}{1 + e^{-t}} \label{eq:7}
\end{equation}
Bei der Klassifkation werden hingeben, der ReLu-Layer \ref{eq:8a} \ref{eq:8b} oder der Leaky-ReLu Layer \ref{eq:9a} benutzt, diese verhindern das Expodieren bzw. Verschiwenden des Grandienten beim Training:
\begin{subnumcases} 
{R(z) = }
1, & wenn $z \geq 0$\\  \label{eq:8a}
0, & sonst $z < 0$		\label{eq:8b}
\end{subnumcases}
\begin{subnumcases} 
{R(z) = }					
1, & wenn $z \geq 0$\\		\label{eq:9a}
\alpha z, & sonst $z < 0$	\label{eq:9b}
\end{subnumcases}


\iffalse
Die Aktivierungsfunktion kann man sich als Schwellwertfunktion vorstellen, ab wann das Neuron den Input weiter gibt. Es gibt verschiedene Funktionen, um diesen Schwellwert zu definieren. Je nach Aufgabe des Neuronalen Netze werden andere Aktivierungsfunktionen verwendet. Bei Klassifizierungen werden heute meist ReLu-Layer oder ein Weakly-ReLu Layer benutzt, diese verhindern das Vanishing- bzw. Exploding- gradientproblem beim Trainieren.

\fi

\paragraph{Ausgang}
Wenn die Schwellwertfunktion aktiviert wird, wird am Ausgang des Neurons eine Wert geschalten. Dieser Ausgangswert kann dann entweder an andere Neronen weitergeben werden oder als finales Ergebnis verwendet werden.


\iffalse
Wenn der Schwellwert überschritten wird, wird am Output durchgeschaltet. Dieser Output kann entweder mit einer nen Schicht Neronen verbundne sein oder direkt als Ausgang gesehen werden. Über welchen man anhand von xxxVariabelenwerten/Kommawerten die 
Von Input nach Output nennt sich ein Single-Forward-Pass. Wie hier beschrieben wird, kann ein Netz verschieden viele Layer besitzen mit verschiedenen Anzahlen von Neuronen.
\fi

\subsubsection{Struktureller Aufbau eines Künstlichen Neuronalen Netzes}
Aus schlauen zusammen schließen solcher Neuronen entsteht ein Künstliches Neuronales Netz welches auch Multi-Layer-Perseptron genannt wird. Dabei sind grundsätzliche jegliche Strukturelle Anordnung der Neuronen möglich. Besonders verbreitet ist das sogenannte Feedforward Netz (FFW).
Bei den FFW Netzen sind die Verbindungen nur in eine Richtung gerichtet. Dies wird beispielhaft in Abbildung \ref{fig:neural_network} gezeigt. Hier ist gut, zu sehen, dass diese Netze in drei Schichten unterteilt werden können.  
\begin{itemize}
\item \textbf{Eingangsschicht} Die Neuronen der Eingangsschicht sind nicht wie die oben beschriebenen Neuronen aufgebaut. Sie verteilen die Eingagsinformationen an die Versteckteschicht weiter. Weshalb es immer genau soviele Eingangsneuonen wie es Eingangssignale geben muss.

\item \textbf{Versteckteschicht}
Die Verstecktesicht enthält die oben genanten Neuronen. Sie kann aus einer Beliebigen Anzahl dieser aufgebaut sein. Es kann auch beliebig viele Versteckteschichten geben. In der Literatur bezeichnet man Neuronale Netze mit mehr als einer Verstecktenschicht als Deep Neural Networks.

\item \textbf{Ausgangsschicht}
Die Ausgangsschicht beinhaltet genau soviele Neuronen wie Ausgangsgrößen gewünscht.
Aus dieser können dann die Klassifizierungswerte entnommen werden.
\end{itemize}



\subsubsection{Verlustfunktion}
Die Verlustfunktion(eng. Lossfunction) stellt ein ausgesuchtes Maß der Diskrepanz zwischen den beobachteten und den vorhergesagten Daten dar. Sie bestimmt die Leistungsfähigkeit des Künstlichen Neuronalen Netzes während des Trainings. Ziel ist es, im laufenden Prozess der Modellanpassung, die Verlustfunktion zu minimieren. xxxnoch erweiternxxx

\subsubsection{Gradientenabstieg}
Um die Fehlerfunktion zu minimieren wird als Werkzeug der Gradienten Abstieg benutzt. Diese ist nur möglich da ein Künstliches Neuronales Netz aus verketteten differenzierbaren Gewichte der Neuronen(Tensoroperationen) aufgebaut ist, die es erlauben duch anwendung der Kettenregel die Gradientenfunktion zu finden, die den aktuellen Parametern des Datenstapels Werte des Gradienten zuordnet. Es gibt auch hier verschiedene Ansätze von Optimierern, welche die genauen Regeln wie der Gradient der Verlustfunktion zu Aktualisierund der Parameter verwendet wird hier könnte Beispielweise den RMSProp-Optimierer, der die trägheit des Gradientenabstiegsverfahren berücksichtet.

Seite 83 - Deep Learning chollet


\iffalse
 Im Grunde werden dabei die Gewichte so angepasst, dass ein besseres Ergebnis entsteht und dadurch die Fehlerfunktion verringert wird. Wie das Wort Backpropagation schon sagt, wird von hinten nach vorne verbessert. Es gibt verschiedene Variationen von Gradientenabstiegen, welche verschiedene Vor- und Nachteile haben. Bei dem Trainieren des Netzes wurde der Momentum-Optimizer, welcher aus einem Gradientenabstieg mit Momentum aufgebaut ist.
\fi


\subsubsection{Hyperparameter}
Als Hyperparameter werden, in Bezug auf KNN's, meist die Anfangsbedingungen bezeichnet. 
Für diese Hyperparameter gelten keine universellen Werte sondern müssen je nach Daten und Funktion bzw. künstliches Neuroales Netz speziell angepasst und verändert werden. Deshalb gibt es nur einige Regeln und grobe Abschätzungen in welchen Grenzen sich diese Hyperparameter befinden. Zu diesen Hyperparameter gehören folgdende:
\begin{itemize}
\item \textbf{Learningrate},blabalaa
\item \textbf{Dropout}
\item \textbf{Lossfunktion}
\item \textbf{Optimizer}
\item \textbf{Model Achitektur}
\end{itemize}

xxxwird noch angepasst wenn ich weis welche Parameterxxx

\iffalse
Als Hyperparameter werden, in Bezug auf KNN's, meist die Anfangsbedingungen bezeichnet.
Dabei handelt es sich um die Learnrate (eng. Learningrate), der Abdeckunggrad(eng. Dropout), die Verlustfunktion oder auch der Optimizer. In selten Fällen kann die selbst Modelachitektur als Hyperparameter bezeicht werden. Für diese Hyperparameter gelten keine universellen Werte sondern müssen je nach Daten und Funktion bzw. künstliches Neuroales Netz speziell angepasst und verändert werden. Deshalb gibt es nur einige Regeln und grobe Abschätzungen in welchen grenzen sich diese Hyperparameter befinden. 
\fi


\subsection{Zusammenfassung}





\iffalse
Genetische algorithms ist ein sehr erfolgreiches Oprimiungsverfahren welches es erlaubt auch bei schweren Suchräumen lösungen zu finden. Insbesondere wenn keine gradienten berechnet werden können. In diesem Kapitel wurden die Grundlagen der genetischen Grundlagen zusammengefasst. Sie bassieren auf einer Lösungspopulation, die sich im laufe der iterationen dem Optima annähert. Genetische Operatioren ändern die Lösungen. Cross-overoperatoren kobinieren genome zweier Lösungen. Die Mutation fügt den Lösungen Zufälligkeiten hinzu und sollte somit jenden Ort im Lösungsraum erreichen. Der Genotyp oder Das Chromosom einer Lösing wird auf einen Phänotyp, die reale Lösung, abgebildetet, bevor es mit einer Fintessfunktion ausgewertet werden kann. Diese Fittnesfunktion muss sehr sorgfällig ausgearbeitet werden, da sie einen entscheidenden einfluss auf die Suche hat. Die Lösungen mit der höchsten fittnes sind folglich die Eltern der nächsten generation. Sobald eine Generation eine bestimmte Fintess ereicht sprich genug Optimiert wurde ist die beste Lösung gefunden. Somit wurde ein Algorithmus vorgestellt welcher auf ein breites Spektrum von Probkemen anwendbar ist.

Genectic - algorhmen - essential s.19 
\fi
