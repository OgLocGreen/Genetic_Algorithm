{
  "0": {
    "0": {
      "name": 0,
      "learningrate": "0.03222542645148858",
      "dropout": "0.09080164036940153",
      "epoch": "83.11313575484533",
      "batchsize": "57.975735487503854",
      "optimizer": "1.3759835729645",
      "acc": "0.866574074074074",
      "loss": "0.4601021074983809"
    },
    "1": {
      "name": 1,
      "learningrate": "0.025934196669206763",
      "dropout": "0.24527959771028401",
      "epoch": "62.30406279666424",
      "batchsize": "42.17622783799226",
      "optimizer": "0.9755546821271471",
      "acc": "0.8644259259259259",
      "loss": "0.41423918693595463"
    },
    "2": {
      "name": 2,
      "learningrate": "0.023419326125007103",
      "dropout": "0.06415790976857864",
      "epoch": "66.0114296625254",
      "batchsize": "60.40187317607396",
      "optimizer": "1.159527337305669",
      "acc": "0.8640925925925926",
      "loss": "0.42383709226934996"
    },
    "3": {
      "name": 3,
      "learningrate": "0.020298017410219305",
      "dropout": "0.10974042864349763",
      "epoch": "59.313634764916685",
      "batchsize": "43.804232247732656",
      "optimizer": "0.5894650028966234",
      "acc": "0.8637777777777778",
      "loss": "0.4093925916949908"
    },
    "4": {
      "name": 4,
      "learningrate": "0.05089000925653207",
      "dropout": "0.2908781670609659",
      "epoch": "88.26332762022814",
      "batchsize": "48.17057808977437",
      "optimizer": "1.4154541697753977",
      "acc": "0.8633333333333333",
      "loss": "0.46420185327861047"
    },
    "5": {
      "name": 5,
      "learningrate": "0.04046518256615339",
      "dropout": "0.13808767118249593",
      "epoch": "64.10256613847515",
      "batchsize": "45.775024282314604",
      "optimizer": "1.1302559443027604",
      "acc": "0.8629629629629629",
      "loss": "0.4470764289730125"
    },
    "6": {
      "name": 6,
      "learningrate": "0.041973828250987666",
      "dropout": "0.1973256340949881",
      "epoch": "89.71236692835251",
      "batchsize": "39.99432528340698",
      "optimizer": "1.4549817051268106",
      "acc": "0.8628703703703704",
      "loss": "0.480998749177765"
    },
    "7": {
      "name": 7,
      "learningrate": "0.03707245881516731",
      "dropout": "0.22859552658637877",
      "epoch": "60.48496965113489",
      "batchsize": "61.54968607236141",
      "optimizer": "0.5437452474740226",
      "acc": "0.8625",
      "loss": "0.4240365627054815"
    },
    "8": {
      "name": 8,
      "learningrate": "0.06090142329461008",
      "dropout": "0.3056303614762138",
      "epoch": "97.87743268279488",
      "batchsize": "38.92168909381023",
      "optimizer": "0.889286730474451",
      "acc": "0.8623333333333333",
      "loss": "0.4848734023725545"
    },
    "9": {
      "name": 9,
      "learningrate": "0.02487812755379013",
      "dropout": "0.3388557757226878",
      "epoch": "65.848405814424",
      "batchsize": "53.08103110078168",
      "optimizer": "1.1407786616822675",
      "acc": "0.8622592592592593",
      "loss": "0.4101137723017622"
    },
    "10": {
      "name": 10,
      "learningrate": "0.03594791388854267",
      "dropout": "0.06756358923193675",
      "epoch": "77.12948607257012",
      "batchsize": "61.930289699218505",
      "optimizer": "1.1273392403680014",
      "acc": "0.8621111111111112",
      "loss": "0.4666089299586084"
    },
    "11": {
      "name": 11,
      "learningrate": "0.021990047028982145",
      "dropout": "0.3175933740104966",
      "epoch": "71.07211288164245",
      "batchsize": "59.0384910932574",
      "optimizer": "0.9090903302096747",
      "acc": "0.8617962962962963",
      "loss": "0.40921509267665723"
    },
    "12": {
      "name": 12,
      "learningrate": "0.047767563623102485",
      "dropout": "0.2280342974856268",
      "epoch": "50.30844942152027",
      "batchsize": "42.22192436655475",
      "optimizer": "0.9570381076185762",
      "acc": "0.8612407407407408",
      "loss": "0.4345648874198949"
    },
    "13": {
      "name": 13,
      "learningrate": "0.05134707857022188",
      "dropout": "0.06184697239295847",
      "epoch": "75.25018634622965",
      "batchsize": "46.36404499424934",
      "optimizer": "0.6773893683065058",
      "acc": "0.8610555555555556",
      "loss": "0.46999046987074394"
    },
    "14": {
      "name": 14,
      "learningrate": "0.09686332628649717",
      "dropout": "0.1069428329698505",
      "epoch": "67.51319281645982",
      "batchsize": "34.21552794445837",
      "optimizer": "2.858750454773407",
      "acc": "0.8609814814814815",
      "loss": "0.5130282004828807"
    },
    "15": {
      "name": 15,
      "learningrate": "0.023067377569084495",
      "dropout": "0.42953001160247245",
      "epoch": "99.59042290436089",
      "batchsize": "57.43605995619555",
      "optimizer": "0.9317111278937101",
      "acc": "0.8608888888888889",
      "loss": "0.4191963034779937"
    },
    "16": {
      "name": 16,
      "learningrate": "0.0783951163158767",
      "dropout": "0.29119808813866294",
      "epoch": "60.83282222246788",
      "batchsize": "49.06437265541588",
      "optimizer": "0.5517983559773961",
      "acc": "0.8607407407407407",
      "loss": "0.4589071867664655"
    },
    "17": {
      "name": 17,
      "learningrate": "0.02672151040294162",
      "dropout": "0.4379364629469503",
      "epoch": "93.69461124925112",
      "batchsize": "40.77098489105316",
      "optimizer": "1.166542015656995",
      "acc": "0.8606666666666667",
      "loss": "0.4164368373111442"
    },
    "18": {
      "name": 18,
      "learningrate": "0.08187054568160797",
      "dropout": "0.29880725893336607",
      "epoch": "98.40143050416268",
      "batchsize": "57.79548468136592",
      "optimizer": "2.527470775926157",
      "acc": "0.8601296296296296",
      "loss": "0.47008589092890424"
    },
    "19": {
      "name": 19,
      "learningrate": "0.0924823280037996",
      "dropout": "0.28927554798488114",
      "epoch": "77.62317205406134",
      "batchsize": "62.3255942093254",
      "optimizer": "0.9859091962591179",
      "acc": "0.8596481481481482",
      "loss": "0.49614106968155613"
    },
    "20": {
      "name": 20,
      "learningrate": "0.054209110598181176",
      "dropout": "0.14256354543469552",
      "epoch": "90.97225072177204",
      "batchsize": "54.53655879884563",
      "optimizer": "1.4564516860853973",
      "acc": "0.8594814814814815",
      "loss": "0.4887712819289278"
    },
    "21": {
      "name": 21,
      "learningrate": "0.049824178620971195",
      "dropout": "0.23029942749488413",
      "epoch": "90.58651142790887",
      "batchsize": "34.8103390672843",
      "optimizer": "2.579689437270119",
      "acc": "0.8591296296296296",
      "loss": "0.4635416750245624"
    },
    "22": {
      "name": 22,
      "learningrate": "0.06180625562498449",
      "dropout": "0.1248741446945482",
      "epoch": "89.34387164710182",
      "batchsize": "51.12948908329292",
      "optimizer": "0.5000583265772236",
      "acc": "0.8589629629629629",
      "loss": "0.5216409130262004"
    },
    "23": {
      "name": 23,
      "learningrate": "0.07291185272662466",
      "dropout": "0.15741430852659063",
      "epoch": "94.94258947199506",
      "batchsize": "49.735062356539274",
      "optimizer": "0.556970654774054",
      "acc": "0.8587222222222223",
      "loss": "0.5338676329674544"
    },
    "24": {
      "name": 24,
      "learningrate": "0.0632421259777018",
      "dropout": "0.10634032870373797",
      "epoch": "86.31485188743282",
      "batchsize": "55.8497964294564",
      "optimizer": "0.5124722748565711",
      "acc": "0.8584444444444445",
      "loss": "0.5320262761425089"
    },
    "25": {
      "name": 25,
      "learningrate": "0.0823213764174937",
      "dropout": "0.33337760705919617",
      "epoch": "74.97774433850668",
      "batchsize": "40.0543661329596",
      "optimizer": "2.964369707785686",
      "acc": "0.8583888888888889",
      "loss": "0.4731668525845916"
    },
    "26": {
      "name": 26,
      "learningrate": "0.04557565388221749",
      "dropout": "0.10298660529179239",
      "epoch": "83.17989853512796",
      "batchsize": "63.02478844024721",
      "optimizer": "0.524764479905619",
      "acc": "0.8578518518518519",
      "loss": "0.49309452745539173"
    },
    "27": {
      "name": 27,
      "learningrate": "0.06966971055700544",
      "dropout": "0.16930305196973852",
      "epoch": "53.37940011793869",
      "batchsize": "42.87452213559731",
      "optimizer": "1.1377641017392712",
      "acc": "0.8577592592592592",
      "loss": "0.4817377614908748"
    },
    "28": {
      "name": 28,
      "learningrate": "0.032148437444860276",
      "dropout": "0.4266925724651205",
      "epoch": "83.14265395752216",
      "batchsize": "43.727999173645486",
      "optimizer": "2.569447574565445",
      "acc": "0.8577222222222223",
      "loss": "0.41414504637320837"
    },
    "29": {
      "name": 29,
      "learningrate": "0.03546294814446498",
      "dropout": "0.07921879527802096",
      "epoch": "52.42813188127613",
      "batchsize": "36.728769442951695",
      "optimizer": "2.939425761962549",
      "acc": "0.857574074074074",
      "loss": "0.4273160628433581"
    },
    "30": {
      "name": 30,
      "learningrate": "0.08673741231243812",
      "dropout": "0.19442599177234887",
      "epoch": "96.97835671956005",
      "batchsize": "36.77909655031909",
      "optimizer": "2.6012282136315443",
      "acc": "0.8575555555555555",
      "loss": "0.538723530124735"
    },
    "31": {
      "name": 31,
      "learningrate": "0.004585605288539888",
      "dropout": "0.3048013811287077",
      "epoch": "72.25970147586061",
      "batchsize": "59.11387740462145",
      "optimizer": "1.3349193624632427",
      "acc": "0.857462962962963",
      "loss": "0.4089981615719972"
    },
    "32": {
      "name": 32,
      "learningrate": "0.037812637528175375",
      "dropout": "0.26053435069941894",
      "epoch": "65.99627942390688",
      "batchsize": "54.95157566372683",
      "optimizer": "2.879581282973752",
      "acc": "0.8572592592592593",
      "loss": "0.4124201086141445"
    },
    "33": {
      "name": 33,
      "learningrate": "0.09282123310488384",
      "dropout": "0.27669102954991104",
      "epoch": "67.33361913818004",
      "batchsize": "47.68549573600693",
      "optimizer": "1.3894860204971664",
      "acc": "0.8572592592592593",
      "loss": "0.47628076493298566"
    },
    "34": {
      "name": 34,
      "learningrate": "0.04481125202099861",
      "dropout": "0.49743966882630847",
      "epoch": "66.81541458352086",
      "batchsize": "62.307371701391595",
      "optimizer": "2.89036656305664",
      "acc": "0.8569074074074075",
      "loss": "0.40901102472455414"
    },
    "35": {
      "name": 35,
      "learningrate": "0.039681723034388355",
      "dropout": "0.4450823659307201",
      "epoch": "99.34042248369772",
      "batchsize": "58.8994103126805",
      "optimizer": "1.1253829954709995",
      "acc": "0.8568518518518519",
      "loss": "0.4571806795530849"
    },
    "36": {
      "name": 36,
      "learningrate": "0.004287417876735115",
      "dropout": "0.34418456904627764",
      "epoch": "78.59701934145178",
      "batchsize": "33.02675233282953",
      "optimizer": "1.267328498070962",
      "acc": "0.8563703703703703",
      "loss": "0.40931596451776997"
    },
    "37": {
      "name": 37,
      "learningrate": "0.0977972354854585",
      "dropout": "0.1448591432442452",
      "epoch": "88.97008913277",
      "batchsize": "60.584465638270125",
      "optimizer": "2.817293816509875",
      "acc": "0.8563518518518518",
      "loss": "0.4854589749618813"
    },
    "38": {
      "name": 38,
      "learningrate": "0.08890590547556194",
      "dropout": "0.3345976078527482",
      "epoch": "95.94607077296726",
      "batchsize": "41.70440771626642",
      "optimizer": "1.403535438122763",
      "acc": "0.8562777777777778",
      "loss": "0.5183800754480892"
    },
    "39": {
      "name": 39,
      "learningrate": "0.06552320723358639",
      "dropout": "0.4087579794891214",
      "epoch": "79.52008626772616",
      "batchsize": "38.26776245308493",
      "optimizer": "1.2278800852320833",
      "acc": "0.8560740740740741",
      "loss": "0.47313668360864675"
    },
    "40": {
      "name": 40,
      "learningrate": "0.052887001814185486",
      "dropout": "0.4312081770962407",
      "epoch": "71.25257568649181",
      "batchsize": "53.41134318869854",
      "optimizer": "0.6439482172800164",
      "acc": "0.8560740740740741",
      "loss": "0.44952820761115464"
    },
    "41": {
      "name": 41,
      "learningrate": "0.08699725803436933",
      "dropout": "0.40192670000680647",
      "epoch": "69.21971332887946",
      "batchsize": "48.5984119614661",
      "optimizer": "1.2533645918564855",
      "acc": "0.8552037037037037",
      "loss": "0.4510927214600422"
    },
    "42": {
      "name": 42,
      "learningrate": "0.06467778417692137",
      "dropout": "0.4859465895178422",
      "epoch": "52.75217353548594",
      "batchsize": "34.89633755029976",
      "optimizer": "1.086438027383046",
      "acc": "0.8551296296296297",
      "loss": "0.44434101754647715"
    },
    "43": {
      "name": 43,
      "learningrate": "0.09438800369037476",
      "dropout": "0.306133174154651",
      "epoch": "64.96372735293903",
      "batchsize": "43.562464076862625",
      "optimizer": "1.1324569007834122",
      "acc": "0.8546111111111111",
      "loss": "0.5020193166644485"
    },
    "44": {
      "name": 44,
      "learningrate": "0.005876223444862041",
      "dropout": "0.33634846802052515",
      "epoch": "74.03981717608066",
      "batchsize": "54.38296431731011",
      "optimizer": "2.212650039427817",
      "acc": "0.8542222222222222",
      "loss": "0.882049699820854"
    },
    "45": {
      "name": 45,
      "learningrate": "0.00419831322668377",
      "dropout": "0.0633123880597721",
      "epoch": "98.94029597290293",
      "batchsize": "34.77732207272314",
      "optimizer": "2.235260937709566",
      "acc": "0.8541666666666666",
      "loss": "1.2865335168359733"
    },
    "46": {
      "name": 46,
      "learningrate": "0.0015928891893064081",
      "dropout": "0.4482127406820194",
      "epoch": "71.2446696722607",
      "batchsize": "45.133907343633716",
      "optimizer": "2.167536649505077",
      "acc": "0.8540185185185185",
      "loss": "0.6343339439277296"
    },
    "47": {
      "name": 47,
      "learningrate": "0.08754663435975163",
      "dropout": "0.10554153952926801",
      "epoch": "58.78827750828532",
      "batchsize": "47.821710154564926",
      "optimizer": "2.552820891301656",
      "acc": "0.8539074074074074",
      "loss": "0.47454137947161995"
    },
    "48": {
      "name": 48,
      "learningrate": "0.08774939600271578",
      "dropout": "0.444565309302707",
      "epoch": "76.29800908808576",
      "batchsize": "37.88781888752854",
      "optimizer": "1.34767997476071",
      "acc": "0.8538333333333333",
      "loss": "0.47173696555693945"
    },
    "49": {
      "name": 49,
      "learningrate": "0.0371198340565914",
      "dropout": "0.3610740327471064",
      "epoch": "57.747025023979035",
      "batchsize": "35.25059375789995",
      "optimizer": "2.5985936908749765",
      "acc": "0.8536111111111111",
      "loss": "0.4289804813508634"
    },
    "50": {
      "name": 50,
      "learningrate": "0.006264337748814795",
      "dropout": "0.1350366532905687",
      "epoch": "84.28461660244079",
      "batchsize": "60.649471720346895",
      "optimizer": "0.3277762755147975",
      "acc": "0.8531296296296297",
      "loss": "0.6728932726212122"
    },
    "51": {
      "name": 51,
      "learningrate": "0.004490887342580168",
      "dropout": "0.16132670789501122",
      "epoch": "77.06866726011016",
      "batchsize": "37.53909936199868",
      "optimizer": "0.1207248266532529",
      "acc": "0.8526851851851852",
      "loss": "0.6692744894645832"
    },
    "52": {
      "name": 52,
      "learningrate": "0.03123987720539155",
      "dropout": "0.19040582227438063",
      "epoch": "50.69738416416569",
      "batchsize": "53.60034828206025",
      "optimizer": "2.7161885229016645",
      "acc": "0.8524259259259259",
      "loss": "0.4233978817904437"
    },
    "53": {
      "name": 53,
      "learningrate": "0.04772405910881988",
      "dropout": "0.26929917435466616",
      "epoch": "54.62246968773179",
      "batchsize": "54.38065601113438",
      "optimizer": "1.3231968314528557",
      "acc": "0.8507777777777777",
      "loss": "0.4676480651696523"
    },
    "54": {
      "name": 54,
      "learningrate": "0.044802429754233195",
      "dropout": "0.37040621575774657",
      "epoch": "55.023214376655545",
      "batchsize": "35.980293620707684",
      "optimizer": "2.674089897778333",
      "acc": "0.8496296296296296",
      "loss": "0.4268952592699616"
    },
    "55": {
      "name": 55,
      "learningrate": "0.07293912528228723",
      "dropout": "0.08098682555384834",
      "epoch": "99.98502971019704",
      "batchsize": "37.18427075049576",
      "optimizer": "2.901281136163635",
      "acc": "0.8487407407407408",
      "loss": "0.6089085579669034"
    },
    "56": {
      "name": 56,
      "learningrate": "0.005268502425626372",
      "dropout": "0.15086288816430898",
      "epoch": "89.18795874565828",
      "batchsize": "37.33719732654936",
      "optimizer": "2.2654293493785858",
      "acc": "0.8477962962962963",
      "loss": "1.1159560670615347"
    },
    "57": {
      "name": 57,
      "learningrate": "0.08996587723825336",
      "dropout": "0.08340747622856472",
      "epoch": "56.68574920979725",
      "batchsize": "52.07555758267689",
      "optimizer": "2.8854314438121316",
      "acc": "0.8476296296296296",
      "loss": "0.471954422849196"
    },
    "58": {
      "name": 58,
      "learningrate": "0.08282436289874825",
      "dropout": "0.4156970422767948",
      "epoch": "51.58313948752162",
      "batchsize": "49.48547675526788",
      "optimizer": "2.7706407149912073",
      "acc": "0.8460740740740741",
      "loss": "0.44113973957300184"
    },
    "59": {
      "name": 59,
      "learningrate": "0.005130419684346167",
      "dropout": "0.45142387578119153",
      "epoch": "51.15834997514164",
      "batchsize": "53.65402728274056",
      "optimizer": "2.172635886156626",
      "acc": "0.8419629629629629",
      "loss": "0.7313695386725443"
    },
    "60": {
      "name": 60,
      "learningrate": "0.040125456030598375",
      "dropout": "0.11158001039396453",
      "epoch": "98.95626321044008",
      "batchsize": "35.21459378894858",
      "optimizer": "2.838847614187668",
      "acc": "0.8375185185185186",
      "loss": "0.5661204046452487"
    },
    "61": {
      "name": 61,
      "learningrate": "0.005940884641346213",
      "dropout": "0.265429879502143",
      "epoch": "99.5651188843838",
      "batchsize": "54.299866005143556",
      "optimizer": "2.832962485652219",
      "acc": "0.8364074074074074",
      "loss": "0.4692902757459217"
    },
    "62": {
      "name": 62,
      "learningrate": "0.0019691087813547533",
      "dropout": "0.453234181623737",
      "epoch": "56.29437565078525",
      "batchsize": "60.06286364357809",
      "optimizer": "1.3393015375802615",
      "acc": "0.8358333333333333",
      "loss": "0.4809953579990952"
    },
    "63": {
      "name": 63,
      "learningrate": "0.008416722481664335",
      "dropout": "0.05654940253166684",
      "epoch": "73.72169727814556",
      "batchsize": "36.93022963762962",
      "optimizer": "2.1810549897568374",
      "acc": "0.8355370370370371",
      "loss": "1.1712781585079652"
    },
    "64": {
      "name": 64,
      "learningrate": "0.017385103885303312",
      "dropout": "0.13052699946362212",
      "epoch": "56.16075237717045",
      "batchsize": "51.93099861670683",
      "optimizer": "2.134483773121435",
      "acc": "0.8289814814814814",
      "loss": "0.9757386245043189"
    },
    "65": {
      "name": 65,
      "learningrate": "0.08809837630319999",
      "dropout": "0.23034296126409398",
      "epoch": "62.2486113074275",
      "batchsize": "46.96063940180072",
      "optimizer": "2.8297956950256316",
      "acc": "0.8277222222222222",
      "loss": "0.5341026451830511"
    },
    "66": {
      "name": 66,
      "learningrate": "0.003352972445494073",
      "dropout": "0.16812373567634253",
      "epoch": "64.72761942667428",
      "batchsize": "42.28286776733269",
      "optimizer": "2.5462414025767877",
      "acc": "0.8249814814814814",
      "loss": "0.5159349878893958"
    },
    "67": {
      "name": 67,
      "learningrate": "0.013662498974962654",
      "dropout": "0.29796346561127507",
      "epoch": "57.86062230404803",
      "batchsize": "41.15000996016681",
      "optimizer": "2.0362232783636927",
      "acc": "0.8055555555555556",
      "loss": "0.8846695621521384"
    },
    "68": {
      "name": 68,
      "learningrate": "0.020769535835135484",
      "dropout": "0.15076606170958726",
      "epoch": "85.22066678373189",
      "batchsize": "42.0949913737562",
      "optimizer": "2.024882203240765",
      "acc": "0.8015555555555556",
      "loss": "1.187018853859769"
    },
    "69": {
      "name": 69,
      "learningrate": "0.026929208306193487",
      "dropout": "0.3120241001712198",
      "epoch": "80.30106584403424",
      "batchsize": "34.36751860974333",
      "optimizer": "2.27508101237553",
      "acc": "0.7726296296296297",
      "loss": "1.2540734188909883"
    },
    "70": {
      "name": 70,
      "learningrate": "0.022813445306016047",
      "dropout": "0.24709993827215337",
      "epoch": "66.91000612628787",
      "batchsize": "35.58185220629801",
      "optimizer": "2.0818304564494348",
      "acc": "0.757425925925926",
      "loss": "1.3818777693686661"
    },
    "71": {
      "name": 71,
      "learningrate": "0.030308497545924937",
      "dropout": "0.1760079205998309",
      "epoch": "99.22986875772031",
      "batchsize": "53.25157496988755",
      "optimizer": "0.1332494428568437",
      "acc": "0.7132407407407407",
      "loss": "0.8751046349825683"
    },
    "72": {
      "name": 72,
      "learningrate": "0.03520399213491249",
      "dropout": "0.07305051749959396",
      "epoch": "51.63612274076159",
      "batchsize": "42.08399533127821",
      "optimizer": "0.17243869074612128",
      "acc": "0.7040555555555555",
      "loss": "0.9900546492117422"
    },
    "73": {
      "name": 73,
      "learningrate": "0.03710960264897701",
      "dropout": "0.4647836186579008",
      "epoch": "55.12805356467087",
      "batchsize": "45.64180829106486",
      "optimizer": "0.45590128361662474",
      "acc": "0.5111111111111111",
      "loss": "1.3703832948119552"
    },
    "74": {
      "name": 74,
      "learningrate": "0.026920829624995937",
      "dropout": "0.48339161241285533",
      "epoch": "76.436705029764",
      "batchsize": "56.931335489914716",
      "optimizer": "0.14643369046303756",
      "acc": "0.49974074074074076",
      "loss": "1.3969796273266828"
    },
    "75": {
      "name": 75,
      "learningrate": "0.09220110009686114",
      "dropout": "0.494360845658279",
      "epoch": "70.3599802611796",
      "batchsize": "55.93972992341962",
      "optimizer": "1.672774748303727",
      "acc": "0.3795",
      "loss": "9.999622410103127"
    },
    "76": {
      "name": 76,
      "learningrate": "0.0781997170400468",
      "dropout": "0.4376905954580126",
      "epoch": "59.52289097735437",
      "batchsize": "34.88434871945142",
      "optimizer": "1.6389921984726583",
      "acc": "0.36298148148148146",
      "loss": "10.264739464936433"
    },
    "77": {
      "name": 77,
      "learningrate": "0.03524618537832408",
      "dropout": "0.405460368590415",
      "epoch": "87.19588027714056",
      "batchsize": "46.0909574870202",
      "optimizer": "1.6499106731324291",
      "acc": "0.34335185185185185",
      "loss": "10.57445214787236"
    },
    "78": {
      "name": 78,
      "learningrate": "0.027070016023308354",
      "dropout": "0.1365484715322946",
      "epoch": "85.86803836211288",
      "batchsize": "44.77872248026418",
      "optimizer": "2.1262005773362995",
      "acc": "0.3334259259259259",
      "loss": "10.733343444259079"
    },
    "79": {
      "name": 79,
      "learningrate": "0.05970034578834146",
      "dropout": "0.18528963131964715",
      "epoch": "82.67185677906271",
      "batchsize": "44.76690081113547",
      "optimizer": "0.14376197623832487",
      "acc": "0.3277037037037037",
      "loss": "10.835182156315556"
    },
    "80": {
      "name": 80,
      "learningrate": "0.08046777649242577",
      "dropout": "0.3450493715649886",
      "epoch": "98.07744507630477",
      "batchsize": "46.86962053590737",
      "optimizer": "2.488302487742754",
      "acc": "0.3142037037037037",
      "loss": "11.047442237288864"
    },
    "81": {
      "name": 81,
      "learningrate": "0.05442712437765596",
      "dropout": "0.3920009595113474",
      "epoch": "72.18932790856257",
      "batchsize": "60.26396586477333",
      "optimizer": "2.490734725673096",
      "acc": "0.2952592592592593",
      "loss": "11.35809489638717"
    },
    "82": {
      "name": 82,
      "learningrate": "0.0689911088399302",
      "dropout": "0.3841789127029159",
      "epoch": "77.70980935720789",
      "batchsize": "54.05729478653837",
      "optimizer": "1.682935109495589",
      "acc": "0.29264814814814816",
      "loss": "11.400771581296567"
    },
    "83": {
      "name": 83,
      "learningrate": "0.05742219134730876",
      "dropout": "0.2748990414764393",
      "epoch": "72.40932337267948",
      "batchsize": "52.728768693743554",
      "optimizer": "0.03153738569716391",
      "acc": "0.2922037037037037",
      "loss": "11.408328219661007"
    },
    "84": {
      "name": 84,
      "learningrate": "0.08622404588510792",
      "dropout": "0.13946066556762937",
      "epoch": "56.88176656505866",
      "batchsize": "37.214391546544405",
      "optimizer": "1.920097608386424",
      "acc": "0.2842222222222222",
      "loss": "11.530000888965748"
    },
    "85": {
      "name": 85,
      "learningrate": "0.05690431798028152",
      "dropout": "0.42461530840847395",
      "epoch": "93.07120952625954",
      "batchsize": "33.56407369877812",
      "optimizer": "0.21493809297544664",
      "acc": "0.2825185185185185",
      "loss": "11.56427432900888"
    },
    "86": {
      "name": 86,
      "learningrate": "0.07971611057613173",
      "dropout": "0.1965646768266225",
      "epoch": "50.637186615691796",
      "batchsize": "47.785193175150454",
      "optimizer": "0.433717227554304",
      "acc": "0.2688333333333333",
      "loss": "11.78477790041323"
    },
    "87": {
      "name": 87,
      "learningrate": "0.05524615708675236",
      "dropout": "0.26665915575194926",
      "epoch": "60.092136174655835",
      "batchsize": "63.95753641898026",
      "optimizer": "2.2089999481683766",
      "acc": "0.1993888888888889",
      "loss": "12.904326347916214"
    },
    "88": {
      "name": 88,
      "learningrate": "0.09516191319406185",
      "dropout": "0.10888819247159931",
      "epoch": "72.83670407770452",
      "batchsize": "50.0592138521684",
      "optimizer": "0.48800607015099606",
      "acc": "0.19912962962962963",
      "loss": "12.908505113107188"
    },
    "89": {
      "name": 89,
      "learningrate": "0.0929895112759413",
      "dropout": "0.14814162532482764",
      "epoch": "90.00917707215224",
      "batchsize": "36.422340127132586",
      "optimizer": "0.2660560371194983",
      "acc": "0.19787037037037036",
      "loss": "12.928801972000688"
    },
    "90": {
      "name": 90,
      "learningrate": "0.07138999698826963",
      "dropout": "0.4978763556861834",
      "epoch": "54.66093479519453",
      "batchsize": "52.52616448956249",
      "optimizer": "0.05080840970073919",
      "acc": "0.10961111111111112",
      "loss": "14.350081904658564"
    },
    "91": {
      "name": 91,
      "learningrate": "0.09376821292337456",
      "dropout": "0.06688902340171621",
      "epoch": "83.00165520396591",
      "batchsize": "63.464684862928976",
      "optimizer": "1.475800907678824",
      "acc": "0.10018518518518518",
      "loss": "14.50329933279532"
    },
    "92": {
      "name": 92,
      "learningrate": "0.09608364030751243",
      "dropout": "0.08419003947626758",
      "epoch": "70.44205892206911",
      "batchsize": "59.32486467326664",
      "optimizer": "2.148435264856634",
      "acc": "0.10018518518518518",
      "loss": "14.50330083154749"
    },
    "93": {
      "name": 93,
      "learningrate": "0.06123070349319345",
      "dropout": "0.05948504230838254",
      "epoch": "99.68312287774872",
      "batchsize": "42.0610009431711",
      "optimizer": "0.35969547053831497",
      "acc": "0.10011111111111111",
      "loss": "14.50449479534008"
    },
    "94": {
      "name": 94,
      "learningrate": "0.0740386085283673",
      "dropout": "0.09839596943986828",
      "epoch": "56.723741473903786",
      "batchsize": "50.97189961597443",
      "optimizer": "0.3990955466340007",
      "acc": "0.09996296296296296",
      "loss": "14.506882636741356"
    },
    "95": {
      "name": 95,
      "learningrate": "0.07229963310644479",
      "dropout": "0.08227371514841128",
      "epoch": "92.81860054156708",
      "batchsize": "62.120351668395514",
      "optimizer": "0.392639016099385",
      "acc": "0.09996296296296296",
      "loss": "14.506882636741356"
    },
    "96": {
      "name": 96,
      "learningrate": "0.08665440688987058",
      "dropout": "0.06771232607464836",
      "epoch": "85.86652134661243",
      "batchsize": "59.279216994030264",
      "optimizer": "2.282711953135086",
      "acc": "0.09977777777777778",
      "loss": "14.509867480807834"
    },
    "97": {
      "name": 97,
      "learningrate": "0.08332518790255558",
      "dropout": "0.09594348758362745",
      "epoch": "83.2508172650163",
      "batchsize": "38.14598877454684",
      "optimizer": "1.7171561909623647",
      "acc": "0.09968518518518518",
      "loss": "14.511359884756583"
    },
    "98": {
      "name": 98,
      "learningrate": "0.09860790557248389",
      "dropout": "0.19226919777640084",
      "epoch": "86.56995291898787",
      "batchsize": "32.87995653683768",
      "optimizer": "1.904534817809472",
      "acc": "0.09920370370370371",
      "loss": "14.519120458532262"
    },
    "99": {
      "name": 99,
      "learningrate": "0.09983456385635796",
      "dropout": "0.0844366932148555",
      "epoch": "65.13654349738964",
      "batchsize": "32.6378500747007",
      "optimizer": "2.2229664391236037",
      "acc": "0.09920370370370371",
      "loss": "14.519120458532262"
    }
  },
  "1": {
    "0": {
      "name": 0,
      "learningrate": "0.01979",
      "dropout": "0.14414",
      "epoch": "107.84151",
      "batchsize": "77.53705",
      "optimizer": "1.12897",
      "acc": "0.8647037037037038",
      "loss": "0.43672565455127643"
    },
    "1": {
      "name": 1,
      "learningrate": "0.02345",
      "dropout": "0.32874",
      "epoch": "69.44754",
      "batchsize": "51.36525",
      "optimizer": "1.1577",
      "acc": "0.8643148148148149",
      "loss": "0.41031345033204114"
    },
    "2": {
      "name": 2,
      "learningrate": "0.03371",
      "dropout": "0.10749",
      "epoch": "71.6206",
      "batchsize": "47.69792",
      "optimizer": "0.85842",
      "acc": "0.8638333333333333",
      "loss": "0.44531880741207686"
    },
    "3": {
      "name": 3,
      "learningrate": "0.044",
      "dropout": "0.16333",
      "epoch": "63.21357",
      "batchsize": "33.41692",
      "optimizer": "0.53698",
      "acc": "0.8634444444444445",
      "loss": "0.45896934619656315"
    },
    "4": {
      "name": 4,
      "learningrate": "0.09461",
      "dropout": "0.3247",
      "epoch": "91.60966",
      "batchsize": "47.58094",
      "optimizer": "2.59549",
      "acc": "0.8633518518518518",
      "loss": "0.46979512364776044"
    },
    "5": {
      "name": 5,
      "learningrate": "0.025934196669206763",
      "dropout": "0.24527959771028401",
      "epoch": "62.30406279666424",
      "batchsize": "42.17622783799226",
      "optimizer": "0.9755546821271471",
      "acc": "0.8631111111111112",
      "loss": "0.4128793730029353"
    },
    "6": {
      "name": 6,
      "learningrate": "0.0182",
      "dropout": "0.20573",
      "epoch": "50.70281",
      "batchsize": "49.81358",
      "optimizer": "0.70812",
      "acc": "0.863037037037037",
      "loss": "0.4017227733289754"
    },
    "7": {
      "name": 7,
      "learningrate": "0.0749",
      "dropout": "0.16591",
      "epoch": "107.70827",
      "batchsize": "43.41048",
      "optimizer": "0.92521",
      "acc": "0.8621296296296296",
      "loss": "0.5530652725177783"
    },
    "8": {
      "name": 8,
      "learningrate": "0.05798",
      "dropout": "0.37113",
      "epoch": "82.14615",
      "batchsize": "36.29986",
      "optimizer": "1.19099",
      "acc": "0.8620555555555556",
      "loss": "0.4682865928279029"
    },
    "9": {
      "name": 9,
      "learningrate": "0.05059",
      "dropout": "0.29564",
      "epoch": "87.80406",
      "batchsize": "63.82865",
      "optimizer": "0.61045",
      "acc": "0.8620555555555556",
      "loss": "0.4617336213334843"
    },
    "10": {
      "name": 10,
      "learningrate": "0.06256",
      "dropout": "0.18452",
      "epoch": "54.84523",
      "batchsize": "30.77363",
      "optimizer": "0.97166",
      "acc": "0.8620185185185185",
      "loss": "0.45878676374974076"
    },
    "11": {
      "name": 11,
      "learningrate": "0.07083",
      "dropout": "0.33625",
      "epoch": "90.06465",
      "batchsize": "52.47804",
      "optimizer": "0.85008",
      "acc": "0.8618888888888889",
      "loss": "0.506105662215639"
    },
    "12": {
      "name": 12,
      "learningrate": "0.06611",
      "dropout": "0.18427",
      "epoch": "78.54464",
      "batchsize": "50.86048",
      "optimizer": "1.17137",
      "acc": "0.8618333333333333",
      "loss": "0.49025524703220086"
    },
    "13": {
      "name": 13,
      "learningrate": "0.07773",
      "dropout": "0.30247",
      "epoch": "63.40479",
      "batchsize": "47.03454",
      "optimizer": "2.5646",
      "acc": "0.8618148148148148",
      "loss": "0.42238770093299727"
    },
    "14": {
      "name": 14,
      "learningrate": "0.03222542645148858",
      "dropout": "0.09080164036940153",
      "epoch": "83.11313575484533",
      "batchsize": "57.975735487503854",
      "optimizer": "1.3759835729645",
      "acc": "0.8616481481481482",
      "loss": "0.45814873159594005"
    },
    "15": {
      "name": 15,
      "learningrate": "0.02795",
      "dropout": "0.30294",
      "epoch": "72.85104",
      "batchsize": "28.68359",
      "optimizer": "1.02162",
      "acc": "0.8616111111111111",
      "loss": "0.43029558553077557"
    },
    "16": {
      "name": 16,
      "learningrate": "0.03449",
      "dropout": "0.26763",
      "epoch": "99.12023",
      "batchsize": "70.31164",
      "optimizer": "0.84522",
      "acc": "0.8613333333333333",
      "loss": "0.44860885658308314"
    },
    "17": {
      "name": 17,
      "learningrate": "0.03989",
      "dropout": "0.42903",
      "epoch": "107.35271",
      "batchsize": "70.59904",
      "optimizer": "0.65418",
      "acc": "0.8611666666666666",
      "loss": "0.45253070551157"
    },
    "18": {
      "name": 18,
      "learningrate": "0.02731",
      "dropout": "0.30073",
      "epoch": "69.27257",
      "batchsize": "52.95009",
      "optimizer": "0.72145",
      "acc": "0.861037037037037",
      "loss": "0.4204737622870339"
    },
    "19": {
      "name": 19,
      "learningrate": "0.08187",
      "dropout": "0.22411",
      "epoch": "78.22823",
      "batchsize": "57.63161",
      "optimizer": "1.17262",
      "acc": "0.8608518518518519",
      "loss": "0.4951372866431872"
    },
    "20": {
      "name": 20,
      "learningrate": "0.04881",
      "dropout": "0.04752",
      "epoch": "63.99715",
      "batchsize": "43.51633",
      "optimizer": "0.78773",
      "acc": "0.8608148148148148",
      "loss": "0.4886600450299404"
    },
    "21": {
      "name": 21,
      "learningrate": "0.04954",
      "dropout": "0.05315",
      "epoch": "78.00702",
      "batchsize": "33.0029",
      "optimizer": "1.3803",
      "acc": "0.8606481481481482",
      "loss": "0.5179455787815429"
    },
    "22": {
      "name": 22,
      "learningrate": "0.05536",
      "dropout": "0.0567",
      "epoch": "69.62077",
      "batchsize": "60.61154",
      "optimizer": "1.22171",
      "acc": "0.8606111111111111",
      "loss": "0.49084940690243684"
    },
    "23": {
      "name": 23,
      "learningrate": "0.06833",
      "dropout": "0.29522",
      "epoch": "97.39684",
      "batchsize": "42.77579",
      "optimizer": "0.63644",
      "acc": "0.8602037037037037",
      "loss": "0.5067863797644774"
    },
    "24": {
      "name": 24,
      "learningrate": "0.06309",
      "dropout": "0.15978",
      "epoch": "104.25762",
      "batchsize": "47.36009",
      "optimizer": "0.54437",
      "acc": "0.8602037037037037",
      "loss": "0.5156035341642521"
    },
    "25": {
      "name": 25,
      "learningrate": "0.05524",
      "dropout": "0.10643",
      "epoch": "44.76065",
      "batchsize": "35.91759",
      "optimizer": "0.54691",
      "acc": "0.8601111111111112",
      "loss": "0.4541179067514561"
    },
    "26": {
      "name": 26,
      "learningrate": "0.0594",
      "dropout": "0.0755",
      "epoch": "71.24091",
      "batchsize": "45.70279",
      "optimizer": "0.52536",
      "acc": "0.8599814814814815",
      "loss": "0.4976435571798572"
    },
    "27": {
      "name": 27,
      "learningrate": "0.05297",
      "dropout": "0.21946",
      "epoch": "54.06661",
      "batchsize": "45.25906",
      "optimizer": "0.92459",
      "acc": "0.8599259259259259",
      "loss": "0.43547659168530395"
    },
    "28": {
      "name": 28,
      "learningrate": "0.04449",
      "dropout": "0.34542",
      "epoch": "65.55712",
      "batchsize": "36.45178",
      "optimizer": "0.82823",
      "acc": "0.8597962962962963",
      "loss": "0.4368938579493099"
    },
    "29": {
      "name": 29,
      "learningrate": "0.09567",
      "dropout": "0.25331",
      "epoch": "59.80416",
      "batchsize": "30.0939",
      "optimizer": "3.38624",
      "acc": "0.8596111111111111",
      "loss": "0.4853256388902664"
    },
    "30": {
      "name": 30,
      "learningrate": "0.05508",
      "dropout": "0.22799",
      "epoch": "57.40047",
      "batchsize": "65.52274",
      "optimizer": "0.99841",
      "acc": "0.8593703703703703",
      "loss": "0.449587328977055"
    },
    "31": {
      "name": 31,
      "learningrate": "0.09575",
      "dropout": "0.23211",
      "epoch": "86.31791",
      "batchsize": "60.61657",
      "optimizer": "3.00505",
      "acc": "0.8593518518518518",
      "loss": "0.47975166151920956"
    },
    "32": {
      "name": 32,
      "learningrate": "0.02207",
      "dropout": "0.49619",
      "epoch": "86.77387",
      "batchsize": "41.17173",
      "optimizer": "1.04066",
      "acc": "0.8593148148148149",
      "loss": "0.4180294399438081"
    },
    "33": {
      "name": 33,
      "learningrate": "0.04694",
      "dropout": "0.34965",
      "epoch": "64.56393",
      "batchsize": "47.43882",
      "optimizer": "0.63727",
      "acc": "0.8585925925925926",
      "loss": "0.44535204827343977"
    },
    "34": {
      "name": 34,
      "learningrate": "0.02583",
      "dropout": "0.52422",
      "epoch": "74.52764",
      "batchsize": "63.58914",
      "optimizer": "1.09578",
      "acc": "0.8584814814814815",
      "loss": "0.4130317077371809"
    },
    "35": {
      "name": 35,
      "learningrate": "0.02667",
      "dropout": "0.29466",
      "epoch": "61.06874",
      "batchsize": "46.74821",
      "optimizer": "1.2554",
      "acc": "0.8580925925925926",
      "loss": "0.4449050190007245"
    },
    "36": {
      "name": 36,
      "learningrate": "0.04159",
      "dropout": "0.42843",
      "epoch": "92.55982",
      "batchsize": "47.42669",
      "optimizer": "3.10914",
      "acc": "0.8580555555555556",
      "loss": "0.42413539845855147"
    },
    "37": {
      "name": 37,
      "learningrate": "0.04121",
      "dropout": "0.35431",
      "epoch": "47.0807",
      "batchsize": "51.79161",
      "optimizer": "0.82436",
      "acc": "0.8579629629629629",
      "loss": "0.41976691762606305"
    },
    "38": {
      "name": 38,
      "learningrate": "0.09272",
      "dropout": "0.10163",
      "epoch": "62.27102",
      "batchsize": "29.0792",
      "optimizer": "2.58695",
      "acc": "0.8579074074074075",
      "loss": "0.5341377864303413"
    },
    "39": {
      "name": 39,
      "learningrate": "0.09974",
      "dropout": "0.30277",
      "epoch": "100.02958",
      "batchsize": "48.02615",
      "optimizer": "1.15726",
      "acc": "0.8577037037037037",
      "loss": "0.5093733900310816"
    },
    "40": {
      "name": 40,
      "learningrate": "0.07138",
      "dropout": "0.11287",
      "epoch": "111.25878",
      "batchsize": "29.63246",
      "optimizer": "0.66586",
      "acc": "0.8574074074074074",
      "loss": "0.5796940745501606"
    },
    "41": {
      "name": 41,
      "learningrate": "0.00501",
      "dropout": "0.1205",
      "epoch": "55.02969",
      "batchsize": "40.75647",
      "optimizer": "0.93716",
      "acc": "0.8573518518518518",
      "loss": "0.41231997321711644"
    },
    "42": {
      "name": 42,
      "learningrate": "0.05442",
      "dropout": "0.50352",
      "epoch": "65.4663",
      "batchsize": "42.18544",
      "optimizer": "2.75713",
      "acc": "0.856925925925926",
      "loss": "0.4221215694524624"
    },
    "43": {
      "name": 43,
      "learningrate": "0.03192",
      "dropout": "0.41708",
      "epoch": "72.80229",
      "batchsize": "47.33915",
      "optimizer": "1.28567",
      "acc": "0.8568703703703704",
      "loss": "0.4262932774601159"
    },
    "44": {
      "name": 44,
      "learningrate": "0.04648",
      "dropout": "0.42222",
      "epoch": "65.46705",
      "batchsize": "60.29997",
      "optimizer": "2.60876",
      "acc": "0.8564814814814815",
      "loss": "0.40911766481399536"
    },
    "45": {
      "name": 45,
      "learningrate": "0.02871",
      "dropout": "0.1801",
      "epoch": "88.06762",
      "batchsize": "28.68342",
      "optimizer": "3.73601",
      "acc": "0.8563703703703703",
      "loss": "0.4532252901858754"
    },
    "46": {
      "name": 46,
      "learningrate": "0.00337",
      "dropout": "0.16611",
      "epoch": "62.31082",
      "batchsize": "37.32963",
      "optimizer": "0.11724",
      "acc": "0.8559629629629629",
      "loss": "0.6520040742225117"
    },
    "47": {
      "name": 47,
      "learningrate": "0.04308",
      "dropout": "0.0627",
      "epoch": "119.7515",
      "batchsize": "68.27318",
      "optimizer": "2.7066",
      "acc": "0.8552592592592593",
      "loss": "0.45993726374264116"
    },
    "48": {
      "name": 48,
      "learningrate": "0.03832",
      "dropout": "0.23175",
      "epoch": "75.32222",
      "batchsize": "66.73737",
      "optimizer": "3.62744",
      "acc": "0.8552592592592593",
      "loss": "0.42312340835730233"
    },
    "49": {
      "name": 49,
      "learningrate": "0.06214",
      "dropout": "0.43418",
      "epoch": "66.14057",
      "batchsize": "42.32398",
      "optimizer": "0.6048",
      "acc": "0.8548888888888889",
      "loss": "0.45324705898320233"
    },
    "50": {
      "name": 50,
      "learningrate": "0.02278",
      "dropout": "0.23699",
      "epoch": "58.62044",
      "batchsize": "74.10175",
      "optimizer": "0.98218",
      "acc": "0.8547777777777777",
      "loss": "0.42530743877313754"
    },
    "51": {
      "name": 51,
      "learningrate": "0.04495",
      "dropout": "0.51967",
      "epoch": "62.62496",
      "batchsize": "45.26362",
      "optimizer": "0.78891",
      "acc": "0.8539444444444444",
      "loss": "0.4292441855426188"
    },
    "52": {
      "name": 52,
      "learningrate": "0.03708",
      "dropout": "0.40082",
      "epoch": "45.24286",
      "batchsize": "33.687",
      "optimizer": "2.97633",
      "acc": "0.8539074074074074",
      "loss": "0.4230109903746181"
    },
    "53": {
      "name": 53,
      "learningrate": "0.06827",
      "dropout": "0.38123",
      "epoch": "56.94429",
      "batchsize": "51.06175",
      "optimizer": "0.52207",
      "acc": "0.8536481481481482",
      "loss": "0.46030800040121433"
    },
    "54": {
      "name": 54,
      "learningrate": "0.00403",
      "dropout": "0.3166",
      "epoch": "83.25876",
      "batchsize": "32.03433",
      "optimizer": "1.54445",
      "acc": "0.851462962962963",
      "loss": "1.05724463762067"
    },
    "55": {
      "name": 55,
      "learningrate": "0.05938",
      "dropout": "0.36807",
      "epoch": "66.21133",
      "batchsize": "55.14968",
      "optimizer": "3.44967",
      "acc": "0.8513333333333334",
      "loss": "0.44361273014986957"
    },
    "56": {
      "name": 56,
      "learningrate": "0.01489",
      "dropout": "0.37954",
      "epoch": "75.60282",
      "batchsize": "41.30631",
      "optimizer": "2.87835",
      "acc": "0.8503333333333334",
      "loss": "0.4200442224431921"
    },
    "57": {
      "name": 57,
      "learningrate": "0.09285",
      "dropout": "0.40068",
      "epoch": "58.07593",
      "batchsize": "48.16874",
      "optimizer": "2.89094",
      "acc": "0.8483703703703703",
      "loss": "0.4697263216288001"
    },
    "58": {
      "name": 58,
      "learningrate": "0.06527",
      "dropout": "0.11416",
      "epoch": "60.47374",
      "batchsize": "43.77405",
      "optimizer": "2.90346",
      "acc": "0.8456851851851852",
      "loss": "0.5064026357531548"
    },
    "59": {
      "name": 59,
      "learningrate": "0.06846",
      "dropout": "0.06112",
      "epoch": "57.59624",
      "batchsize": "69.45632",
      "optimizer": "3.40164",
      "acc": "0.8446296296296296",
      "loss": "0.4599261462467688"
    },
    "60": {
      "name": 60,
      "learningrate": "0.00657",
      "dropout": "0.16348",
      "epoch": "60.99413",
      "batchsize": "33.49115",
      "optimizer": "2.68682",
      "acc": "0.8437962962962963",
      "loss": "0.45314806811456326"
    },
    "61": {
      "name": 61,
      "learningrate": "0.03735",
      "dropout": "0.07613",
      "epoch": "75.30284",
      "batchsize": "54.90316",
      "optimizer": "3.3702",
      "acc": "0.8431851851851851",
      "loss": "0.4819675066758085"
    },
    "62": {
      "name": 62,
      "learningrate": "0.03485",
      "dropout": "0.60733",
      "epoch": "49.72014",
      "batchsize": "44.52887",
      "optimizer": "3.29405",
      "acc": "0.842925925925926",
      "loss": "0.43735937235090466"
    },
    "63": {
      "name": 63,
      "learningrate": "0.00382",
      "dropout": "0.11142",
      "epoch": "59.0919",
      "batchsize": "25.15609",
      "optimizer": "2.22722",
      "acc": "0.8422777777777778",
      "loss": "1.2186217196859694"
    },
    "64": {
      "name": 64,
      "learningrate": "0.0061",
      "dropout": "0.25702",
      "epoch": "67.89228",
      "batchsize": "43.51831",
      "optimizer": "2.61155",
      "acc": "0.8380185185185185",
      "loss": "0.47178660420135216"
    },
    "65": {
      "name": 65,
      "learningrate": "0.00397",
      "dropout": "0.27804",
      "epoch": "56.31131",
      "batchsize": "49.57556",
      "optimizer": "1.88076",
      "acc": "0.8377407407407408",
      "loss": "0.7412407360435636"
    },
    "66": {
      "name": 66,
      "learningrate": "0.008209687133575833",
      "dropout": "0.11647334771951971",
      "epoch": "9.237436454087987",
      "batchsize": "51.40627230555972",
      "optimizer": "2.078763770396401",
      "acc": "0.8347962962962963",
      "loss": "0.5462421258687973"
    },
    "67": {
      "name": 67,
      "learningrate": "0.00506",
      "dropout": "0.37782",
      "epoch": "62.35827",
      "batchsize": "47.48988",
      "optimizer": "2.79552",
      "acc": "0.8273333333333334",
      "loss": "0.5043712592654758"
    },
    "68": {
      "name": 68,
      "learningrate": "0.00328",
      "dropout": "0.18081",
      "epoch": "39.27123",
      "batchsize": "36.16322",
      "optimizer": "2.81142",
      "acc": "0.8138518518518518",
      "loss": "0.5558372891037553"
    },
    "69": {
      "name": 69,
      "learningrate": "0.02174",
      "dropout": "0.06883",
      "epoch": "72.36512",
      "batchsize": "34.62796",
      "optimizer": "1.80952",
      "acc": "0.7988148148148149",
      "loss": "1.290363275534439"
    },
    "70": {
      "name": 70,
      "learningrate": "0.02811",
      "dropout": "0.0973",
      "epoch": "59.9278",
      "batchsize": "38.45571",
      "optimizer": "0.31574",
      "acc": "0.7943518518518519",
      "loss": "0.7859096237641794"
    },
    "71": {
      "name": 71,
      "learningrate": "0.01966",
      "dropout": "0.0982",
      "epoch": "107.17684",
      "batchsize": "51.32913",
      "optimizer": "1.50934",
      "acc": "0.7887037037037037",
      "loss": "1.333645207171087"
    },
    "72": {
      "name": 72,
      "learningrate": "0.01764",
      "dropout": "0.44072",
      "epoch": "39.61715",
      "batchsize": "43.15903",
      "optimizer": "2.36397",
      "acc": "0.7563333333333333",
      "loss": "0.9795642283492618"
    },
    "73": {
      "name": 73,
      "learningrate": "0.02934",
      "dropout": "0.28352",
      "epoch": "91.75087",
      "batchsize": "44.08507",
      "optimizer": "0.08634",
      "acc": "0.6096481481481482",
      "loss": "0.9971577328222769"
    },
    "74": {
      "name": 74,
      "learningrate": "0.04869851424899843",
      "dropout": "0.4333418695289836",
      "epoch": "6.683601040526819",
      "batchsize": "56.18032663550929",
      "optimizer": "0.034530336196123",
      "acc": "0.598",
      "loss": "1.086615802270395"
    },
    "75": {
      "name": 75,
      "learningrate": "0.08207",
      "dropout": "0.27354",
      "epoch": "90.43244",
      "batchsize": "49.06636",
      "optimizer": "1.57577",
      "acc": "0.453537037037037",
      "loss": "8.80589299858941"
    },
    "76": {
      "name": 76,
      "learningrate": "0.05746",
      "dropout": "0.09188",
      "epoch": "71.44274",
      "batchsize": "40.20877",
      "optimizer": "0.47057",
      "acc": "0.43272222222222223",
      "loss": "2.1079767030786587"
    },
    "77": {
      "name": 77,
      "learningrate": "0.0279",
      "dropout": "0.20852",
      "epoch": "57.32192",
      "batchsize": "32.88387",
      "optimizer": "2.49556",
      "acc": "0.4246666666666667",
      "loss": "9.247865096339472"
    },
    "78": {
      "name": 78,
      "learningrate": "0.03152",
      "dropout": "0.16858",
      "epoch": "110.91876",
      "batchsize": "34.33843",
      "optimizer": "1.58111",
      "acc": "0.41674074074074074",
      "loss": "9.3926677508884"
    },
    "79": {
      "name": 79,
      "learningrate": "0.07891",
      "dropout": "0.25976",
      "epoch": "123.55958",
      "batchsize": "70.46891",
      "optimizer": "2.37381",
      "acc": "0.37164814814814817",
      "loss": "10.117800233911584"
    },
    "80": {
      "name": 80,
      "learningrate": "0.05886",
      "dropout": "0.33494",
      "epoch": "46.32145",
      "batchsize": "58.40221",
      "optimizer": "1.69426",
      "acc": "0.36544444444444446",
      "loss": "10.223413770605017"
    },
    "81": {
      "name": 81,
      "learningrate": "0.08924",
      "dropout": "0.36733",
      "epoch": "111.0353",
      "batchsize": "38.81173",
      "optimizer": "2.18835",
      "acc": "0.2924074074074074",
      "loss": "11.404833872477214"
    },
    "82": {
      "name": 82,
      "learningrate": "0.06584",
      "dropout": "0.40893",
      "epoch": "39.41335",
      "batchsize": "66.30949",
      "optimizer": "1.56987",
      "acc": "0.2715",
      "loss": "11.739364644085919"
    },
    "83": {
      "name": 83,
      "learningrate": "0.03613",
      "dropout": "0.3754",
      "epoch": "61.86875",
      "batchsize": "37.86108",
      "optimizer": "2.19542",
      "acc": "0.2617037037037037",
      "loss": "11.897776511015715"
    },
    "84": {
      "name": 84,
      "learningrate": "0.1181",
      "dropout": "0.17394",
      "epoch": "93.15864",
      "batchsize": "66.05733",
      "optimizer": "1.00984",
      "acc": "0.20014814814814816",
      "loss": "12.891524388631185"
    },
    "85": {
      "name": 85,
      "learningrate": "0.11331",
      "dropout": "0.13015",
      "epoch": "108.87087",
      "batchsize": "35.69101",
      "optimizer": "0.99203",
      "acc": "0.19975925925925925",
      "loss": "12.898356924551505"
    },
    "86": {
      "name": 86,
      "learningrate": "0.10845",
      "dropout": "0.36926",
      "epoch": "48.85006",
      "batchsize": "42.5219",
      "optimizer": "1.74134",
      "acc": "0.19590740740740742",
      "loss": "12.959924777278193"
    },
    "87": {
      "name": 87,
      "learningrate": "0.06218",
      "dropout": "0.06535",
      "epoch": "99.29984",
      "batchsize": "35.42831",
      "optimizer": "2.43873",
      "acc": "0.10074074074074074",
      "loss": "14.49434634427671"
    },
    "88": {
      "name": 88,
      "learningrate": "0.11238",
      "dropout": "0.10846",
      "epoch": "85.35525",
      "batchsize": "27.27211",
      "optimizer": "1.37092",
      "acc": "0.1002962962962963",
      "loss": "14.501509959468136"
    },
    "89": {
      "name": 89,
      "learningrate": "0.10695",
      "dropout": "0.08509",
      "epoch": "64.43641",
      "batchsize": "59.10587",
      "optimizer": "0.39304",
      "acc": "0.10018518518518518",
      "loss": "14.503300856131094"
    },
    "90": {
      "name": 90,
      "learningrate": "0.03433",
      "dropout": "0.05063",
      "epoch": "121.64993",
      "batchsize": "34.97536",
      "optimizer": "1.77922",
      "acc": "0.10018518518518518",
      "loss": "14.503300856131094"
    },
    "91": {
      "name": 91,
      "learningrate": "0.0601",
      "dropout": "0.08972",
      "epoch": "101.21922",
      "batchsize": "53.30552",
      "optimizer": "2.36938",
      "acc": "0.10018518518518518",
      "loss": "14.50330083154749"
    },
    "92": {
      "name": 92,
      "learningrate": "0.0436",
      "dropout": "0.13257",
      "epoch": "60.19132",
      "batchsize": "33.27919",
      "optimizer": "1.84878",
      "acc": "0.10018518518518518",
      "loss": "14.503300856131094"
    },
    "93": {
      "name": 93,
      "learningrate": "0.06139",
      "dropout": "0.07449",
      "epoch": "103.20801",
      "batchsize": "29.00978",
      "optimizer": "1.56802",
      "acc": "0.10011111111111111",
      "loss": "14.50449479534008"
    },
    "94": {
      "name": 94,
      "learningrate": "0.09253",
      "dropout": "0.10746",
      "epoch": "61.9342",
      "batchsize": "42.39057",
      "optimizer": "0.41821",
      "acc": "0.09996296296296296",
      "loss": "14.506882636741356"
    },
    "95": {
      "name": 95,
      "learningrate": "0.07162",
      "dropout": "0.10385",
      "epoch": "72.0926",
      "batchsize": "58.24052",
      "optimizer": "2.43314",
      "acc": "0.09985185185185186",
      "loss": "14.50867355742278"
    }
  },
  "2": {
    "0": {
      "name": 0,
      "learningrate": "0.01955",
      "dropout": "0.11553",
      "epoch": "71.23894",
      "batchsize": "50.8927",
      "optimizer": "0.66212",
      "acc": "0.8658703703703704",
      "loss": "0.4163042431826945"
    },
    "1": {
      "name": 1,
      "learningrate": "0.03103",
      "dropout": "0.30721",
      "epoch": "80.35501",
      "batchsize": "52.11187",
      "optimizer": "0.94119",
      "acc": "0.8650555555555556",
      "loss": "0.4282873456213209"
    },
    "2": {
      "name": 2,
      "learningrate": "0.01979",
      "dropout": "0.14414",
      "epoch": "107.84151",
      "batchsize": "77.53705",
      "optimizer": "1.12897",
      "acc": "0.8646296296296296",
      "loss": "0.42559476738285135"
    },
    "3": {
      "name": 3,
      "learningrate": "0.0395",
      "dropout": "0.29306",
      "epoch": "46.50839",
      "batchsize": "43.19777",
      "optimizer": "0.67154",
      "acc": "0.8642222222222222",
      "loss": "0.41881867577853027"
    },
    "4": {
      "name": 4,
      "learningrate": "0.02345",
      "dropout": "0.32874",
      "epoch": "69.44754",
      "batchsize": "51.36525",
      "optimizer": "1.1577",
      "acc": "0.8631481481481481",
      "loss": "0.40720815233831054"
    },
    "5": {
      "name": 5,
      "learningrate": "0.03943",
      "dropout": "0.18619",
      "epoch": "59.84456",
      "batchsize": "26.86222",
      "optimizer": "0.78642",
      "acc": "0.8630555555555556",
      "loss": "0.44296386910588653"
    },
    "6": {
      "name": 6,
      "learningrate": "0.03112",
      "dropout": "0.2994",
      "epoch": "53.2414",
      "batchsize": "36.46009",
      "optimizer": "1.4769",
      "acc": "0.8629814814814815",
      "loss": "0.41003718066215517"
    },
    "7": {
      "name": 7,
      "learningrate": "0.0224",
      "dropout": "0.15315",
      "epoch": "61.02674",
      "batchsize": "63.75255",
      "optimizer": "1.39255",
      "acc": "0.8629259259259259",
      "loss": "0.4156172145075268"
    },
    "8": {
      "name": 8,
      "learningrate": "0.0633",
      "dropout": "0.25722",
      "epoch": "63.77957",
      "batchsize": "54.69074",
      "optimizer": "3.23324",
      "acc": "0.8627037037037038",
      "loss": "0.41827959817427174"
    },
    "9": {
      "name": 9,
      "learningrate": "0.04072",
      "dropout": "0.17305",
      "epoch": "44.26695",
      "batchsize": "33.85132",
      "optimizer": "0.89826",
      "acc": "0.8625",
      "loss": "0.42431573548802626"
    },
    "10": {
      "name": 10,
      "learningrate": "0.02161",
      "dropout": "0.06151",
      "epoch": "54.45039",
      "batchsize": "72.50201",
      "optimizer": "1.24677",
      "acc": "0.8624074074074074",
      "loss": "0.41060833315937606"
    },
    "11": {
      "name": 11,
      "learningrate": "0.11573",
      "dropout": "0.25404",
      "epoch": "89.2426",
      "batchsize": "46.75494",
      "optimizer": "4.366",
      "acc": "0.8623888888888889",
      "loss": "0.495965148717165"
    },
    "12": {
      "name": 12,
      "learningrate": "0.0271",
      "dropout": "0.36892",
      "epoch": "73.57972",
      "batchsize": "32.71653",
      "optimizer": "0.76396",
      "acc": "0.8620925925925926",
      "loss": "0.421964744300754"
    },
    "13": {
      "name": 13,
      "learningrate": "0.11358",
      "dropout": "0.38053",
      "epoch": "97.47651",
      "batchsize": "37.29645",
      "optimizer": "3.34922",
      "acc": "0.862",
      "loss": "0.4903692712717586"
    },
    "14": {
      "name": 14,
      "learningrate": "0.06637",
      "dropout": "0.17939",
      "epoch": "111.8527",
      "batchsize": "67.70764",
      "optimizer": "0.5493",
      "acc": "0.8618333333333333",
      "loss": "0.5105097994429094"
    },
    "15": {
      "name": 15,
      "learningrate": "0.03204",
      "dropout": "0.34406",
      "epoch": "80.22072",
      "batchsize": "22.75805",
      "optimizer": "1.22479",
      "acc": "0.8617222222222222",
      "loss": "0.43276776077129225"
    },
    "16": {
      "name": 16,
      "learningrate": "0.02508",
      "dropout": "0.27426",
      "epoch": "64.5187",
      "batchsize": "46.36367",
      "optimizer": "1.4474",
      "acc": "0.8616481481481482",
      "loss": "0.4122455368395205"
    },
    "17": {
      "name": 17,
      "learningrate": "0.01998",
      "dropout": "0.37996",
      "epoch": "88.22704",
      "batchsize": "64.45764",
      "optimizer": "0.76917",
      "acc": "0.8616481481481482",
      "loss": "0.4067412569280024"
    },
    "18": {
      "name": 18,
      "learningrate": "0.05454",
      "dropout": "0.11444",
      "epoch": "89.07724",
      "batchsize": "49.02064",
      "optimizer": "1.06625",
      "acc": "0.8615",
      "loss": "0.5118882942519806"
    },
    "19": {
      "name": 19,
      "learningrate": "0.05015",
      "dropout": "0.38217",
      "epoch": "88.09479",
      "batchsize": "45.46022",
      "optimizer": "1.05843",
      "acc": "0.8613518518518518",
      "loss": "0.4548900242293323"
    },
    "20": {
      "name": 20,
      "learningrate": "0.04761",
      "dropout": "0.27377",
      "epoch": "99.89845",
      "batchsize": "75.38421",
      "optimizer": "0.78826",
      "acc": "0.8613148148148149",
      "loss": "0.47497156619915254"
    },
    "21": {
      "name": 21,
      "learningrate": "0.05107",
      "dropout": "0.04246",
      "epoch": "79.75821",
      "batchsize": "49.45845",
      "optimizer": "1.16047",
      "acc": "0.8612962962962963",
      "loss": "0.5005888081700713"
    },
    "22": {
      "name": 22,
      "learningrate": "0.0674",
      "dropout": "0.28634",
      "epoch": "107.41795",
      "batchsize": "61.4703",
      "optimizer": "0.79675",
      "acc": "0.8611851851851852",
      "loss": "0.5085231236793377"
    },
    "23": {
      "name": 23,
      "learningrate": "0.0586",
      "dropout": "0.32444",
      "epoch": "64.60372",
      "batchsize": "51.83421",
      "optimizer": "0.57543",
      "acc": "0.8609259259259259",
      "loss": "0.4627343586285909"
    },
    "24": {
      "name": 24,
      "learningrate": "0.05374",
      "dropout": "0.06636",
      "epoch": "53.67107",
      "batchsize": "33.29868",
      "optimizer": "1.26755",
      "acc": "0.8608518518518519",
      "loss": "0.48861351837273"
    },
    "25": {
      "name": 25,
      "learningrate": "0.04061",
      "dropout": "0.11932",
      "epoch": "88.94636",
      "batchsize": "24.68975",
      "optimizer": "1.07852",
      "acc": "0.8606111111111111",
      "loss": "0.4879505875640445"
    },
    "26": {
      "name": 26,
      "learningrate": "0.02897",
      "dropout": "0.26484",
      "epoch": "82.30334",
      "batchsize": "50.31618",
      "optimizer": "0.60482",
      "acc": "0.8606111111111111",
      "loss": "0.4338876510130035"
    },
    "27": {
      "name": 27,
      "learningrate": "0.02119",
      "dropout": "0.36956",
      "epoch": "80.18507",
      "batchsize": "61.45493",
      "optimizer": "0.97073",
      "acc": "0.8605",
      "loss": "0.4144886265926891"
    },
    "28": {
      "name": 28,
      "learningrate": "0.03417",
      "dropout": "0.36815",
      "epoch": "56.94446",
      "batchsize": "43.34537",
      "optimizer": "0.9762",
      "acc": "0.8604259259259259",
      "loss": "0.41701890602376723"
    },
    "29": {
      "name": 29,
      "learningrate": "0.02543",
      "dropout": "0.29768",
      "epoch": "59.64738",
      "batchsize": "68.59505",
      "optimizer": "0.90286",
      "acc": "0.8603518518518518",
      "loss": "0.4161634887324439"
    },
    "30": {
      "name": 30,
      "learningrate": "0.03482",
      "dropout": "0.32052",
      "epoch": "45.88091",
      "batchsize": "53.24603",
      "optimizer": "1.15692",
      "acc": "0.8602037037037037",
      "loss": "0.4142148556532683"
    },
    "31": {
      "name": 31,
      "learningrate": "0.07639",
      "dropout": "0.18893",
      "epoch": "79.09951",
      "batchsize": "57.71209",
      "optimizer": "1.31793",
      "acc": "0.8601296296296296",
      "loss": "0.4985910505497897"
    },
    "32": {
      "name": 32,
      "learningrate": "0.04652",
      "dropout": "0.38933",
      "epoch": "46.40036",
      "batchsize": "38.12671",
      "optimizer": "0.85629",
      "acc": "0.8598888888888889",
      "loss": "0.42051364059911833"
    },
    "33": {
      "name": 33,
      "learningrate": "0.04418",
      "dropout": "0.37854",
      "epoch": "121.69774",
      "batchsize": "44.29195",
      "optimizer": "1.41286",
      "acc": "0.8598518518518519",
      "loss": "0.46937097669751554"
    },
    "34": {
      "name": 34,
      "learningrate": "0.05935",
      "dropout": "0.0588",
      "epoch": "114.0349",
      "batchsize": "52.16978",
      "optimizer": "0.76262",
      "acc": "0.8597777777777778",
      "loss": "0.585148614310556"
    },
    "35": {
      "name": 35,
      "learningrate": "0.06785",
      "dropout": "0.243",
      "epoch": "57.12384",
      "batchsize": "37.40772",
      "optimizer": "4.32143",
      "acc": "0.8596851851851852",
      "loss": "0.43991704397952114"
    },
    "36": {
      "name": 36,
      "learningrate": "0.05859",
      "dropout": "0.14877",
      "epoch": "82.06261",
      "batchsize": "39.42219",
      "optimizer": "1.05495",
      "acc": "0.8596296296296296",
      "loss": "0.5097422091712555"
    },
    "37": {
      "name": 37,
      "learningrate": "0.07344",
      "dropout": "0.13232",
      "epoch": "101.86776",
      "batchsize": "83.54511",
      "optimizer": "0.69574",
      "acc": "0.859537037037037",
      "loss": "0.5618331805379302"
    },
    "38": {
      "name": 38,
      "learningrate": "0.04081",
      "dropout": "0.21991",
      "epoch": "47.43912",
      "batchsize": "70.33928",
      "optimizer": "0.80332",
      "acc": "0.8593518518518518",
      "loss": "0.4241107313103146"
    },
    "39": {
      "name": 39,
      "learningrate": "0.04702",
      "dropout": "0.05627",
      "epoch": "54.60048",
      "batchsize": "49.97876",
      "optimizer": "1.21787",
      "acc": "0.8593148148148149",
      "loss": "0.48249464442774104"
    },
    "40": {
      "name": 40,
      "learningrate": "0.04573",
      "dropout": "0.29422",
      "epoch": "93.31442",
      "batchsize": "29.47463",
      "optimizer": "1.23662",
      "acc": "0.8591666666666666",
      "loss": "0.47038505417108534"
    },
    "41": {
      "name": 41,
      "learningrate": "0.03322",
      "dropout": "0.42223",
      "epoch": "80.03373",
      "batchsize": "42.13904",
      "optimizer": "4.26997",
      "acc": "0.8590555555555556",
      "loss": "0.40737404898140167"
    },
    "42": {
      "name": 42,
      "learningrate": "0.00401",
      "dropout": "0.33131",
      "epoch": "103.52079",
      "batchsize": "67.10328",
      "optimizer": "0.50027",
      "acc": "0.8588333333333333",
      "loss": "0.40652358759332585"
    },
    "43": {
      "name": 43,
      "learningrate": "0.07094",
      "dropout": "0.07119",
      "epoch": "78.17614",
      "batchsize": "54.37373",
      "optimizer": "0.86001",
      "acc": "0.8586851851851852",
      "loss": "0.5156558596061336"
    },
    "44": {
      "name": 44,
      "learningrate": "0.04257",
      "dropout": "0.4454",
      "epoch": "92.75162",
      "batchsize": "58.10226",
      "optimizer": "0.85958",
      "acc": "0.8586481481481482",
      "loss": "0.4529164805323989"
    },
    "45": {
      "name": 45,
      "learningrate": "0.04166",
      "dropout": "0.51447",
      "epoch": "107.79273",
      "batchsize": "57.73576",
      "optimizer": "1.04677",
      "acc": "0.8579444444444444",
      "loss": "0.4528853243611477"
    },
    "46": {
      "name": 46,
      "learningrate": "0.04745",
      "dropout": "0.11163",
      "epoch": "83.85645",
      "batchsize": "39.67546",
      "optimizer": "2.79126",
      "acc": "0.8578518518518519",
      "loss": "0.4515025943517685"
    },
    "47": {
      "name": 47,
      "learningrate": "0.06868",
      "dropout": "0.44639",
      "epoch": "74.66513",
      "batchsize": "52.62223",
      "optimizer": "0.64448",
      "acc": "0.8577407407407407",
      "loss": "0.45917146636821604"
    },
    "48": {
      "name": 48,
      "learningrate": "0.06253",
      "dropout": "0.46333",
      "epoch": "85.71875",
      "batchsize": "67.14538",
      "optimizer": "2.90865",
      "acc": "0.8576851851851852",
      "loss": "0.422377239048481"
    },
    "49": {
      "name": 49,
      "learningrate": "0.03511",
      "dropout": "0.31007",
      "epoch": "52.23927",
      "batchsize": "27.79443",
      "optimizer": "3.45867",
      "acc": "0.8576111111111111",
      "loss": "0.41571704747721"
    },
    "50": {
      "name": 50,
      "learningrate": "0.03083",
      "dropout": "0.33996",
      "epoch": "81.40447",
      "batchsize": "55.88276",
      "optimizer": "3.04586",
      "acc": "0.8573333333333333",
      "loss": "0.4087080790201823"
    },
    "51": {
      "name": 51,
      "learningrate": "0.00532",
      "dropout": "0.09122",
      "epoch": "42.9547",
      "batchsize": "29.32377",
      "optimizer": "1.14525",
      "acc": "0.8571851851851852",
      "loss": "0.4103089441281778"
    },
    "52": {
      "name": 52,
      "learningrate": "0.04146",
      "dropout": "0.44836",
      "epoch": "60.50905",
      "batchsize": "32.66141",
      "optimizer": "1.06828",
      "acc": "0.8571666666666666",
      "loss": "0.4357959838443332"
    },
    "53": {
      "name": 53,
      "learningrate": "0.06559",
      "dropout": "0.13039",
      "epoch": "72.57801",
      "batchsize": "29.09997",
      "optimizer": "0.5556",
      "acc": "0.8568703703703704",
      "loss": "0.5157632022301356"
    },
    "54": {
      "name": 54,
      "learningrate": "0.05368",
      "dropout": "0.09562",
      "epoch": "56.55659",
      "batchsize": "69.21395",
      "optimizer": "2.88562",
      "acc": "0.856537037037037",
      "loss": "0.4162509998701237"
    },
    "55": {
      "name": 55,
      "learningrate": "0.02601",
      "dropout": "0.07523",
      "epoch": "53.79109",
      "batchsize": "68.97501",
      "optimizer": "0.89485",
      "acc": "0.8562777777777778",
      "loss": "0.43854211006782673"
    },
    "56": {
      "name": 56,
      "learningrate": "0.06509",
      "dropout": "0.33441",
      "epoch": "38.60908",
      "batchsize": "58.57145",
      "optimizer": "2.67904",
      "acc": "0.8562407407407407",
      "loss": "0.41028319167428545"
    },
    "57": {
      "name": 57,
      "learningrate": "0.05282",
      "dropout": "0.32561",
      "epoch": "47.68111",
      "batchsize": "51.19097",
      "optimizer": "2.84167",
      "acc": "0.855537037037037",
      "loss": "0.4158043018182119"
    },
    "58": {
      "name": 58,
      "learningrate": "0.02512",
      "dropout": "0.32038",
      "epoch": "40.43726",
      "batchsize": "39.13699",
      "optimizer": "0.57239",
      "acc": "0.8555",
      "loss": "0.4147222857651887"
    },
    "59": {
      "name": 59,
      "learningrate": "0.05974",
      "dropout": "0.16363",
      "epoch": "94.05384",
      "batchsize": "31.06146",
      "optimizer": "1.01323",
      "acc": "0.8554074074074074",
      "loss": "0.5438828979554"
    },
    "60": {
      "name": 60,
      "learningrate": "0.07285",
      "dropout": "0.5063",
      "epoch": "122.48097",
      "batchsize": "50.09382",
      "optimizer": "0.75424",
      "acc": "0.8553888888888889",
      "loss": "0.5044220659313379"
    },
    "61": {
      "name": 61,
      "learningrate": "0.09648",
      "dropout": "0.1199",
      "epoch": "73.91581",
      "batchsize": "50.47476",
      "optimizer": "0.83502",
      "acc": "0.8552962962962963",
      "loss": "0.5158735188444455"
    },
    "62": {
      "name": 62,
      "learningrate": "0.07424",
      "dropout": "0.24067",
      "epoch": "99.87187",
      "batchsize": "52.79233",
      "optimizer": "0.7278",
      "acc": "0.854462962962963",
      "loss": "0.5393970567451583"
    },
    "63": {
      "name": 63,
      "learningrate": "0.00365",
      "dropout": "0.31596",
      "epoch": "51.87906",
      "batchsize": "44.7867",
      "optimizer": "2.15758",
      "acc": "0.8542777777777778",
      "loss": "0.6990502577313671"
    },
    "64": {
      "name": 64,
      "learningrate": "0.02069",
      "dropout": "0.61826",
      "epoch": "69.639",
      "batchsize": "39.31969",
      "optimizer": "0.78849",
      "acc": "0.8538703703703704",
      "loss": "0.41608889251726644"
    },
    "65": {
      "name": 65,
      "learningrate": "0.05463",
      "dropout": "0.52892",
      "epoch": "102.82694",
      "batchsize": "31.81427",
      "optimizer": "1.1766",
      "acc": "0.8538333333333333",
      "loss": "0.4585764475244063"
    },
    "66": {
      "name": 66,
      "learningrate": "0.0039",
      "dropout": "0.26498",
      "epoch": "57.23531",
      "batchsize": "48.4413",
      "optimizer": "1.45848",
      "acc": "0.8535555555555555",
      "loss": "0.4229751845156705"
    },
    "67": {
      "name": 67,
      "learningrate": "0.10099",
      "dropout": "0.35061",
      "epoch": "56.65658",
      "batchsize": "39.98083",
      "optimizer": "1.05548",
      "acc": "0.8535",
      "loss": "0.48311064807573956"
    },
    "68": {
      "name": 68,
      "learningrate": "0.02348",
      "dropout": "0.62778",
      "epoch": "95.24361",
      "batchsize": "44.26264",
      "optimizer": "1.08986",
      "acc": "0.8535",
      "loss": "0.4211493910197858"
    },
    "69": {
      "name": 69,
      "learningrate": "0.08685",
      "dropout": "0.15388",
      "epoch": "42.3918",
      "batchsize": "58.72577",
      "optimizer": "0.68663",
      "acc": "0.852925925925926",
      "loss": "0.4664340922390973"
    },
    "70": {
      "name": 70,
      "learningrate": "0.00517",
      "dropout": "0.35611",
      "epoch": "56.88271",
      "batchsize": "39.43745",
      "optimizer": "1.81295",
      "acc": "0.8515925925925926",
      "loss": "0.7993882903478764"
    },
    "71": {
      "name": 71,
      "learningrate": "0.07512",
      "dropout": "0.08279",
      "epoch": "66.17264",
      "batchsize": "41.94224",
      "optimizer": "1.26696",
      "acc": "0.8510555555555556",
      "loss": "0.541700693966062"
    },
    "72": {
      "name": 72,
      "learningrate": "0.01787",
      "dropout": "0.58963",
      "epoch": "61.63981",
      "batchsize": "51.21952",
      "optimizer": "1.08725",
      "acc": "0.8501111111111112",
      "loss": "0.42440614814228483"
    },
    "73": {
      "name": 73,
      "learningrate": "0.03796",
      "dropout": "0.13702",
      "epoch": "81.14374",
      "batchsize": "54.44943",
      "optimizer": "0.70906",
      "acc": "0.8500925925925926",
      "loss": "0.49797646840192655"
    },
    "74": {
      "name": 74,
      "learningrate": "0.0144",
      "dropout": "0.31879",
      "epoch": "59.77939",
      "batchsize": "45.1397",
      "optimizer": "3.28361",
      "acc": "0.8473333333333334",
      "loss": "0.43368710554087603"
    },
    "75": {
      "name": 75,
      "learningrate": "0.01849",
      "dropout": "0.10363",
      "epoch": "63.20078",
      "batchsize": "74.74912",
      "optimizer": "0.82896",
      "acc": "0.8472407407407407",
      "loss": "0.4704733752012253"
    },
    "76": {
      "name": 76,
      "learningrate": "0.12133",
      "dropout": "0.2687",
      "epoch": "61.03198",
      "batchsize": "38.96103",
      "optimizer": "1.4897",
      "acc": "0.8420185185185185",
      "loss": "0.4902568854799977"
    },
    "77": {
      "name": 77,
      "learningrate": "0.06097",
      "dropout": "0.07962",
      "epoch": "50.45429",
      "batchsize": "23.88918",
      "optimizer": "2.57357",
      "acc": "0.8412037037037037",
      "loss": "0.5152917731912048"
    },
    "78": {
      "name": 78,
      "learningrate": "0.03892",
      "dropout": "0.51745",
      "epoch": "79.26908",
      "batchsize": "74.67067",
      "optimizer": "4.64209",
      "acc": "0.8407407407407408",
      "loss": "0.4498705181369075"
    },
    "79": {
      "name": 79,
      "learningrate": "0.0044",
      "dropout": "0.22553",
      "epoch": "95.16508",
      "batchsize": "39.93992",
      "optimizer": "2.71536",
      "acc": "0.8405925925925926",
      "loss": "0.4598532629719487"
    },
    "80": {
      "name": 80,
      "learningrate": "0.06493228149272681",
      "dropout": "0.44862510726873084",
      "epoch": "8.497635575286356",
      "batchsize": "35.16231765442676",
      "optimizer": "1.280449091519717",
      "acc": "0.831462962962963",
      "loss": "0.48390908107051145"
    },
    "81": {
      "name": 81,
      "learningrate": "0.01699",
      "dropout": "0.07139",
      "epoch": "69.97069",
      "batchsize": "36.5233",
      "optimizer": "2.11701",
      "acc": "0.8057592592592593",
      "loss": "1.089216427397121"
    },
    "82": {
      "name": 82,
      "learningrate": "0.016052663895262553",
      "dropout": "0.3122701307862135",
      "epoch": "5.087806236733348",
      "batchsize": "46.68681228685334",
      "optimizer": "1.725243099828086",
      "acc": "0.7062962962962963",
      "loss": "0.8946310698544537"
    },
    "83": {
      "name": 83,
      "learningrate": "0.06612",
      "dropout": "0.08035",
      "epoch": "35.01292",
      "batchsize": "74.63152",
      "optimizer": "0.39107",
      "acc": "0.535074074074074",
      "loss": "1.3885140988032023"
    },
    "84": {
      "name": 84,
      "learningrate": "0.04404",
      "dropout": "0.14302",
      "epoch": "45.92262",
      "batchsize": "33.21675",
      "optimizer": "0.11484",
      "acc": "0.5269259259259259",
      "loss": "1.238263470861647"
    },
    "85": {
      "name": 85,
      "learningrate": "0.03983",
      "dropout": "0.45642",
      "epoch": "69.11174",
      "batchsize": "51.53907",
      "optimizer": "1.58853",
      "acc": "0.45181481481481484",
      "loss": "8.828903566996257"
    },
    "86": {
      "name": 86,
      "learningrate": "0.06663",
      "dropout": "0.05236",
      "epoch": "55.50131",
      "batchsize": "38.00485",
      "optimizer": "0.43122",
      "acc": "0.34455555555555556",
      "loss": "10.564012613649721"
    },
    "87": {
      "name": 87,
      "learningrate": "0.05422",
      "dropout": "0.22214",
      "epoch": "125.54107",
      "batchsize": "44.63373",
      "optimizer": "0.44933",
      "acc": "0.28938888888888886",
      "loss": "11.453415136831778"
    },
    "88": {
      "name": 88,
      "learningrate": "0.0722",
      "dropout": "0.11068",
      "epoch": "62.27189",
      "batchsize": "32.14303",
      "optimizer": "2.19368",
      "acc": "0.1999074074074074",
      "loss": "12.895968807079173"
    },
    "89": {
      "name": 89,
      "learningrate": "0.07009",
      "dropout": "0.20265",
      "epoch": "77.9419",
      "batchsize": "33.59982",
      "optimizer": "0.11271",
      "acc": "0.1501111111111111",
      "loss": "13.697715134514702"
    },
    "90": {
      "name": 90,
      "learningrate": "0.0617",
      "dropout": "0.19122",
      "epoch": "71.68591",
      "batchsize": "36.18956",
      "optimizer": "0.47585",
      "acc": "0.10018518518518518",
      "loss": "14.50330083154749"
    },
    "91": {
      "name": 91,
      "learningrate": "0.0589",
      "dropout": "0.31999",
      "epoch": "44.29731",
      "batchsize": "45.69227",
      "optimizer": "1.95671",
      "acc": "0.10011111111111111",
      "loss": "14.50449479534008"
    },
    "92": {
      "name": 92,
      "learningrate": "0.07502",
      "dropout": "0.22238",
      "epoch": "109.56603",
      "batchsize": "65.4203",
      "optimizer": "2.28255",
      "acc": "0.09996296296296296",
      "loss": "14.506882636741356"
    },
    "93": {
      "name": 93,
      "learningrate": "0.09382",
      "dropout": "0.26154",
      "epoch": "68.80902",
      "batchsize": "33.77379",
      "optimizer": "2.4294",
      "acc": "0.09996296296296296",
      "loss": "14.506882636741356"
    },
    "94": {
      "name": 94,
      "learningrate": "0.06163",
      "dropout": "0.28409",
      "epoch": "81.54563",
      "batchsize": "34.29176",
      "optimizer": "2.24711",
      "acc": "0.09985185185185186",
      "loss": "14.50867355742278"
    },
    "95": {
      "name": 95,
      "learningrate": "0.07746",
      "dropout": "0.06835",
      "epoch": "83.7286",
      "batchsize": "55.20373",
      "optimizer": "2.30035",
      "acc": "0.09968518518518518",
      "loss": "14.511359884756583"
    }
  },
  "3": {
    "0": {
      "name": 0,
      "learningrate": "0.04117",
      "dropout": "0.08287",
      "epoch": "47.36707",
      "batchsize": "66.76966",
      "optimizer": "1.10709",
      "acc": "0.8659259259259259",
      "loss": "0.4371932927226579"
    },
    "1": {
      "name": 1,
      "learningrate": "0.01955",
      "dropout": "0.11553",
      "epoch": "71.23894",
      "batchsize": "50.8927",
      "optimizer": "0.66212",
      "acc": "0.8649814814814815",
      "loss": "0.41491906250185434"
    },
    "2": {
      "name": 2,
      "learningrate": "0.04745",
      "dropout": "0.33445",
      "epoch": "144.76375",
      "batchsize": "44.68513",
      "optimizer": "0.91239",
      "acc": "0.8643333333333333",
      "loss": "0.5200226460463471"
    },
    "3": {
      "name": 3,
      "learningrate": "0.03988",
      "dropout": "0.21516",
      "epoch": "70.91471",
      "batchsize": "48.10631",
      "optimizer": "1.00298",
      "acc": "0.8642592592592593",
      "loss": "0.43783285935940564"
    },
    "4": {
      "name": 4,
      "learningrate": "0.02022",
      "dropout": "0.27435",
      "epoch": "70.20667",
      "batchsize": "30.94179",
      "optimizer": "0.63781",
      "acc": "0.8642037037037037",
      "loss": "0.4160457900453497"
    },
    "5": {
      "name": 5,
      "learningrate": "0.03875",
      "dropout": "0.03482",
      "epoch": "65.92063",
      "batchsize": "27.76631",
      "optimizer": "1.00503",
      "acc": "0.8639814814814815",
      "loss": "0.4888573247326745"
    },
    "6": {
      "name": 6,
      "learningrate": "0.03416",
      "dropout": "0.07898",
      "epoch": "57.20559",
      "batchsize": "36.7749",
      "optimizer": "1.48384",
      "acc": "0.8634444444444445",
      "loss": "0.4347519426235446"
    },
    "7": {
      "name": 7,
      "learningrate": "0.05657",
      "dropout": "0.03327",
      "epoch": "57.53177",
      "batchsize": "52.01032",
      "optimizer": "1.2707",
      "acc": "0.8633888888888889",
      "loss": "0.5052347972691059"
    },
    "8": {
      "name": 8,
      "learningrate": "0.02943",
      "dropout": "0.10016",
      "epoch": "97.05396",
      "batchsize": "38.74815",
      "optimizer": "0.80649",
      "acc": "0.863037037037037",
      "loss": "0.46007729115751056"
    },
    "9": {
      "name": 9,
      "learningrate": "0.02696",
      "dropout": "0.39322",
      "epoch": "71.99029",
      "batchsize": "43.23819",
      "optimizer": "1.28414",
      "acc": "0.863",
      "loss": "0.41227100372535214"
    },
    "10": {
      "name": 10,
      "learningrate": "0.01882",
      "dropout": "0.25114",
      "epoch": "56.19507",
      "batchsize": "27.93708",
      "optimizer": "0.72785",
      "acc": "0.8627962962962963",
      "loss": "0.41217354466297007"
    },
    "11": {
      "name": 11,
      "learningrate": "0.02884",
      "dropout": "0.09757",
      "epoch": "64.04543",
      "batchsize": "66.61466",
      "optimizer": "1.33733",
      "acc": "0.8627407407407407",
      "loss": "0.42176285626932425"
    },
    "12": {
      "name": 12,
      "learningrate": "0.0598",
      "dropout": "0.24574",
      "epoch": "72.47283",
      "batchsize": "54.422",
      "optimizer": "0.92358",
      "acc": "0.8627222222222222",
      "loss": "0.4721190643862442"
    },
    "13": {
      "name": 13,
      "learningrate": "0.03521",
      "dropout": "0.11765",
      "epoch": "84.41474",
      "batchsize": "51.86581",
      "optimizer": "0.71295",
      "acc": "0.8623888888888889",
      "loss": "0.4675159328955191"
    },
    "14": {
      "name": 14,
      "learningrate": "0.0254",
      "dropout": "0.29454",
      "epoch": "97.60542",
      "batchsize": "23.59198",
      "optimizer": "4.44824",
      "acc": "0.8621666666666666",
      "loss": "0.4414205517040359"
    },
    "15": {
      "name": 15,
      "learningrate": "0.03179",
      "dropout": "0.31445",
      "epoch": "93.36941",
      "batchsize": "34.95428",
      "optimizer": "0.67573",
      "acc": "0.862",
      "loss": "0.44061495754012353"
    },
    "16": {
      "name": 16,
      "learningrate": "0.02698",
      "dropout": "0.38531",
      "epoch": "92.55611",
      "batchsize": "72.15415",
      "optimizer": "0.70401",
      "acc": "0.8619444444444444",
      "loss": "0.4197536394264963"
    },
    "17": {
      "name": 17,
      "learningrate": "0.02543",
      "dropout": "0.39098",
      "epoch": "81.44373",
      "batchsize": "64.24794",
      "optimizer": "0.73586",
      "acc": "0.8618703703703704",
      "loss": "0.41192876028352315"
    },
    "18": {
      "name": 18,
      "learningrate": "0.02123",
      "dropout": "0.36667",
      "epoch": "100.11016",
      "batchsize": "51.27428",
      "optimizer": "0.96127",
      "acc": "0.8618333333333333",
      "loss": "0.42108789686582704"
    },
    "19": {
      "name": 19,
      "learningrate": "0.02583",
      "dropout": "0.28604",
      "epoch": "89.78101",
      "batchsize": "47.0714",
      "optimizer": "0.87569",
      "acc": "0.8618148148148148",
      "loss": "0.4238245477102421"
    },
    "20": {
      "name": 20,
      "learningrate": "0.04748",
      "dropout": "0.19331",
      "epoch": "76.49196",
      "batchsize": "31.03663",
      "optimizer": "0.63791",
      "acc": "0.8617777777777778",
      "loss": "0.4708230442316444"
    },
    "21": {
      "name": 21,
      "learningrate": "0.02876",
      "dropout": "0.32742",
      "epoch": "62.742",
      "batchsize": "20.15355",
      "optimizer": "1.20955",
      "acc": "0.8617222222222222",
      "loss": "0.4226063948704137"
    },
    "22": {
      "name": 22,
      "learningrate": "0.03607",
      "dropout": "0.28493",
      "epoch": "84.21562",
      "batchsize": "35.32929",
      "optimizer": "0.99399",
      "acc": "0.8616481481481482",
      "loss": "0.45451187830501133"
    },
    "23": {
      "name": 23,
      "learningrate": "0.03789",
      "dropout": "0.26488",
      "epoch": "84.22212",
      "batchsize": "31.25785",
      "optimizer": "4.98469",
      "acc": "0.8616481481481482",
      "loss": "0.4393282886434484"
    },
    "24": {
      "name": 24,
      "learningrate": "0.05415",
      "dropout": "0.35626",
      "epoch": "131.82261",
      "batchsize": "105.15602",
      "optimizer": "0.886",
      "acc": "0.861462962962963",
      "loss": "0.4865339544680383"
    },
    "25": {
      "name": 25,
      "learningrate": "0.05711",
      "dropout": "0.14206",
      "epoch": "112.32459",
      "batchsize": "34.6589",
      "optimizer": "1.12377",
      "acc": "0.8613888888888889",
      "loss": "0.5565840122810116"
    },
    "26": {
      "name": 26,
      "learningrate": "0.03384",
      "dropout": "0.37212",
      "epoch": "81.73171",
      "batchsize": "72.07629",
      "optimizer": "1.29528",
      "acc": "0.8612962962962963",
      "loss": "0.4264154462946786"
    },
    "27": {
      "name": 27,
      "learningrate": "0.03103",
      "dropout": "0.30721",
      "epoch": "80.35501",
      "batchsize": "52.11187",
      "optimizer": "0.94119",
      "acc": "0.8612222222222222",
      "loss": "0.43430755290720197"
    },
    "28": {
      "name": 28,
      "learningrate": "0.02508",
      "dropout": "0.32593",
      "epoch": "51.33811",
      "batchsize": "59.95893",
      "optimizer": "0.79379",
      "acc": "0.8611851851851852",
      "loss": "0.4045429670236729"
    },
    "29": {
      "name": 29,
      "learningrate": "0.0438",
      "dropout": "0.03463",
      "epoch": "81.85802",
      "batchsize": "62.85645",
      "optimizer": "1.33784",
      "acc": "0.8611666666666666",
      "loss": "0.4933309623113385"
    },
    "30": {
      "name": 30,
      "learningrate": "0.02412",
      "dropout": "0.28357",
      "epoch": "91.54693",
      "batchsize": "43.5908",
      "optimizer": "0.63356",
      "acc": "0.8610925925925926",
      "loss": "0.4240273361117752"
    },
    "31": {
      "name": 31,
      "learningrate": "0.05417",
      "dropout": "0.16053",
      "epoch": "69.91608",
      "batchsize": "36.95539",
      "optimizer": "1.15958",
      "acc": "0.8610740740740741",
      "loss": "0.47725927298819576"
    },
    "32": {
      "name": 32,
      "learningrate": "0.07402",
      "dropout": "0.30913",
      "epoch": "112.78367",
      "batchsize": "48.19045",
      "optimizer": "0.6682",
      "acc": "0.861",
      "loss": "0.5285367261358985"
    },
    "33": {
      "name": 33,
      "learningrate": "0.02029",
      "dropout": "0.09345",
      "epoch": "96.41099",
      "batchsize": "31.2431",
      "optimizer": "1.21438",
      "acc": "0.8609814814814815",
      "loss": "0.44329661953890764"
    },
    "34": {
      "name": 34,
      "learningrate": "0.07083",
      "dropout": "0.1328",
      "epoch": "102.55951",
      "batchsize": "24.65188",
      "optimizer": "1.22318",
      "acc": "0.8608888888888889",
      "loss": "0.5551427982372267"
    },
    "35": {
      "name": 35,
      "learningrate": "0.03626",
      "dropout": "0.31391",
      "epoch": "58.33514",
      "batchsize": "36.10044",
      "optimizer": "0.85796",
      "acc": "0.8607777777777778",
      "loss": "0.4292934753276684"
    },
    "36": {
      "name": 36,
      "learningrate": "0.05603",
      "dropout": "0.25267",
      "epoch": "77.90925",
      "batchsize": "64.27679",
      "optimizer": "0.57608",
      "acc": "0.8607777777777778",
      "loss": "0.4849326316338998"
    },
    "37": {
      "name": 37,
      "learningrate": "0.051",
      "dropout": "0.28494",
      "epoch": "69.37593",
      "batchsize": "66.7944",
      "optimizer": "1.05704",
      "acc": "0.8606666666666667",
      "loss": "0.44662601534525553"
    },
    "38": {
      "name": 38,
      "learningrate": "0.03316",
      "dropout": "0.25967",
      "epoch": "42.42005",
      "batchsize": "81.686",
      "optimizer": "1.13789",
      "acc": "0.8603888888888889",
      "loss": "0.4121942686571015"
    },
    "39": {
      "name": 39,
      "learningrate": "0.05007",
      "dropout": "0.19088",
      "epoch": "59.66957",
      "batchsize": "57.53525",
      "optimizer": "0.90169",
      "acc": "0.8602777777777778",
      "loss": "0.44213181729449164"
    },
    "40": {
      "name": 40,
      "learningrate": "0.04005",
      "dropout": "0.31678",
      "epoch": "40.94201",
      "batchsize": "50.43246",
      "optimizer": "1.43889",
      "acc": "0.8601666666666666",
      "loss": "0.40740834187578273"
    },
    "41": {
      "name": 41,
      "learningrate": "0.04933",
      "dropout": "0.30729",
      "epoch": "101.34565",
      "batchsize": "21.85305",
      "optimizer": "0.78052",
      "acc": "0.8600740740740741",
      "loss": "0.48436036520423714"
    },
    "42": {
      "name": 42,
      "learningrate": "0.0514",
      "dropout": "0.18109",
      "epoch": "136.57545",
      "batchsize": "91.71929",
      "optimizer": "1.36626",
      "acc": "0.8600740740740741",
      "loss": "0.5252990686109772"
    },
    "43": {
      "name": 43,
      "learningrate": "0.0191",
      "dropout": "0.28876",
      "epoch": "50.55623",
      "batchsize": "56.49913",
      "optimizer": "0.91305",
      "acc": "0.860037037037037",
      "loss": "0.40330252194846117"
    },
    "44": {
      "name": 44,
      "learningrate": "0.03991",
      "dropout": "0.22417",
      "epoch": "78.38234",
      "batchsize": "68.24775",
      "optimizer": "0.75048",
      "acc": "0.8597777777777778",
      "loss": "0.4602521211262102"
    },
    "45": {
      "name": 45,
      "learningrate": "0.0244",
      "dropout": "0.06203",
      "epoch": "45.21392",
      "batchsize": "69.13305",
      "optimizer": "1.37179",
      "acc": "0.8597777777777778",
      "loss": "0.40834485357779043"
    },
    "46": {
      "name": 46,
      "learningrate": "0.05241",
      "dropout": "0.36004",
      "epoch": "55.99849",
      "batchsize": "25.53721",
      "optimizer": "1.23208",
      "acc": "0.8597592592592592",
      "loss": "0.446936809145742"
    },
    "47": {
      "name": 47,
      "learningrate": "0.0507",
      "dropout": "0.09156",
      "epoch": "51.93597",
      "batchsize": "53.18275",
      "optimizer": "0.62876",
      "acc": "0.8597407407407407",
      "loss": "0.4670657948255539"
    },
    "48": {
      "name": 48,
      "learningrate": "0.08729",
      "dropout": "0.14058",
      "epoch": "73.7206",
      "batchsize": "71.25225",
      "optimizer": "1.03916",
      "acc": "0.8596666666666667",
      "loss": "0.5107544787967646"
    },
    "49": {
      "name": 49,
      "learningrate": "0.02305",
      "dropout": "0.33262",
      "epoch": "51.35229",
      "batchsize": "54.85551",
      "optimizer": "1.21935",
      "acc": "0.8594074074074074",
      "loss": "0.4074975843473717"
    },
    "50": {
      "name": 50,
      "learningrate": "0.06582",
      "dropout": "0.15883",
      "epoch": "89.73181",
      "batchsize": "24.27994",
      "optimizer": "0.66726",
      "acc": "0.8592962962962963",
      "loss": "0.5292166908891113"
    },
    "51": {
      "name": 51,
      "learningrate": "0.05939",
      "dropout": "0.08818",
      "epoch": "116.98309",
      "batchsize": "30.64757",
      "optimizer": "4.17321",
      "acc": "0.8592777777777778",
      "loss": "0.593057306540785"
    },
    "52": {
      "name": 52,
      "learningrate": "0.01633",
      "dropout": "0.4352",
      "epoch": "65.26414",
      "batchsize": "70.55685",
      "optimizer": "0.6755",
      "acc": "0.8592407407407407",
      "loss": "0.40233689763369385"
    },
    "53": {
      "name": 53,
      "learningrate": "0.04984",
      "dropout": "0.42332",
      "epoch": "57.77297",
      "batchsize": "63.14405",
      "optimizer": "0.84686",
      "acc": "0.8587037037037037",
      "loss": "0.43733134814324204"
    },
    "54": {
      "name": 54,
      "learningrate": "0.0266",
      "dropout": "0.14051",
      "epoch": "91.64085",
      "batchsize": "53.56141",
      "optimizer": "3.8845",
      "acc": "0.8583703703703703",
      "loss": "0.4149212132427427"
    },
    "55": {
      "name": 55,
      "learningrate": "0.0316",
      "dropout": "0.35975",
      "epoch": "33.65351",
      "batchsize": "39.76089",
      "optimizer": "0.76815",
      "acc": "0.8583518518518518",
      "loss": "0.403076985111943"
    },
    "56": {
      "name": 56,
      "learningrate": "0.04614",
      "dropout": "0.07567",
      "epoch": "67.62355",
      "batchsize": "65.72261",
      "optimizer": "3.06983",
      "acc": "0.8582037037037037",
      "loss": "0.41599520006886237"
    },
    "57": {
      "name": 57,
      "learningrate": "0.06413",
      "dropout": "0.08919",
      "epoch": "62.35102",
      "batchsize": "46.84368",
      "optimizer": "0.52762",
      "acc": "0.857925925925926",
      "loss": "0.500267405476835"
    },
    "58": {
      "name": 58,
      "learningrate": "0.03558",
      "dropout": "0.2681",
      "epoch": "118.49075",
      "batchsize": "28.79232",
      "optimizer": "3.21367",
      "acc": "0.8579074074074075",
      "loss": "0.4783869319845129"
    },
    "59": {
      "name": 59,
      "learningrate": "0.00542",
      "dropout": "0.10866",
      "epoch": "57.98577",
      "batchsize": "22.70954",
      "optimizer": "1.06847",
      "acc": "0.8572777777777778",
      "loss": "0.41060685940142033"
    },
    "60": {
      "name": 60,
      "learningrate": "0.08472",
      "dropout": "0.08814",
      "epoch": "92.06031",
      "batchsize": "24.88206",
      "optimizer": "0.6215",
      "acc": "0.8572592592592593",
      "loss": "0.5869378444740065"
    },
    "61": {
      "name": 61,
      "learningrate": "0.06708",
      "dropout": "0.11595",
      "epoch": "129.60953",
      "batchsize": "52.97188",
      "optimizer": "0.78789",
      "acc": "0.8572592592592593",
      "loss": "0.5849434810446368"
    },
    "62": {
      "name": 62,
      "learningrate": "0.06103",
      "dropout": "0.08232",
      "epoch": "54.91441",
      "batchsize": "41.64018",
      "optimizer": "1.15532",
      "acc": "0.8571851851851852",
      "loss": "0.48216885129831455"
    },
    "63": {
      "name": 63,
      "learningrate": "0.08592",
      "dropout": "0.13633",
      "epoch": "97.5357",
      "batchsize": "67.72457",
      "optimizer": "1.1061",
      "acc": "0.8570740740740741",
      "loss": "0.5578379116025236"
    },
    "64": {
      "name": 64,
      "learningrate": "0.05256",
      "dropout": "0.34509",
      "epoch": "41.0995",
      "batchsize": "31.37258",
      "optimizer": "1.26676",
      "acc": "0.857",
      "loss": "0.42786249267613446"
    },
    "65": {
      "name": 65,
      "learningrate": "0.02174",
      "dropout": "0.26926",
      "epoch": "44.03436",
      "batchsize": "60.37314",
      "optimizer": "0.60334",
      "acc": "0.8566296296296296",
      "loss": "0.4051029448266383"
    },
    "66": {
      "name": 66,
      "learningrate": "0.06467",
      "dropout": "0.26162",
      "epoch": "38.94134",
      "batchsize": "51.39894",
      "optimizer": "0.55591",
      "acc": "0.8564259259259259",
      "loss": "0.43586245211848507"
    },
    "67": {
      "name": 67,
      "learningrate": "0.13676",
      "dropout": "0.45992",
      "epoch": "63.99145",
      "batchsize": "39.16342",
      "optimizer": "3.61635",
      "acc": "0.8564074074074074",
      "loss": "0.45520365866466805"
    },
    "68": {
      "name": 68,
      "learningrate": "0.03537",
      "dropout": "0.30987",
      "epoch": "54.68682",
      "batchsize": "23.97248",
      "optimizer": "3.2944",
      "acc": "0.8562407407407407",
      "loss": "0.4369691614508629"
    },
    "69": {
      "name": 69,
      "learningrate": "0.046",
      "dropout": "0.48068",
      "epoch": "50.13003",
      "batchsize": "40.74937",
      "optimizer": "0.66122",
      "acc": "0.8561481481481481",
      "loss": "0.4237369032745008"
    },
    "70": {
      "name": 70,
      "learningrate": "0.05144",
      "dropout": "0.50384",
      "epoch": "60.03351",
      "batchsize": "39.55451",
      "optimizer": "0.85978",
      "acc": "0.8561481481481481",
      "loss": "0.43968319621792545"
    },
    "71": {
      "name": 71,
      "learningrate": "0.02251",
      "dropout": "0.03993",
      "epoch": "56.88081",
      "batchsize": "58.24298",
      "optimizer": "1.2275",
      "acc": "0.8557592592592592",
      "loss": "0.43467425265577103"
    },
    "72": {
      "name": 72,
      "learningrate": "0.0219",
      "dropout": "0.16549",
      "epoch": "112.8728",
      "batchsize": "43.47197",
      "optimizer": "3.88765",
      "acc": "0.8557037037037037",
      "loss": "0.43820836772742094"
    },
    "73": {
      "name": 73,
      "learningrate": "0.04552",
      "dropout": "0.49286",
      "epoch": "74.33148",
      "batchsize": "35.02175",
      "optimizer": "0.70273",
      "acc": "0.8547777777777777",
      "loss": "0.4362146031083884"
    },
    "74": {
      "name": 74,
      "learningrate": "0.01635",
      "dropout": "0.1583",
      "epoch": "104.17696",
      "batchsize": "84.2594",
      "optimizer": "0.79695",
      "acc": "0.8546481481481482",
      "loss": "0.440498311219392"
    },
    "75": {
      "name": 75,
      "learningrate": "0.04473",
      "dropout": "0.46548",
      "epoch": "75.63575",
      "batchsize": "45.59496",
      "optimizer": "0.94907",
      "acc": "0.8543518518518518",
      "loss": "0.4381075055643364"
    },
    "76": {
      "name": 76,
      "learningrate": "0.09236",
      "dropout": "0.31017",
      "epoch": "75.07826",
      "batchsize": "81.06409",
      "optimizer": "0.80898",
      "acc": "0.8542777777777778",
      "loss": "0.4862427404324214"
    },
    "77": {
      "name": 77,
      "learningrate": "0.03105",
      "dropout": "0.42367",
      "epoch": "54.21824",
      "batchsize": "30.37664",
      "optimizer": "0.84707",
      "acc": "0.8542592592592593",
      "loss": "0.4195955125534976"
    },
    "78": {
      "name": 78,
      "learningrate": "0.06426",
      "dropout": "0.2166",
      "epoch": "48.42877",
      "batchsize": "37.31516",
      "optimizer": "4.67229",
      "acc": "0.852462962962963",
      "loss": "0.45108603763580324"
    },
    "79": {
      "name": 79,
      "learningrate": "0.08115",
      "dropout": "0.50321",
      "epoch": "41.36051",
      "batchsize": "49.28009",
      "optimizer": "0.90883",
      "acc": "0.8516481481481482",
      "loss": "0.4474068913647422"
    },
    "80": {
      "name": 80,
      "learningrate": "0.02847",
      "dropout": "0.14441",
      "epoch": "54.56035",
      "batchsize": "34.23685",
      "optimizer": "3.88236",
      "acc": "0.8502407407407407",
      "loss": "0.43473633585152804"
    },
    "81": {
      "name": 81,
      "learningrate": "0.07558",
      "dropout": "0.56105",
      "epoch": "65.39877",
      "batchsize": "44.93053",
      "optimizer": "0.56868",
      "acc": "0.8496296296296296",
      "loss": "0.45703768095705244"
    },
    "82": {
      "name": 82,
      "learningrate": "0.02478",
      "dropout": "0.23454",
      "epoch": "53.21174",
      "batchsize": "33.30044",
      "optimizer": "2.82843",
      "acc": "0.8469814814814814",
      "loss": "0.4336077129355183"
    },
    "83": {
      "name": 83,
      "learningrate": "0.12691",
      "dropout": "0.26015",
      "epoch": "67.03063",
      "batchsize": "35.96571",
      "optimizer": "4.48361",
      "acc": "0.838",
      "loss": "0.5992760149880692"
    },
    "84": {
      "name": 84,
      "learningrate": "0.01907",
      "dropout": "0.08436",
      "epoch": "56.33978",
      "batchsize": "74.80529",
      "optimizer": "0.71097",
      "acc": "0.8282777777777778",
      "loss": "0.5185827146636115"
    },
    "85": {
      "name": 85,
      "learningrate": "0.09465",
      "dropout": "0.19681",
      "epoch": "101.40426",
      "batchsize": "41.53712",
      "optimizer": "3.22056",
      "acc": "0.8248518518518518",
      "loss": "0.7036579468978776"
    },
    "86": {
      "name": 86,
      "learningrate": "0.06312",
      "dropout": "0.37317",
      "epoch": "42.80181",
      "batchsize": "38.74759",
      "optimizer": "1.5783",
      "acc": "0.5342962962962963",
      "loss": "7.4961156935515225"
    },
    "87": {
      "name": 87,
      "learningrate": "0.04451",
      "dropout": "0.28521",
      "epoch": "53.7817",
      "batchsize": "59.44008",
      "optimizer": "2.11896",
      "acc": "0.4615925925925926",
      "loss": "8.66012752589473"
    },
    "88": {
      "name": 88,
      "learningrate": "0.05680815721013396",
      "dropout": "0.14704816928798473",
      "epoch": "7.110136640516195",
      "batchsize": "42.723283442157516",
      "optimizer": "0.42358668045721193",
      "acc": "0.44792592592592595",
      "loss": "1.3722164524219653"
    },
    "89": {
      "name": 89,
      "learningrate": "0.03544",
      "dropout": "0.37668",
      "epoch": "75.42423",
      "batchsize": "35.40536",
      "optimizer": "1.57745",
      "acc": "0.3705555555555556",
      "loss": "10.125345085991754"
    },
    "90": {
      "name": 90,
      "learningrate": "0.04209",
      "dropout": "0.41121",
      "epoch": "70.13288",
      "batchsize": "45.52542",
      "optimizer": "2.02457",
      "acc": "0.3478148148148148",
      "loss": "10.506067025078668"
    },
    "91": {
      "name": 91,
      "learningrate": "0.06237",
      "dropout": "0.17884",
      "epoch": "62.03839",
      "batchsize": "47.66324",
      "optimizer": "1.60775",
      "acc": "0.2873703703703704",
      "loss": "11.48526256024396"
    },
    "92": {
      "name": 92,
      "learningrate": "0.08344794079654898",
      "dropout": "0.2427644846443553",
      "epoch": "5.815302483220261",
      "batchsize": "43.17896152318329",
      "optimizer": "2.16324246587677",
      "acc": "0.1993888888888889",
      "loss": "12.904246745074238"
    },
    "93": {
      "name": 93,
      "learningrate": "0.04859",
      "dropout": "0.06181",
      "epoch": "49.33226",
      "batchsize": "59.85337",
      "optimizer": "1.54336",
      "acc": "0.10011111111111111",
      "loss": "14.50449479534008"
    },
    "94": {
      "name": 94,
      "learningrate": "0.03841",
      "dropout": "0.11234",
      "epoch": "135.9794",
      "batchsize": "42.20817",
      "optimizer": "1.96575",
      "acc": "0.10011111111111111",
      "loss": "14.50449479534008"
    },
    "95": {
      "name": 95,
      "learningrate": "0.09285",
      "dropout": "0.09262",
      "epoch": "45.68081",
      "batchsize": "44.68986",
      "optimizer": "1.54139",
      "acc": "0.09977777777777778",
      "loss": "14.509867480807834"
    }
  }
}