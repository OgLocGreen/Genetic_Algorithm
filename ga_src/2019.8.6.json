{
  "0": {
    "0": {
      "name": 0,
      "learningrate": 0.02659556305972846,
      "dropout": 0.23019951466921384,
      "epoch": 8.946495350875523,
      "batchsize": 35.6274590768487,
      "optimizer": 1.2581417613669177,
      "acc": 0.8395185185185186,
      "loss": 0.4472402598372212
    },
    "1": {
      "name": 1,
      "learningrate": 0.011381773088867848,
      "dropout": 0.1540566588793753,
      "epoch": 9.758468139052905,
      "batchsize": 60.70333460874758,
      "optimizer": 0.7251530079394816,
      "acc": 0.8363888888888888,
      "loss": 0.46601227882173324
    },
    "2": {
      "name": 2,
      "learningrate": 0.09559311324360945,
      "dropout": 0.18999619462214085,
      "epoch": 9.657233378228451,
      "batchsize": 56.23336628562574,
      "optimizer": 0.6519429225447876,
      "acc": 0.8354814814814815,
      "loss": 0.4697253647954376
    },
    "3": {
      "name": 3,
      "learningrate": 0.04986426144577428,
      "dropout": 0.3587911803676509,
      "epoch": 8.80124913481438,
      "batchsize": 61.385012473020254,
      "optimizer": 0.633058154299297,
      "acc": 0.8327962962962963,
      "loss": 0.4752991846358335
    },
    "4": {
      "name": 4,
      "learningrate": 0.06494956116493272,
      "dropout": 0.4335566461588153,
      "epoch": 8.578619663019763,
      "batchsize": 46.89512375301486,
      "optimizer": 1.0569307194430833,
      "acc": 0.8282037037037037,
      "loss": 0.4720781029816027
    },
    "5": {
      "name": 5,
      "learningrate": 0.04581609315197788,
      "dropout": 0.3728528791230185,
      "epoch": 5.147767740559661,
      "batchsize": 56.8458484444608,
      "optimizer": 1.0027442792797296,
      "acc": 0.8253148148148148,
      "loss": 0.49189546262334893
    },
    "6": {
      "name": 6,
      "learningrate": 0.014137614474244053,
      "dropout": 0.09330189292090296,
      "epoch": 5.937940874034028,
      "batchsize": 43.6298907653761,
      "optimizer": 1.3282446427089694,
      "acc": 0.8251481481481482,
      "loss": 0.49412881510346024
    },
    "7": {
      "name": 7,
      "learningrate": 0.0676462159187389,
      "dropout": 0.4546567780308822,
      "epoch": 8.702682357402015,
      "batchsize": 48.3858232190877,
      "optimizer": 1.2379699198907184,
      "acc": 0.8205555555555556,
      "loss": 0.4986007437352781
    },
    "8": {
      "name": 8,
      "learningrate": 0.0396895028543658,
      "dropout": 0.12954920949205367,
      "epoch": 9.548448518803994,
      "batchsize": 52.45477398980826,
      "optimizer": 2.5804243617661227,
      "acc": 0.8203333333333334,
      "loss": 0.5141306595184185
    },
    "9": {
      "name": 9,
      "learningrate": 0.09965135021497536,
      "dropout": 0.1053062354863791,
      "epoch": 7.704240409482998,
      "batchsize": 35.9841246781051,
      "optimizer": 2.539628503840561,
      "acc": 0.8162592592592592,
      "loss": 0.5025922565769266
    },
    "10": {
      "name": 10,
      "learningrate": 0.004459954072779165,
      "dropout": 0.4525170535875275,
      "epoch": 8.135826086389375,
      "batchsize": 56.44167052913991,
      "optimizer": 0.9320849817437,
      "acc": 0.8137962962962964,
      "loss": 0.5389055271148682
    },
    "11": {
      "name": 11,
      "learningrate": 0.00703242283773642,
      "dropout": 0.47646551244433544,
      "epoch": 9.583515018400863,
      "batchsize": 39.51365845660615,
      "optimizer": 1.6253446887313578,
      "acc": 0.8112777777777778,
      "loss": 0.5488734168829741
    },
    "12": {
      "name": 12,
      "learningrate": 0.027580757464244314,
      "dropout": 0.2101325736390366,
      "epoch": 7.834397295492673,
      "batchsize": 62.8141113291897,
      "optimizer": 2.7932973722266463,
      "acc": 0.8028333333333333,
      "loss": 0.5781657863546301
    },
    "13": {
      "name": 13,
      "learningrate": 0.015615668704872425,
      "dropout": 0.3052405348479483,
      "epoch": 6.673081420118459,
      "batchsize": 58.01843723444443,
      "optimizer": 0.4298449022815952,
      "acc": 0.8017407407407408,
      "loss": 0.5860774867711244
    },
    "14": {
      "name": 14,
      "learningrate": 0.01506129271702459,
      "dropout": 0.37288864569789915,
      "epoch": 6.404136197108076,
      "batchsize": 34.6595758544328,
      "optimizer": 0.19474801095628647,
      "acc": 0.785537037037037,
      "loss": 0.594185925686801
    },
    "15": {
      "name": 15,
      "learningrate": 0.004799104727285173,
      "dropout": 0.467031366454486,
      "epoch": 8.86259850518186,
      "batchsize": 47.06171476803859,
      "optimizer": 2.4941556302511962,
      "acc": 0.7478518518518519,
      "loss": 0.7007119626204172
    },
    "16": {
      "name": 16,
      "learningrate": 0.038366910443031685,
      "dropout": 0.20676702838535638,
      "epoch": 5.288316766700139,
      "batchsize": 43.06967609460047,
      "optimizer": 0.13130018081675976,
      "acc": 0.6323703703703704,
      "loss": 1.015440286124194
    },
    "17": {
      "name": 17,
      "learningrate": 0.046701835729913155,
      "dropout": 0.43775866622914056,
      "epoch": 9.176442608970248,
      "batchsize": 47.038021587982946,
      "optimizer": 2.3017227702079825,
      "acc": 0.36542592592592593,
      "loss": 10.213470241122776
    },
    "18": {
      "name": 18,
      "learningrate": 0.05626841562366817,
      "dropout": 0.3977198591891532,
      "epoch": 7.477883835826352,
      "batchsize": 33.71232532438917,
      "optimizer": 0.44551001503979704,
      "acc": 0.26955555555555555,
      "loss": 11.596611280088071
    },
    "19": {
      "name": 19,
      "learningrate": 0.05122882777314478,
      "dropout": 0.18525145043802105,
      "epoch": 9.876839937174172,
      "batchsize": 51.96182128155401,
      "optimizer": 2.0923342163917225,
      "acc": 0.25427777777777777,
      "loss": 11.998630432976617
    },
    "20": {
      "name": 20,
      "learningrate": 0.0984232748581465,
      "dropout": 0.4999684856430598,
      "epoch": 5.596457970936123,
      "batchsize": 50.376830510789816,
      "optimizer": 1.8266539683024892,
      "acc": 0.19833333333333333,
      "loss": 12.921103272614655
    },
    "21": {
      "name": 21,
      "learningrate": 0.06820534758083152,
      "dropout": 0.24485051151473547,
      "epoch": 8.588730317378737,
      "batchsize": 39.818970848606355,
      "optimizer": 0.21741679560545113,
      "acc": 0.10018518518518518,
      "loss": 14.503300856131094
    },
    "22": {
      "name": 22,
      "learningrate": 0.060458764362841845,
      "dropout": 0.2677241631882401,
      "epoch": 6.002478491022941,
      "batchsize": 35.38821139782005,
      "optimizer": 2.222933817573523,
      "acc": 0.09996296296296296,
      "loss": 14.506882636741356
    },
    "23": {
      "name": 23,
      "learningrate": 0.09453662028062003,
      "dropout": 0.13633407914486362,
      "epoch": 9.884576152458752,
      "batchsize": 56.047699701319985,
      "optimizer": 1.8950304704261058,
      "acc": 0.09920370370370371,
      "loss": 14.519120458532262
    },
    "24": {
      "name": 24,
      "learningrate": 0.0958450162309619,
      "dropout": 0.05454766245251616,
      "epoch": 7.668616327856401,
      "batchsize": 54.57707648208357,
      "optimizer": 1.8050482917118287,
      "acc": 0.09920370370370371,
      "loss": 14.519120458532262
    }
  },
  "1": {
    "0": {
      "name": 0,
      "learningrate": 0.02742,
      "dropout": 0.22055,
      "epoch": 10.067,
      "batchsize": 39.38856,
      "optimizer": 0.75553,
      "acc": 0.8510555555555556,
      "loss": 0.42542081524266134
    },
    "1": {
      "name": 1,
      "learningrate": 0.02659556305972846,
      "dropout": 0.23019951466921384,
      "epoch": 8.946495350875523,
      "batchsize": 35.6274590768487,
      "optimizer": 1.2581417613669177,
      "acc": 0.849925925925926,
      "loss": 0.4244760304292043
    },
    "2": {
      "name": 2,
      "learningrate": 0.01912,
      "dropout": 0.28017,
      "epoch": 10.4776,
      "batchsize": 36.76016,
      "optimizer": 0.96712,
      "acc": 0.8471851851851852,
      "loss": 0.43524162343254796
    },
    "3": {
      "name": 3,
      "learningrate": 0.02652,
      "dropout": 0.26679,
      "epoch": 8.39662,
      "batchsize": 49.68881,
      "optimizer": 0.68125,
      "acc": 0.8436296296296296,
      "loss": 0.43827733217345344
    },
    "4": {
      "name": 4,
      "learningrate": 0.01248,
      "dropout": 0.36034,
      "epoch": 10.9604,
      "batchsize": 51.20566,
      "optimizer": 1.36641,
      "acc": 0.8431481481481482,
      "loss": 0.4435323661521629
    },
    "5": {
      "name": 5,
      "learningrate": 0.011381773088867848,
      "dropout": 0.1540566588793753,
      "epoch": 9.758468139052905,
      "batchsize": 60.70333460874758,
      "optimizer": 0.7251530079394816,
      "acc": 0.8380185185185185,
      "loss": 0.46058069711261324
    },
    "6": {
      "name": 6,
      "learningrate": 0.04414,
      "dropout": 0.43693,
      "epoch": 9.40636,
      "batchsize": 66.29899,
      "optimizer": 0.72329,
      "acc": 0.8359074074074074,
      "loss": 0.45361349495693487
    },
    "7": {
      "name": 7,
      "learningrate": 0.03395,
      "dropout": 0.19132,
      "epoch": 7.63724,
      "batchsize": 58.36314,
      "optimizer": 1.24602,
      "acc": 0.8354074074074074,
      "loss": 0.4570880681761989
    },
    "8": {
      "name": 8,
      "learningrate": 0.01156,
      "dropout": 0.38493,
      "epoch": 9.94501,
      "batchsize": 77.58484,
      "optimizer": 0.76664,
      "acc": 0.8347777777777777,
      "loss": 0.48087885798348323
    },
    "9": {
      "name": 9,
      "learningrate": 0.05843,
      "dropout": 0.51498,
      "epoch": 9.65206,
      "batchsize": 50.04803,
      "optimizer": 0.7417,
      "acc": 0.8313703703703703,
      "loss": 0.4800668357831461
    },
    "10": {
      "name": 10,
      "learningrate": 0.06839577998217768,
      "dropout": 0.4631585996070809,
      "epoch": 7.254852332091726,
      "batchsize": 32.399355218225466,
      "optimizer": 1.4408604991468277,
      "acc": 0.8304074074074074,
      "loss": 0.48968837990142683
    },
    "11": {
      "name": 11,
      "learningrate": 0.057141644130774376,
      "dropout": 0.23495594664468222,
      "epoch": 5.878019752274044,
      "batchsize": 48.03704450672845,
      "optimizer": 0.7467164947999236,
      "acc": 0.8301851851851851,
      "loss": 0.470722300502989
    },
    "12": {
      "name": 12,
      "learningrate": 0.03768,
      "dropout": 0.32018,
      "epoch": 5.4423,
      "batchsize": 68.42874,
      "optimizer": 0.71646,
      "acc": 0.8280555555555555,
      "loss": 0.4896226079331504
    },
    "13": {
      "name": 13,
      "learningrate": 0.08354,
      "dropout": 0.14673,
      "epoch": 7.32846,
      "batchsize": 70.83857,
      "optimizer": 0.88936,
      "acc": 0.8275,
      "loss": 0.4916127634445826
    },
    "14": {
      "name": 14,
      "learningrate": 0.04221,
      "dropout": 0.36043,
      "epoch": 5.15384,
      "batchsize": 64.59329,
      "optimizer": 0.71623,
      "acc": 0.827,
      "loss": 0.4831006118500674
    },
    "15": {
      "name": 15,
      "learningrate": 0.09967,
      "dropout": 0.45267,
      "epoch": 11.35606,
      "batchsize": 46.33165,
      "optimizer": 0.90289,
      "acc": 0.8067592592592593,
      "loss": 0.5320763884032215
    },
    "16": {
      "name": 16,
      "learningrate": 0.03649,
      "dropout": 0.2798,
      "epoch": 4.21385,
      "batchsize": 45.52938,
      "optimizer": 2.66421,
      "acc": 0.7989259259259259,
      "loss": 0.6010627700487773
    },
    "17": {
      "name": 17,
      "learningrate": 0.04764,
      "dropout": 0.1126,
      "epoch": 6.98378,
      "batchsize": 37.06736,
      "optimizer": 2.59453,
      "acc": 0.7827592592592593,
      "loss": 0.6188120553316894
    },
    "18": {
      "name": 18,
      "learningrate": 0.02695,
      "dropout": 0.49781,
      "epoch": 8.79368,
      "batchsize": 51.48015,
      "optimizer": 1.51602,
      "acc": 0.683,
      "loss": 0.8819443648656209
    },
    "19": {
      "name": 19,
      "learningrate": 0.07316,
      "dropout": 0.14531,
      "epoch": 6.22824,
      "batchsize": 39.08497,
      "optimizer": 1.59518,
      "acc": 0.1002962962962963,
      "loss": 14.501509959468136
    },
    "20": {
      "name": 20,
      "learningrate": 0.08689,
      "dropout": 0.1001,
      "epoch": 9.1303,
      "batchsize": 39.58335,
      "optimizer": 2.39709,
      "acc": 0.10011111111111111,
      "loss": 14.50449479534008
    }
  },
  "2": {
    "0": {
      "name": 0,
      "learningrate": 0.02413,
      "dropout": 0.18331,
      "epoch": 12.54523,
      "batchsize": 77.41059,
      "optimizer": 0.9342,
      "acc": 0.8499629629629629,
      "loss": 0.42752850704722933
    },
    "1": {
      "name": 1,
      "learningrate": 0.03036,
      "dropout": 0.32013,
      "epoch": 12.60031,
      "batchsize": 67.76776,
      "optimizer": 0.52234,
      "acc": 0.848574074074074,
      "loss": 0.42461459506441046
    },
    "2": {
      "name": 2,
      "learningrate": 0.02742,
      "dropout": 0.22055,
      "epoch": 10.067,
      "batchsize": 39.38856,
      "optimizer": 0.75553,
      "acc": 0.8482962962962963,
      "loss": 0.42970467600999057
    },
    "3": {
      "name": 3,
      "learningrate": 0.02934,
      "dropout": 0.16927,
      "epoch": 11.51869,
      "batchsize": 43.26204,
      "optimizer": 0.78003,
      "acc": 0.8480555555555556,
      "loss": 0.4267124666593693
    },
    "4": {
      "name": 4,
      "learningrate": 0.02805,
      "dropout": 0.29889,
      "epoch": 12.12136,
      "batchsize": 43.30792,
      "optimizer": 0.61792,
      "acc": 0.8458703703703704,
      "loss": 0.43389736090766057
    },
    "5": {
      "name": 5,
      "learningrate": 0.06351,
      "dropout": 0.3439,
      "epoch": 11.57052,
      "batchsize": 61.91032,
      "optimizer": 0.5692,
      "acc": 0.8443703703703703,
      "loss": 0.44059190238405155
    },
    "6": {
      "name": 6,
      "learningrate": 0.01079,
      "dropout": 0.30602,
      "epoch": 11.20501,
      "batchsize": 67.50912,
      "optimizer": 0.89012,
      "acc": 0.8443333333333334,
      "loss": 0.44914615473040825
    },
    "7": {
      "name": 7,
      "learningrate": 0.01436,
      "dropout": 0.11767,
      "epoch": 8.33856,
      "batchsize": 77.97804,
      "optimizer": 0.54663,
      "acc": 0.8425925925925926,
      "loss": 0.44788888413376277
    },
    "8": {
      "name": 8,
      "learningrate": 0.01101,
      "dropout": 0.27769,
      "epoch": 10.35094,
      "batchsize": 58.87035,
      "optimizer": 0.68817,
      "acc": 0.8412962962962963,
      "loss": 0.4488011448118422
    },
    "9": {
      "name": 9,
      "learningrate": 0.06519,
      "dropout": 0.33525,
      "epoch": 10.76444,
      "batchsize": 69.17887,
      "optimizer": 0.84994,
      "acc": 0.8405,
      "loss": 0.44959604772815
    },
    "10": {
      "name": 10,
      "learningrate": 0.02659556305972846,
      "dropout": 0.23019951466921384,
      "epoch": 8.946495350875523,
      "batchsize": 35.6274590768487,
      "optimizer": 1.2581417613669177,
      "acc": 0.8392592592592593,
      "loss": 0.4471877699604741
    },
    "11": {
      "name": 11,
      "learningrate": 0.02935,
      "dropout": 0.1165,
      "epoch": 7.58112,
      "batchsize": 72.91879,
      "optimizer": 0.88208,
      "acc": 0.8381666666666666,
      "loss": 0.4628528504062582
    },
    "12": {
      "name": 12,
      "learningrate": 0.00991,
      "dropout": 0.33929,
      "epoch": 9.07879,
      "batchsize": 63.54913,
      "optimizer": 0.82353,
      "acc": 0.837037037037037,
      "loss": 0.47053826203169646
    },
    "13": {
      "name": 13,
      "learningrate": 0.01157,
      "dropout": 0.27893,
      "epoch": 8.73504,
      "batchsize": 69.47417,
      "optimizer": 0.59269,
      "acc": 0.836462962962963,
      "loss": 0.46580433679510047
    },
    "14": {
      "name": 14,
      "learningrate": 0.00822,
      "dropout": 0.15801,
      "epoch": 6.6203,
      "batchsize": 55.96418,
      "optimizer": 0.79954,
      "acc": 0.830462962962963,
      "loss": 0.4845618554927685
    },
    "15": {
      "name": 15,
      "learningrate": 0.02358,
      "dropout": 0.35302,
      "epoch": 10.3473,
      "batchsize": 72.1033,
      "optimizer": 0.70314,
      "acc": 0.8298888888888889,
      "loss": 0.47321727486892984
    },
    "16": {
      "name": 16,
      "learningrate": 0.01015,
      "dropout": 0.13406,
      "epoch": 9.22449,
      "batchsize": 53.00392,
      "optimizer": 0.59747,
      "acc": 0.8244074074074074,
      "loss": 0.4875279969992461
    },
    "17": {
      "name": 17,
      "learningrate": 0.01542,
      "dropout": 0.43207,
      "epoch": 10.63791,
      "batchsize": 65.9625,
      "optimizer": 1.56303,
      "acc": 0.795425925925926,
      "loss": 0.7102806312198993
    },
    "18": {
      "name": 18,
      "learningrate": 0.0699697690375552,
      "dropout": 0.41335743580298284,
      "epoch": 7.124733268487085,
      "batchsize": 53.771229624002984,
      "optimizer": 2.3233928428169666,
      "acc": 0.19925925925925925,
      "loss": 12.906415812739619
    },
    "19": {
      "name": 19,
      "learningrate": 0.06315355137722987,
      "dropout": 0.10909635632344436,
      "epoch": 5.466174169462473,
      "batchsize": 40.55132911055528,
      "optimizer": 0.07200960391108213,
      "acc": 0.1991851851851852,
      "loss": 12.90733083484791
    },
    "20": {
      "name": 20,
      "learningrate": 0.0313,
      "dropout": 0.26598,
      "epoch": 10.31411,
      "batchsize": 29.48504,
      "optimizer": 1.59468,
      "acc": 0.19814814814814816,
      "loss": 12.922449238529913
    }
  },
  "3": {
    "0": {
      "name": 0,
      "learningrate": 0.03099,
      "dropout": 0.11334,
      "epoch": 16.29587,
      "batchsize": 88.74285,
      "optimizer": 0.6964,
      "acc": 0.8538518518518519,
      "loss": 0.421452188734655
    },
    "1": {
      "name": 1,
      "learningrate": 0.02413,
      "dropout": 0.18331,
      "epoch": 12.54523,
      "batchsize": 77.41059,
      "optimizer": 0.9342,
      "acc": 0.8526111111111111,
      "loss": 0.42563977693186866
    },
    "2": {
      "name": 2,
      "learningrate": 0.03013,
      "dropout": 0.21375,
      "epoch": 11.88823,
      "batchsize": 26.45482,
      "optimizer": 0.62054,
      "acc": 0.8522222222222222,
      "loss": 0.4224570699753585
    },
    "3": {
      "name": 3,
      "learningrate": 0.06486,
      "dropout": 0.13073,
      "epoch": 14.85067,
      "batchsize": 67.41372,
      "optimizer": 0.99233,
      "acc": 0.851037037037037,
      "loss": 0.4279356019143705
    },
    "4": {
      "name": 4,
      "learningrate": 0.01826,
      "dropout": 0.2024,
      "epoch": 15.86248,
      "batchsize": 71.08177,
      "optimizer": 0.77507,
      "acc": 0.849574074074074,
      "loss": 0.42582611562146083
    },
    "5": {
      "name": 5,
      "learningrate": 0.03036,
      "dropout": 0.32013,
      "epoch": 12.60031,
      "batchsize": 67.76776,
      "optimizer": 0.52234,
      "acc": 0.8490740740740741,
      "loss": 0.42475813439157273
    },
    "6": {
      "name": 6,
      "learningrate": 0.02185,
      "dropout": 0.21322,
      "epoch": 12.35037,
      "batchsize": 55.88815,
      "optimizer": 1.16087,
      "acc": 0.8475925925925926,
      "loss": 0.42998303337891897
    },
    "7": {
      "name": 7,
      "learningrate": 0.03661,
      "dropout": 0.16009,
      "epoch": 10.03944,
      "batchsize": 97.76602,
      "optimizer": 0.56114,
      "acc": 0.8429074074074074,
      "loss": 0.441014647382277
    },
    "8": {
      "name": 8,
      "learningrate": 0.03719,
      "dropout": 0.25271,
      "epoch": 9.81357,
      "batchsize": 57.62853,
      "optimizer": 0.99854,
      "acc": 0.8428703703703704,
      "loss": 0.43943557573689357
    },
    "9": {
      "name": 9,
      "learningrate": 0.02875,
      "dropout": 0.25076,
      "epoch": 12.43409,
      "batchsize": 37.01418,
      "optimizer": 0.92646,
      "acc": 0.8405185185185186,
      "loss": 0.4483082366475353
    },
    "10": {
      "name": 10,
      "learningrate": 0.00915,
      "dropout": 0.37166,
      "epoch": 15.92121,
      "batchsize": 45.93397,
      "optimizer": 0.89072,
      "acc": 0.8405185185185186,
      "loss": 0.44753997177989396
    },
    "11": {
      "name": 11,
      "learningrate": 0.06634,
      "dropout": 0.38535,
      "epoch": 9.65274,
      "batchsize": 85.90944,
      "optimizer": 0.63493,
      "acc": 0.8371111111111111,
      "loss": 0.4629086652464337
    },
    "12": {
      "name": 12,
      "learningrate": 0.00927,
      "dropout": 0.36484,
      "epoch": 9.44136,
      "batchsize": 73.24535,
      "optimizer": 0.89004,
      "acc": 0.833037037037037,
      "loss": 0.4722682402884519
    },
    "13": {
      "name": 13,
      "learningrate": 0.00617240044182181,
      "dropout": 0.49819735040109653,
      "epoch": 6.587535786165635,
      "batchsize": 34.97563816914621,
      "optimizer": 1.3262238384941676,
      "acc": 0.8181111111111111,
      "loss": 0.5263034162962879
    },
    "14": {
      "name": 14,
      "learningrate": 0.01487,
      "dropout": 0.09079,
      "epoch": 7.45263,
      "batchsize": 81.0154,
      "optimizer": 0.56706,
      "acc": 0.8112037037037036,
      "loss": 0.527073685058841
    },
    "15": {
      "name": 15,
      "learningrate": 0.01366,
      "dropout": 0.44353,
      "epoch": 10.73783,
      "batchsize": 49.08725,
      "optimizer": 0.46955,
      "acc": 0.7880185185185186,
      "loss": 0.6079867922376704
    },
    "16": {
      "name": 16,
      "learningrate": 0.027,
      "dropout": 0.08533,
      "epoch": 8.68014,
      "batchsize": 27.14861,
      "optimizer": 0.45551,
      "acc": 0.7348518518518519,
      "loss": 0.828949878109826
    },
    "17": {
      "name": 17,
      "learningrate": 0.0345,
      "dropout": 0.35243,
      "epoch": 14.05162,
      "batchsize": 41.99577,
      "optimizer": 0.42911,
      "acc": 0.7167962962962963,
      "loss": 0.8917975208582701
    },
    "18": {
      "name": 18,
      "learningrate": 0.02781760423645114,
      "dropout": 0.4153491116755495,
      "epoch": 6.702560456805001,
      "batchsize": 54.24523757251471,
      "optimizer": 0.02553247178777085,
      "acc": 0.7039814814814814,
      "loss": 0.7240331039075498
    },
    "19": {
      "name": 19,
      "learningrate": 0.03584,
      "dropout": 0.33287,
      "epoch": 12.87591,
      "batchsize": 32.6313,
      "optimizer": 2.03532,
      "acc": 0.3822037037037037,
      "loss": 9.949763847916214
    },
    "20": {
      "name": 20,
      "learningrate": 0.07794,
      "dropout": 0.26499,
      "epoch": 9.87513,
      "batchsize": 25.56595,
      "optimizer": 1.80782,
      "acc": 0.1985925925925926,
      "loss": 12.91689337158203
    }
  },
  "4": {
    "0": {
      "name": 0,
      "learningrate": 0.02458,
      "dropout": 0.20109,
      "epoch": 13.40006,
      "batchsize": 29.33186,
      "optimizer": 0.85139,
      "acc": 0.8538888888888889,
      "loss": 0.4164220620084692
    },
    "1": {
      "name": 1,
      "learningrate": 0.02897,
      "dropout": 0.23135,
      "epoch": 12.99495,
      "batchsize": 42.7405,
      "optimizer": 1.24679,
      "acc": 0.8533148148148149,
      "loss": 0.413225354914312
    },
    "2": {
      "name": 2,
      "learningrate": 0.01737,
      "dropout": 0.2036,
      "epoch": 15.94257,
      "batchsize": 30.81005,
      "optimizer": 1.01732,
      "acc": 0.8514814814814815,
      "loss": 0.4263532010096091
    },
    "3": {
      "name": 3,
      "learningrate": 0.02033,
      "dropout": 0.23182,
      "epoch": 13.80854,
      "batchsize": 76.56577,
      "optimizer": 0.65019,
      "acc": 0.8485555555555555,
      "loss": 0.4332725319509153
    },
    "4": {
      "name": 4,
      "learningrate": 0.04249,
      "dropout": 0.2482,
      "epoch": 11.7955,
      "batchsize": 51.95024,
      "optimizer": 1.1395,
      "acc": 0.8481111111111111,
      "loss": 0.43043701740988977
    },
    "5": {
      "name": 5,
      "learningrate": 0.02549,
      "dropout": 0.20061,
      "epoch": 11.8321,
      "batchsize": 41.8716,
      "optimizer": 1.06357,
      "acc": 0.847574074074074,
      "loss": 0.4306934484640757
    },
    "6": {
      "name": 6,
      "learningrate": 0.02213,
      "dropout": 0.20511,
      "epoch": 12.28182,
      "batchsize": 91.08503,
      "optimizer": 1.3612,
      "acc": 0.8472777777777778,
      "loss": 0.4284941749661057
    },
    "7": {
      "name": 7,
      "learningrate": 0.0225,
      "dropout": 0.17721,
      "epoch": 10.57432,
      "batchsize": 32.77358,
      "optimizer": 0.56395,
      "acc": 0.8432777777777778,
      "loss": 0.43656924242443507
    },
    "8": {
      "name": 8,
      "learningrate": 0.03008,
      "dropout": 0.16988,
      "epoch": 9.97805,
      "batchsize": 88.35753,
      "optimizer": 1.12827,
      "acc": 0.8428888888888889,
      "loss": 0.4468012553674203
    },
    "9": {
      "name": 9,
      "learningrate": 0.02096,
      "dropout": 0.19704,
      "epoch": 9.836,
      "batchsize": 63.67964,
      "optimizer": 1.45545,
      "acc": 0.8427407407407408,
      "loss": 0.44250687254358223
    },
    "10": {
      "name": 10,
      "learningrate": 0.02413,
      "dropout": 0.18331,
      "epoch": 12.54523,
      "batchsize": 77.41059,
      "optimizer": 0.9342,
      "acc": 0.8424814814814815,
      "loss": 0.43910038207195423
    },
    "11": {
      "name": 11,
      "learningrate": 0.02453,
      "dropout": 0.12575,
      "epoch": 13.1721,
      "batchsize": 87.39397,
      "optimizer": 0.93766,
      "acc": 0.8423148148148148,
      "loss": 0.44678989241741324
    },
    "12": {
      "name": 12,
      "learningrate": 0.01801,
      "dropout": 0.25044,
      "epoch": 8.47527,
      "batchsize": 79.87421,
      "optimizer": 1.00715,
      "acc": 0.841037037037037,
      "loss": 0.4556386388628571
    },
    "13": {
      "name": 13,
      "learningrate": 0.03678,
      "dropout": 0.29034,
      "epoch": 9.99523,
      "batchsize": 75.79589,
      "optimizer": 0.53878,
      "acc": 0.840574074074074,
      "loss": 0.44393378127945793
    },
    "14": {
      "name": 14,
      "learningrate": 0.03099,
      "dropout": 0.11334,
      "epoch": 16.29587,
      "batchsize": 88.74285,
      "optimizer": 0.6964,
      "acc": 0.8378888888888889,
      "loss": 0.4588616012776339
    },
    "15": {
      "name": 15,
      "learningrate": 0.02855,
      "dropout": 0.12868,
      "epoch": 7.75304,
      "batchsize": 49.15072,
      "optimizer": 0.9244,
      "acc": 0.8365555555555556,
      "loss": 0.45336250478691525
    },
    "16": {
      "name": 16,
      "learningrate": 0.02922,
      "dropout": 0.2682,
      "epoch": 12.8713,
      "batchsize": 76.15769,
      "optimizer": 0.48748,
      "acc": 0.7914629629629629,
      "loss": 0.5837622307583138
    },
    "17": {
      "name": 17,
      "learningrate": 0.034561208968276684,
      "dropout": 0.18129728883061336,
      "epoch": 9.065960299216226,
      "batchsize": 42.14104604953609,
      "optimizer": 0.1505520762450263,
      "acc": 0.7083333333333334,
      "loss": 0.9409075681015298
    },
    "18": {
      "name": 18,
      "learningrate": 0.022620762531980393,
      "dropout": 0.24137422836177852,
      "epoch": 5.618592949478044,
      "batchsize": 53.04539662565284,
      "optimizer": 2.4056225975695766,
      "acc": 0.6948518518518518,
      "loss": 1.3119530106473851
    },
    "19": {
      "name": 19,
      "learningrate": 0.03141,
      "dropout": 0.26963,
      "epoch": 9.33452,
      "batchsize": 34.18233,
      "optimizer": 0.40799,
      "acc": 0.6668888888888889,
      "loss": 0.9023775501427828
    },
    "20": {
      "name": 20,
      "learningrate": 0.07746,
      "dropout": 0.11637,
      "epoch": 8.12127,
      "batchsize": 122.09998,
      "optimizer": 0.47188,
      "acc": 0.3665925925925926,
      "loss": 10.20646031584563
    }
  },
  "5": {
    "0": {
      "name": 0,
      "learningrate": 0.03648,
      "dropout": 0.30095,
      "epoch": 17.93632,
      "batchsize": 42.04195,
      "optimizer": 1.22366,
      "acc": 0.8551851851851852,
      "loss": 0.4144209211093408
    },
    "1": {
      "name": 1,
      "learningrate": 0.02458,
      "dropout": 0.20109,
      "epoch": 13.40006,
      "batchsize": 29.33186,
      "optimizer": 0.85139,
      "acc": 0.8545,
      "loss": 0.4202732899983724
    },
    "2": {
      "name": 2,
      "learningrate": 0.01957,
      "dropout": 0.23029,
      "epoch": 13.99703,
      "batchsize": 29.67064,
      "optimizer": 1.04625,
      "acc": 0.8543333333333333,
      "loss": 0.4108734290555671
    },
    "3": {
      "name": 3,
      "learningrate": 0.03179,
      "dropout": 0.17296,
      "epoch": 14.37633,
      "batchsize": 51.46028,
      "optimizer": 0.99215,
      "acc": 0.8518148148148148,
      "loss": 0.41529565400105933
    },
    "4": {
      "name": 4,
      "learningrate": 0.02182,
      "dropout": 0.17228,
      "epoch": 15.93941,
      "batchsize": 31.74387,
      "optimizer": 0.89814,
      "acc": 0.8513888888888889,
      "loss": 0.4181910825923637
    },
    "5": {
      "name": 5,
      "learningrate": 0.01719,
      "dropout": 0.17069,
      "epoch": 13.29805,
      "batchsize": 21.92574,
      "optimizer": 1.18365,
      "acc": 0.8508148148148148,
      "loss": 0.4249976892956981
    },
    "6": {
      "name": 6,
      "learningrate": 0.03054,
      "dropout": 0.22261,
      "epoch": 12.1203,
      "batchsize": 45.93002,
      "optimizer": 1.25118,
      "acc": 0.8496666666666667,
      "loss": 0.4264942625628577
    },
    "7": {
      "name": 7,
      "learningrate": 0.02897,
      "dropout": 0.23135,
      "epoch": 12.99495,
      "batchsize": 42.7405,
      "optimizer": 1.24679,
      "acc": 0.8484074074074074,
      "loss": 0.42631063682061654
    },
    "8": {
      "name": 8,
      "learningrate": 0.0126,
      "dropout": 0.25421,
      "epoch": 12.92946,
      "batchsize": 24.43647,
      "optimizer": 1.2193,
      "acc": 0.8477962962962963,
      "loss": 0.4314209604219154
    },
    "9": {
      "name": 9,
      "learningrate": 0.01969,
      "dropout": 0.22184,
      "epoch": 11.21584,
      "batchsize": 51.74203,
      "optimizer": 0.86719,
      "acc": 0.8477777777777777,
      "loss": 0.4256149132295891
    },
    "10": {
      "name": 10,
      "learningrate": 0.03032,
      "dropout": 0.15399,
      "epoch": 11.95482,
      "batchsize": 47.49734,
      "optimizer": 1.35538,
      "acc": 0.8471296296296297,
      "loss": 0.4289304582896056
    },
    "11": {
      "name": 11,
      "learningrate": 0.05086297463850922,
      "dropout": 0.1349788336100723,
      "epoch": 7.546110200936616,
      "batchsize": 39.12515208849315,
      "optimizer": 0.7958192682196045,
      "acc": 0.8468148148148148,
      "loss": 0.4307373291209892
    },
    "12": {
      "name": 12,
      "learningrate": 0.02569,
      "dropout": 0.19696,
      "epoch": 9.1645,
      "batchsize": 35.59017,
      "optimizer": 1.33672,
      "acc": 0.8454814814814815,
      "loss": 0.4307182680324272
    },
    "13": {
      "name": 13,
      "learningrate": 0.048663883001542375,
      "dropout": 0.2816288914159834,
      "epoch": 8.901646399234568,
      "batchsize": 40.936485191220804,
      "optimizer": 0.5497329087367068,
      "acc": 0.8452222222222222,
      "loss": 0.4423488396185416
    },
    "14": {
      "name": 14,
      "learningrate": 0.03099,
      "dropout": 0.23983,
      "epoch": 9.06992,
      "batchsize": 80.58033,
      "optimizer": 1.4067,
      "acc": 0.8447592592592592,
      "loss": 0.4406336032461237
    },
    "15": {
      "name": 15,
      "learningrate": 0.01502,
      "dropout": 0.17875,
      "epoch": 11.08211,
      "batchsize": 74.38543,
      "optimizer": 1.25112,
      "acc": 0.843462962962963,
      "loss": 0.4425899973048104
    },
    "16": {
      "name": 16,
      "learningrate": 0.01908,
      "dropout": 0.21544,
      "epoch": 12.61026,
      "batchsize": 96.3163,
      "optimizer": 1.3242,
      "acc": 0.8428518518518519,
      "loss": 0.4483736115208379
    },
    "17": {
      "name": 17,
      "learningrate": 0.02686,
      "dropout": 0.1681,
      "epoch": 12.74638,
      "batchsize": 100.58297,
      "optimizer": 1.10652,
      "acc": 0.8420925925925926,
      "loss": 0.44058917027049593
    },
    "18": {
      "name": 18,
      "learningrate": 0.02231,
      "dropout": 0.27763,
      "epoch": 10.77196,
      "batchsize": 74.34365,
      "optimizer": 1.00545,
      "acc": 0.8407962962962963,
      "loss": 0.4566844718367965
    },
    "19": {
      "name": 19,
      "learningrate": 0.01874,
      "dropout": 0.14482,
      "epoch": 13.64885,
      "batchsize": 25.20024,
      "optimizer": 1.57854,
      "acc": 0.7986296296296296,
      "loss": 0.7972569570541382
    },
    "20": {
      "name": 20,
      "learningrate": 0.02816,
      "dropout": 0.25764,
      "epoch": 11.61006,
      "batchsize": 113.32473,
      "optimizer": 1.65897,
      "acc": 0.7507037037037037,
      "loss": 0.6872924377653334
    }
  },
  "6": {
    "0": {
      "name": 0,
      "learningrate": 0.0352,
      "dropout": 0.15968,
      "epoch": 19.02365,
      "batchsize": 39.20649,
      "optimizer": 0.92074,
      "acc": 0.8580555555555556,
      "loss": 0.40476780017217
    },
    "1": {
      "name": 1,
      "learningrate": 0.02124,
      "dropout": 0.16484,
      "epoch": 13.63259,
      "batchsize": 38.55599,
      "optimizer": 0.74802,
      "acc": 0.8532592592592593,
      "loss": 0.4143723754397145
    },
    "2": {
      "name": 2,
      "learningrate": 0.02158,
      "dropout": 0.23009,
      "epoch": 15.46892,
      "batchsize": 33.35603,
      "optimizer": 1.02605,
      "acc": 0.8531111111111112,
      "loss": 0.4162026253982827
    },
    "3": {
      "name": 3,
      "learningrate": 0.03055,
      "dropout": 0.17453,
      "epoch": 17.96941,
      "batchsize": 27.28296,
      "optimizer": 0.76357,
      "acc": 0.8528333333333333,
      "loss": 0.417952669567532
    },
    "4": {
      "name": 4,
      "learningrate": 0.03648,
      "dropout": 0.30095,
      "epoch": 17.93632,
      "batchsize": 42.04195,
      "optimizer": 1.22366,
      "acc": 0.8486111111111111,
      "loss": 0.42816373157721976
    },
    "5": {
      "name": 5,
      "learningrate": 0.01768,
      "dropout": 0.19767,
      "epoch": 8.97558,
      "batchsize": 23.67266,
      "optimizer": 0.75659,
      "acc": 0.8477037037037037,
      "loss": 0.43768870441118873
    },
    "6": {
      "name": 6,
      "learningrate": 0.01429,
      "dropout": 0.28871,
      "epoch": 13.08119,
      "batchsize": 26.37579,
      "optimizer": 0.93438,
      "acc": 0.8475925925925926,
      "loss": 0.4262701814439562
    },
    "7": {
      "name": 7,
      "learningrate": 0.03544,
      "dropout": 0.20382,
      "epoch": 12.46342,
      "batchsize": 42.6769,
      "optimizer": 1.03661,
      "acc": 0.8475925925925926,
      "loss": 0.42891847995917004
    },
    "8": {
      "name": 8,
      "learningrate": 0.03703,
      "dropout": 0.212,
      "epoch": 9.92023,
      "batchsize": 31.62401,
      "optimizer": 0.97496,
      "acc": 0.847462962962963,
      "loss": 0.43525496574684425
    },
    "9": {
      "name": 9,
      "learningrate": 0.02049,
      "dropout": 0.22861,
      "epoch": 12.16578,
      "batchsize": 25.00639,
      "optimizer": 1.13445,
      "acc": 0.8471851851851852,
      "loss": 0.433032802718657
    },
    "10": {
      "name": 10,
      "learningrate": 0.02458,
      "dropout": 0.20109,
      "epoch": 13.40006,
      "batchsize": 29.33186,
      "optimizer": 0.85139,
      "acc": 0.8466851851851852,
      "loss": 0.429363073653645
    },
    "11": {
      "name": 11,
      "learningrate": 0.01391,
      "dropout": 0.21624,
      "epoch": 12.39218,
      "batchsize": 47.29339,
      "optimizer": 0.78797,
      "acc": 0.8450185185185185,
      "loss": 0.4376737616106316
    },
    "12": {
      "name": 12,
      "learningrate": 0.04354,
      "dropout": 0.20466,
      "epoch": 10.73889,
      "batchsize": 36.45305,
      "optimizer": 0.9363,
      "acc": 0.8441111111111111,
      "loss": 0.4346616663049769
    },
    "13": {
      "name": 13,
      "learningrate": 0.02246,
      "dropout": 0.20125,
      "epoch": 10.99354,
      "batchsize": 53.95768,
      "optimizer": 0.76943,
      "acc": 0.8439444444444445,
      "loss": 0.439282751083374
    },
    "14": {
      "name": 14,
      "learningrate": 0.01195,
      "dropout": 0.28854,
      "epoch": 10.09786,
      "batchsize": 22.32321,
      "optimizer": 1.18049,
      "acc": 0.8425,
      "loss": 0.448020285571063
    },
    "15": {
      "name": 15,
      "learningrate": 0.061766678345767045,
      "dropout": 0.08977749447250738,
      "epoch": 9.568614014916104,
      "batchsize": 50.38330814812946,
      "optimizer": 1.1096285771196064,
      "acc": 0.8398333333333333,
      "loss": 0.4468622687878432
    },
    "16": {
      "name": 16,
      "learningrate": 0.03333,
      "dropout": 0.22472,
      "epoch": 9.8033,
      "batchsize": 35.88841,
      "optimizer": 1.01883,
      "acc": 0.8281666666666667,
      "loss": 0.4624988454138791
    },
    "17": {
      "name": 17,
      "learningrate": 0.07024224730805217,
      "dropout": 0.4425219135203549,
      "epoch": 7.98327787559357,
      "batchsize": 62.4663701084199,
      "optimizer": 2.931531885949829,
      "acc": 0.8242962962962963,
      "loss": 0.5093879728847079
    },
    "18": {
      "name": 18,
      "learningrate": 0.02656,
      "dropout": 0.27044,
      "epoch": 10.05921,
      "batchsize": 56.32014,
      "optimizer": 1.24527,
      "acc": 0.8180925925925926,
      "loss": 0.4908224027245133
    },
    "19": {
      "name": 19,
      "learningrate": 0.01352,
      "dropout": 0.13312,
      "epoch": 10.13324,
      "batchsize": 16.46545,
      "optimizer": 1.53912,
      "acc": 0.7722777777777777,
      "loss": 0.822178372224172
    },
    "20": {
      "name": 20,
      "learningrate": 0.01711,
      "dropout": 0.16864,
      "epoch": 13.85317,
      "batchsize": 17.02991,
      "optimizer": 1.51376,
      "acc": 0.7169444444444445,
      "loss": 0.9864493150313696
    }
  },
  "7": {
    "0": {
      "name": 0,
      "learningrate": 0.02901,
      "dropout": 0.19381,
      "epoch": 22.50052,
      "batchsize": 37.25007,
      "optimizer": 1.36033,
      "acc": 0.8615925925925926,
      "loss": 0.4040199049446318
    },
    "1": {
      "name": 1,
      "learningrate": 0.0352,
      "dropout": 0.15968,
      "epoch": 19.02365,
      "batchsize": 39.20649,
      "optimizer": 0.92074,
      "acc": 0.8606111111111111,
      "loss": 0.39989905972613227
    },
    "2": {
      "name": 2,
      "learningrate": 0.02743,
      "dropout": 0.20388,
      "epoch": 22.38136,
      "batchsize": 52.4096,
      "optimizer": 0.61339,
      "acc": 0.8600185185185185,
      "loss": 0.4023930890604302
    },
    "3": {
      "name": 3,
      "learningrate": 0.05123,
      "dropout": 0.24052,
      "epoch": 21.01331,
      "batchsize": 37.53316,
      "optimizer": 1.42133,
      "acc": 0.8559629629629629,
      "loss": 0.41891790021348885
    },
    "4": {
      "name": 4,
      "learningrate": 0.04132,
      "dropout": 0.1693,
      "epoch": 16.08414,
      "batchsize": 29.15415,
      "optimizer": 1.08929,
      "acc": 0.8548888888888889,
      "loss": 0.41067573390183626
    },
    "5": {
      "name": 5,
      "learningrate": 0.03646,
      "dropout": 0.18,
      "epoch": 20.00493,
      "batchsize": 22.08717,
      "optimizer": 1.15696,
      "acc": 0.8540555555555556,
      "loss": 0.4273336449077836
    },
    "6": {
      "name": 6,
      "learningrate": 0.04531,
      "dropout": 0.24918,
      "epoch": 10.12176,
      "batchsize": 20.43538,
      "optimizer": 0.79351,
      "acc": 0.8522962962962963,
      "loss": 0.42192540974087184
    },
    "7": {
      "name": 7,
      "learningrate": 0.01048,
      "dropout": 0.1488,
      "epoch": 19.4092,
      "batchsize": 29.99328,
      "optimizer": 0.69138,
      "acc": 0.8515370370370371,
      "loss": 0.42809842545897875
    },
    "8": {
      "name": 8,
      "learningrate": 0.02095,
      "dropout": 0.24577,
      "epoch": 14.47823,
      "batchsize": 22.75425,
      "optimizer": 1.01862,
      "acc": 0.8508518518518519,
      "loss": 0.4156184868724258
    },
    "9": {
      "name": 9,
      "learningrate": 0.03964,
      "dropout": 0.10518,
      "epoch": 11.49119,
      "batchsize": 47.71431,
      "optimizer": 0.78772,
      "acc": 0.8498703703703704,
      "loss": 0.42425085058256434
    },
    "10": {
      "name": 10,
      "learningrate": 0.02124,
      "dropout": 0.16484,
      "epoch": 13.63259,
      "batchsize": 38.55599,
      "optimizer": 0.74802,
      "acc": 0.8485370370370371,
      "loss": 0.4264836169459202
    },
    "11": {
      "name": 11,
      "learningrate": 0.02739,
      "dropout": 0.1759,
      "epoch": 15.86132,
      "batchsize": 49.95438,
      "optimizer": 1.41213,
      "acc": 0.8468333333333333,
      "loss": 0.4247792185721574
    },
    "12": {
      "name": 12,
      "learningrate": 0.01404,
      "dropout": 0.20431,
      "epoch": 9.52465,
      "batchsize": 44.20996,
      "optimizer": 0.58429,
      "acc": 0.8445185185185186,
      "loss": 0.4410619092340823
    },
    "13": {
      "name": 13,
      "learningrate": 0.01959,
      "dropout": 0.1613,
      "epoch": 11.83331,
      "batchsize": 41.15067,
      "optimizer": 0.72166,
      "acc": 0.8445185185185186,
      "loss": 0.441802664231371
    },
    "14": {
      "name": 14,
      "learningrate": 0.04199,
      "dropout": 0.27795,
      "epoch": 7.97731,
      "batchsize": 22.92304,
      "optimizer": 0.87599,
      "acc": 0.8444259259259259,
      "loss": 0.4398218843583707
    },
    "15": {
      "name": 15,
      "learningrate": 0.05543,
      "dropout": 0.26268,
      "epoch": 10.36902,
      "batchsize": 46.15212,
      "optimizer": 1.215,
      "acc": 0.8435555555555555,
      "loss": 0.4408442259452961
    },
    "16": {
      "name": 16,
      "learningrate": 0.02783,
      "dropout": 0.15713,
      "epoch": 10.78409,
      "batchsize": 51.43754,
      "optimizer": 0.95944,
      "acc": 0.8401296296296297,
      "loss": 0.44492457772625815
    },
    "17": {
      "name": 17,
      "learningrate": 0.04617,
      "dropout": 0.14922,
      "epoch": 8.8839,
      "batchsize": 54.29966,
      "optimizer": 1.00073,
      "acc": 0.8350185185185185,
      "loss": 0.45758849739586865
    },
    "18": {
      "name": 18,
      "learningrate": 0.07714,
      "dropout": 0.07452,
      "epoch": 7.45436,
      "batchsize": 39.79397,
      "optimizer": 0.99428,
      "acc": 0.8245185185185185,
      "loss": 0.49197727549959114
    },
    "19": {
      "name": 19,
      "learningrate": 0.08136249870034575,
      "dropout": 0.47107678909265693,
      "epoch": 5.982967990686207,
      "batchsize": 47.45027230601855,
      "optimizer": 2.25767122693442,
      "acc": 0.2647962962962963,
      "loss": 11.847658400641548
    },
    "20": {
      "name": 20,
      "learningrate": 0.09962983808144543,
      "dropout": 0.28888351802058426,
      "epoch": 6.608938388017142,
      "batchsize": 53.72558548348961,
      "optimizer": 0.22028365278824646,
      "acc": 0.10074074074074074,
      "loss": 14.49434634427671
    }
  },
  "8": {
    "0": {
      "name": 0,
      "learningrate": 0.03438,
      "dropout": 0.18208,
      "epoch": 29.03141,
      "batchsize": 16.07211,
      "optimizer": 1.45449,
      "acc": 0.8594814814814815,
      "loss": 0.41421173683802287
    },
    "1": {
      "name": 1,
      "learningrate": 0.04113,
      "dropout": 0.12017,
      "epoch": 18.47466,
      "batchsize": 33.76994,
      "optimizer": 0.64219,
      "acc": 0.8571851851851852,
      "loss": 0.41645227570003934
    },
    "2": {
      "name": 2,
      "learningrate": 0.05082,
      "dropout": 0.11351,
      "epoch": 13.40089,
      "batchsize": 33.87052,
      "optimizer": 0.74143,
      "acc": 0.8554074074074074,
      "loss": 0.4174685497813755
    },
    "3": {
      "name": 3,
      "learningrate": 0.01333,
      "dropout": 0.18355,
      "epoch": 24.58218,
      "batchsize": 24.50114,
      "optimizer": 1.2209,
      "acc": 0.8543333333333333,
      "loss": 0.41347696459293365
    },
    "4": {
      "name": 4,
      "learningrate": 0.02901,
      "dropout": 0.19381,
      "epoch": 22.50052,
      "batchsize": 37.25007,
      "optimizer": 1.36033,
      "acc": 0.8542777777777778,
      "loss": 0.4153618238060563
    },
    "5": {
      "name": 5,
      "learningrate": 0.01703,
      "dropout": 0.316,
      "epoch": 16.10876,
      "batchsize": 21.76335,
      "optimizer": 1.03672,
      "acc": 0.8541296296296297,
      "loss": 0.412358862735607
    },
    "6": {
      "name": 6,
      "learningrate": 0.02734,
      "dropout": 0.18427,
      "epoch": 13.32688,
      "batchsize": 62.47313,
      "optimizer": 0.52435,
      "acc": 0.8537222222222223,
      "loss": 0.42101141100018113
    },
    "7": {
      "name": 7,
      "learningrate": 0.03209,
      "dropout": 0.31893,
      "epoch": 24.35117,
      "batchsize": 59.39423,
      "optimizer": 0.77783,
      "acc": 0.853462962962963,
      "loss": 0.41331215201042315
    },
    "8": {
      "name": 8,
      "learningrate": 0.0352,
      "dropout": 0.15968,
      "epoch": 19.02365,
      "batchsize": 39.20649,
      "optimizer": 0.92074,
      "acc": 0.852462962962963,
      "loss": 0.41439514434779134
    },
    "9": {
      "name": 9,
      "learningrate": 0.04463,
      "dropout": 0.15268,
      "epoch": 20.62164,
      "batchsize": 45.15778,
      "optimizer": 0.65851,
      "acc": 0.8522962962962963,
      "loss": 0.42821085285478167
    },
    "10": {
      "name": 10,
      "learningrate": 0.02573,
      "dropout": 0.25038,
      "epoch": 18.77343,
      "batchsize": 63.97508,
      "optimizer": 1.43629,
      "acc": 0.8515185185185186,
      "loss": 0.4127806090116501
    },
    "11": {
      "name": 11,
      "learningrate": 0.03768,
      "dropout": 0.28531,
      "epoch": 21.2172,
      "batchsize": 27.72562,
      "optimizer": 1.17009,
      "acc": 0.8512777777777778,
      "loss": 0.42481748426843574
    },
    "12": {
      "name": 12,
      "learningrate": 0.03074,
      "dropout": 0.11105,
      "epoch": 12.60366,
      "batchsize": 60.56486,
      "optimizer": 1.12232,
      "acc": 0.8503888888888889,
      "loss": 0.42393409523699016
    },
    "13": {
      "name": 13,
      "learningrate": 0.00748,
      "dropout": 0.17143,
      "epoch": 13.96182,
      "batchsize": 25.95286,
      "optimizer": 0.88848,
      "acc": 0.8499074074074074,
      "loss": 0.4338270657415743
    },
    "14": {
      "name": 14,
      "learningrate": 0.02091,
      "dropout": 0.17272,
      "epoch": 12.20913,
      "batchsize": 35.81876,
      "optimizer": 1.25927,
      "acc": 0.8497962962962963,
      "loss": 0.4273067357275221
    },
    "15": {
      "name": 15,
      "learningrate": 0.03392,
      "dropout": 0.263,
      "epoch": 24.66234,
      "batchsize": 66.34622,
      "optimizer": 0.97757,
      "acc": 0.8492592592592593,
      "loss": 0.43409533594272753
    },
    "16": {
      "name": 16,
      "learningrate": 0.00928,
      "dropout": 0.18972,
      "epoch": 16.37924,
      "batchsize": 61.52939,
      "optimizer": 0.81261,
      "acc": 0.8457962962962963,
      "loss": 0.4350397877163357
    },
    "17": {
      "name": 17,
      "learningrate": 0.03154,
      "dropout": 0.17134,
      "epoch": 16.27414,
      "batchsize": 57.82638,
      "optimizer": 0.80704,
      "acc": 0.8389629629629629,
      "loss": 0.446868686499419
    },
    "18": {
      "name": 18,
      "learningrate": 0.009772123062923299,
      "dropout": 0.13800615909966815,
      "epoch": 9.016882501064263,
      "batchsize": 61.5437016507337,
      "optimizer": 0.009109636314222569,
      "acc": 0.8313148148148148,
      "loss": 0.5155306327100153
    },
    "19": {
      "name": 19,
      "learningrate": 0.08187583788828258,
      "dropout": 0.17003387538455106,
      "epoch": 7.765506741497107,
      "batchsize": 61.5158167250643,
      "optimizer": 2.5206585553091516,
      "acc": 0.8200555555555555,
      "loss": 0.5054906712284795
    },
    "20": {
      "name": 20,
      "learningrate": 0.02066,
      "dropout": 0.16477,
      "epoch": 16.2465,
      "batchsize": 56.79406,
      "optimizer": 0.43722,
      "acc": 0.7858148148148149,
      "loss": 0.6899747365668968
    }
  },
  "9": {
    "0": {
      "name": 0,
      "learningrate": 0.03892,
      "dropout": 0.12205,
      "epoch": 22.51235,
      "batchsize": 35.8539,
      "optimizer": 0.60509,
      "acc": 0.8622962962962963,
      "loss": 0.4127401554275442
    },
    "1": {
      "name": 1,
      "learningrate": 0.0296,
      "dropout": 0.16672,
      "epoch": 28.24371,
      "batchsize": 37.77119,
      "optimizer": 0.90086,
      "acc": 0.8615925925925926,
      "loss": 0.4078374611624965
    },
    "2": {
      "name": 2,
      "learningrate": 0.03024,
      "dropout": 0.20651,
      "epoch": 29.71144,
      "batchsize": 22.68294,
      "optimizer": 1.19235,
      "acc": 0.8610185185185185,
      "loss": 0.4021737285410916
    },
    "3": {
      "name": 3,
      "learningrate": 0.02885,
      "dropout": 0.16124,
      "epoch": 30.13248,
      "batchsize": 14.3581,
      "optimizer": 0.68466,
      "acc": 0.8596296296296296,
      "loss": 0.41754271415869393
    },
    "4": {
      "name": 4,
      "learningrate": 0.03438,
      "dropout": 0.18208,
      "epoch": 29.03141,
      "batchsize": 16.07211,
      "optimizer": 1.45449,
      "acc": 0.8583333333333333,
      "loss": 0.41806011347417477
    },
    "5": {
      "name": 5,
      "learningrate": 0.01622,
      "dropout": 0.14277,
      "epoch": 24.89019,
      "batchsize": 19.58382,
      "optimizer": 1.21691,
      "acc": 0.8580185185185185,
      "loss": 0.40681623582486753
    },
    "6": {
      "name": 6,
      "learningrate": 0.02896,
      "dropout": 0.22439,
      "epoch": 16.53318,
      "batchsize": 60.27214,
      "optimizer": 0.61062,
      "acc": 0.8569629629629629,
      "loss": 0.4092158485871774
    },
    "7": {
      "name": 7,
      "learningrate": 0.05274,
      "dropout": 0.12048,
      "epoch": 23.94742,
      "batchsize": 28.37522,
      "optimizer": 0.63012,
      "acc": 0.8562222222222222,
      "loss": 0.4214173564358994
    },
    "8": {
      "name": 8,
      "learningrate": 0.02134,
      "dropout": 0.26931,
      "epoch": 30.02907,
      "batchsize": 63.97939,
      "optimizer": 0.5794,
      "acc": 0.8561851851851852,
      "loss": 0.4109314156351266
    },
    "9": {
      "name": 9,
      "learningrate": 0.04113,
      "dropout": 0.12017,
      "epoch": 18.47466,
      "batchsize": 33.76994,
      "optimizer": 0.64219,
      "acc": 0.8552777777777778,
      "loss": 0.4140193997312475
    },
    "10": {
      "name": 10,
      "learningrate": 0.03168,
      "dropout": 0.14924,
      "epoch": 19.92391,
      "batchsize": 39.02217,
      "optimizer": 0.92721,
      "acc": 0.8548703703703704,
      "loss": 0.41223810244931114
    },
    "11": {
      "name": 11,
      "learningrate": 0.03829,
      "dropout": 0.1373,
      "epoch": 10.30644,
      "batchsize": 29.12989,
      "optimizer": 0.82946,
      "acc": 0.8536111111111111,
      "loss": 0.4152571103572845
    },
    "12": {
      "name": 12,
      "learningrate": 0.01215,
      "dropout": 0.2591,
      "epoch": 15.59188,
      "batchsize": 20.14417,
      "optimizer": 0.86244,
      "acc": 0.8532777777777778,
      "loss": 0.4193084820685563
    },
    "13": {
      "name": 13,
      "learningrate": 0.0117,
      "dropout": 0.17923,
      "epoch": 22.05135,
      "batchsize": 45.37699,
      "optimizer": 1.21205,
      "acc": 0.8532592592592593,
      "loss": 0.41917134924729665
    },
    "14": {
      "name": 14,
      "learningrate": 0.01293,
      "dropout": 0.22687,
      "epoch": 15.92343,
      "batchsize": 36.09833,
      "optimizer": 0.75024,
      "acc": 0.8502777777777778,
      "loss": 0.42306632343486505
    },
    "15": {
      "name": 15,
      "learningrate": 0.04189,
      "dropout": 0.14541,
      "epoch": 13.00849,
      "batchsize": 34.95561,
      "optimizer": 0.9087,
      "acc": 0.8501296296296297,
      "loss": 0.4252360969207905
    },
    "16": {
      "name": 16,
      "learningrate": 0.02785,
      "dropout": 0.40743,
      "epoch": 17.75763,
      "batchsize": 19.10473,
      "optimizer": 0.97684,
      "acc": 0.8481666666666666,
      "loss": 0.4161177899969949
    },
    "17": {
      "name": 17,
      "learningrate": 0.0178,
      "dropout": 0.40663,
      "epoch": 18.16921,
      "batchsize": 50.66005,
      "optimizer": 0.94472,
      "acc": 0.846462962962963,
      "loss": 0.4327043782119398
    },
    "18": {
      "name": 18,
      "learningrate": 0.039370285160405034,
      "dropout": 0.31639591270682005,
      "epoch": 7.035714998092013,
      "batchsize": 60.30646671090542,
      "optimizer": 1.3574326117378532,
      "acc": 0.8359444444444445,
      "loss": 0.46089720561327757
    },
    "19": {
      "name": 19,
      "learningrate": 0.02345,
      "dropout": 0.20613,
      "epoch": 19.70027,
      "batchsize": 27.63464,
      "optimizer": 1.56982,
      "acc": 0.7786666666666666,
      "loss": 1.0134163911960743
    },
    "20": {
      "name": 20,
      "learningrate": 0.04822253983355106,
      "dropout": 0.2669235758585038,
      "epoch": 5.115776984853211,
      "batchsize": 38.25212845447513,
      "optimizer": 0.24632468270637964,
      "acc": 0.24881481481481482,
      "loss": 12.104466120402018
    }
  },
  "Winner": {
    "0": {
      "name": 0,
      "learningrate": 0.02423,
      "dropout": 0.16393,
      "epoch": 32.5335,
      "batchsize": 16.37246,
      "optimizer": 0.82815,
      "acc": 0.8628703703703704,
      "loss": 0.40689319107929867
    },
    "1": {
      "name": 1,
      "learningrate": 0.0296,
      "dropout": 0.16672,
      "epoch": 28.24371,
      "batchsize": 37.77119,
      "optimizer": 0.90086,
      "acc": 0.8615,
      "loss": 0.40653153143767956
    },
    "2": {
      "name": 2,
      "learningrate": 0.03931,
      "dropout": 0.13942,
      "epoch": 23.46509,
      "batchsize": 17.59404,
      "optimizer": 0.85684,
      "acc": 0.8608703703703704,
      "loss": 0.4100546259526853
    },
    "3": {
      "name": 3,
      "learningrate": 0.03246,
      "dropout": 0.14669,
      "epoch": 23.66486,
      "batchsize": 13.59675,
      "optimizer": 0.66765,
      "acc": 0.8605,
      "loss": 0.4035028734449987
    },
    "4": {
      "name": 4,
      "learningrate": 0.03688,
      "dropout": 0.11446,
      "epoch": 20.88849,
      "batchsize": 22.00801,
      "optimizer": 0.88767,
      "acc": 0.8596111111111111,
      "loss": 0.4049010883702172
    },
    "5": {
      "name": 5,
      "learningrate": 0.02036,
      "dropout": 0.15072,
      "epoch": 24.96494,
      "batchsize": 15.59327,
      "optimizer": 1.03687,
      "acc": 0.857925925925926,
      "loss": 0.4063035917414559
    },
    "6": {
      "name": 6,
      "learningrate": 0.02766,
      "dropout": 0.2055,
      "epoch": 23.65594,
      "batchsize": 46.15916,
      "optimizer": 0.70498,
      "acc": 0.8577037037037037,
      "loss": 0.41208158073601897
    },
    "7": {
      "name": 7,
      "learningrate": 0.02506,
      "dropout": 0.31366,
      "epoch": 32.03083,
      "batchsize": 60.60375,
      "optimizer": 0.70486,
      "acc": 0.8563518518518518,
      "loss": 0.4064851947713781
    },
    "8": {
      "name": 8,
      "learningrate": 0.03625,
      "dropout": 0.23118,
      "epoch": 29.54164,
      "batchsize": 47.73096,
      "optimizer": 1.16496,
      "acc": 0.854462962962963,
      "loss": 0.4254589164654414
    },
    "9": {
      "name": 9,
      "learningrate": 0.03069,
      "dropout": 0.12009,
      "epoch": 33.5566,
      "batchsize": 38.93392,
      "optimizer": 0.72662,
      "acc": 0.8533888888888889,
      "loss": 0.43634968513912625
    },
    "10": {
      "name": 10,
      "learningrate": 0.02036,
      "dropout": 0.26122,
      "epoch": 18.1016,
      "batchsize": 22.58996,
      "optimizer": 1.33419,
      "acc": 0.8518148148148148,
      "loss": 0.41347636569870844
    },
    "11": {
      "name": 11,
      "learningrate": 0.06778,
      "dropout": 0.13084,
      "epoch": 28.24722,
      "batchsize": 32.21101,
      "optimizer": 0.69988,
      "acc": 0.8503703703703703,
      "loss": 0.44834874736379693
    },
    "12": {
      "name": 12,
      "learningrate": 0.02546,
      "dropout": 0.26722,
      "epoch": 11.89297,
      "batchsize": 63.27952,
      "optimizer": 1.28823,
      "acc": 0.8501851851851852,
      "loss": 0.4262821846670575
    },
    "13": {
      "name": 13,
      "learningrate": 0.03892,
      "dropout": 0.12205,
      "epoch": 22.51235,
      "batchsize": 35.8539,
      "optimizer": 0.60509,
      "acc": 0.8496666666666667,
      "loss": 0.4358291453630836
    },
    "14": {
      "name": 14,
      "learningrate": 0.06268,
      "dropout": 0.18283,
      "epoch": 18.85413,
      "batchsize": 21.56685,
      "optimizer": 0.60642,
      "acc": 0.8493333333333334,
      "loss": 0.43711782733599347
    },
    "15": {
      "name": 15,
      "learningrate": 0.06954946720819427,
      "dropout": 0.11280460097325219,
      "epoch": 6.100988628397415,
      "batchsize": 52.14896848846779,
      "optimizer": 1.209341127402701,
      "acc": 0.8301481481481482,
      "loss": 0.4772349348288995
    },
    "16": {
      "name": 16,
      "learningrate": 0.004391053685108383,
      "dropout": 0.2617928575483355,
      "epoch": 5.680206210088571,
      "batchsize": 60.12498476951278,
      "optimizer": 0.115830504121053,
      "acc": 0.8132777777777778,
      "loss": 0.5031456237148355
    },
    "17": {
      "name": 17,
      "learningrate": 0.02296,
      "dropout": 0.18445,
      "epoch": 19.95398,
      "batchsize": 34.46327,
      "optimizer": 0.46886,
      "acc": 0.7899259259259259,
      "loss": 0.6454300785241304
    },
    "18": {
      "name": 18,
      "learningrate": 0.02616,
      "dropout": 0.09028,
      "epoch": 26.0229,
      "batchsize": 37.03733,
      "optimizer": 0.47688,
      "acc": 0.7641481481481481,
      "loss": 0.720794885582394
    },
    "19": {
      "name": 19,
      "learningrate": 0.02516,
      "dropout": 0.22852,
      "epoch": 22.99076,
      "batchsize": 18.92335,
      "optimizer": 0.47889,
      "acc": 0.6737777777777778,
      "loss": 0.9311023736176668
    },
    "20": {
      "name": 20,
      "learningrate": 0.02788,
      "dropout": 0.09631,
      "epoch": 30.51471,
      "batchsize": 29.33714,
      "optimizer": 1.63316,
      "acc": 0.1002962962962963,
      "loss": 14.501509959468136
    }
  }
}