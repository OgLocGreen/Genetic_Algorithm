{
  "0": {
    "0": {
      "name": 0,
      "learningrate": "0.0326049585959973",
      "dropout": "0.15390309673687497",
      "epoch": "69.66476852841275",
      "batchsize": "38.95135584396287",
      "optimizer": "3.2418925690084515",
      "acc": "0.9001",
      "loss": "0.3469450497791171"
    },
    "1": {
      "name": 1,
      "learningrate": "0.07069363316271536",
      "dropout": "0.18338374776290428",
      "epoch": "90.8399634945794",
      "batchsize": "38.419237494891625",
      "optimizer": "2.5576655919356166",
      "acc": "0.8992",
      "loss": "0.346870858861506"
    },
    "2": {
      "name": 2,
      "learningrate": "0.050036013106287545",
      "dropout": "0.11645735399315217",
      "epoch": "84.01091116434188",
      "batchsize": "32.44530905903166",
      "optimizer": "0.7843911016423073",
      "acc": "0.8981",
      "loss": "0.3788118028700352"
    },
    "3": {
      "name": 3,
      "learningrate": "0.02977651021027728",
      "dropout": "0.14250937691408483",
      "epoch": "64.86849001473645",
      "batchsize": "48.65014125191018",
      "optimizer": "2.927636086551159",
      "acc": "0.8971",
      "loss": "0.3341471383973956"
    },
    "4": {
      "name": 4,
      "learningrate": "0.09508091873649799",
      "dropout": "0.14674383322967172",
      "epoch": "83.7961741095953",
      "batchsize": "33.26953809285055",
      "optimizer": "2.994373468364045",
      "acc": "0.8966",
      "loss": "0.36486956303715706"
    },
    "5": {
      "name": 5,
      "learningrate": "0.07249715280712576",
      "dropout": "0.08151391142354555",
      "epoch": "71.47850924618453",
      "batchsize": "60.62895417739132",
      "optimizer": "3.485189586764998",
      "acc": "0.8965",
      "loss": "0.37891443068534136"
    },
    "6": {
      "name": 6,
      "learningrate": "0.09893079685662283",
      "dropout": "0.12390436320243298",
      "epoch": "78.7462710606174",
      "batchsize": "62.47896423813822",
      "optimizer": "2.8162364480632087",
      "acc": "0.8961",
      "loss": "0.35685350378230213"
    },
    "7": {
      "name": 7,
      "learningrate": "0.06675120889284046",
      "dropout": "0.1961154138914229",
      "epoch": "53.54871884391977",
      "batchsize": "55.45688150626188",
      "optimizer": "3.4582689453637845",
      "acc": "0.8955",
      "loss": "0.3211355762898922"
    },
    "8": {
      "name": 8,
      "learningrate": "0.024912418294201953",
      "dropout": "0.11259828115274625",
      "epoch": "97.00496632995531",
      "batchsize": "63.997231162873376",
      "optimizer": "3.3006666514151815",
      "acc": "0.8944",
      "loss": "0.37757554006278515"
    },
    "9": {
      "name": 9,
      "learningrate": "0.02871621882233047",
      "dropout": "0.17104133499730376",
      "epoch": "89.5153978657542",
      "batchsize": "56.586397717947946",
      "optimizer": "0.566141185222834",
      "acc": "0.894",
      "loss": "0.32725100180506705"
    },
    "10": {
      "name": 10,
      "learningrate": "0.032692259893182855",
      "dropout": "0.17570033647997613",
      "epoch": "65.45088058053373",
      "batchsize": "42.75607072275574",
      "optimizer": "1.3060113351981002",
      "acc": "0.8938",
      "loss": "0.3247259568795562"
    },
    "11": {
      "name": 11,
      "learningrate": "0.0812473150454882",
      "dropout": "0.22799369215812337",
      "epoch": "60.939976361390336",
      "batchsize": "57.130673265379706",
      "optimizer": "1.488428519326097",
      "acc": "0.8933",
      "loss": "0.31795816538333893"
    },
    "12": {
      "name": 12,
      "learningrate": "0.06812428290979596",
      "dropout": "0.19111913702320849",
      "epoch": "69.21827735690714",
      "batchsize": "59.64801658531259",
      "optimizer": "1.4329140807627292",
      "acc": "0.8932",
      "loss": "0.32259524864256384"
    },
    "13": {
      "name": 13,
      "learningrate": "0.07309232202355796",
      "dropout": "0.2639511632470731",
      "epoch": "83.20154660987463",
      "batchsize": "62.58446929642595",
      "optimizer": "2.770217063011011",
      "acc": "0.8931",
      "loss": "0.32720738086104395"
    },
    "14": {
      "name": 14,
      "learningrate": "0.041964846665560954",
      "dropout": "0.31381165511710774",
      "epoch": "68.5729779020112",
      "batchsize": "32.524512406455756",
      "optimizer": "2.8495549984729798",
      "acc": "0.8929",
      "loss": "0.32396042739748954"
    },
    "15": {
      "name": 15,
      "learningrate": "0.03743501927583888",
      "dropout": "0.3039865771673058",
      "epoch": "88.55020743517909",
      "batchsize": "49.05477377759429",
      "optimizer": "2.5667800359293897",
      "acc": "0.8925",
      "loss": "0.3261112149834633"
    },
    "16": {
      "name": 16,
      "learningrate": "0.03351389869437422",
      "dropout": "0.24763220474720998",
      "epoch": "70.52345479692016",
      "batchsize": "41.27406922955197",
      "optimizer": "0.7136675331266358",
      "acc": "0.8923",
      "loss": "0.31671321984529494"
    },
    "17": {
      "name": 17,
      "learningrate": "0.08880890787754876",
      "dropout": "0.32452025627683767",
      "epoch": "73.82709745884131",
      "batchsize": "38.13337873441125",
      "optimizer": "0.7686399200483991",
      "acc": "0.889",
      "loss": "0.3277552390038967"
    },
    "18": {
      "name": 18,
      "learningrate": "0.05155336899228769",
      "dropout": "0.09877813973718988",
      "epoch": "69.08270387261362",
      "batchsize": "49.048449734013246",
      "optimizer": "0.6546420258607353",
      "acc": "0.8886",
      "loss": "0.37051299231648444"
    },
    "19": {
      "name": 19,
      "learningrate": "0.022176710808436053",
      "dropout": "0.19018789389665552",
      "epoch": "51.00891990952224",
      "batchsize": "47.52759550736023",
      "optimizer": "0.5813710613634138",
      "acc": "0.8884",
      "loss": "0.3257643321752548"
    },
    "20": {
      "name": 20,
      "learningrate": "0.010153710020699988",
      "dropout": "0.11123842025737316",
      "epoch": "67.72975048842102",
      "batchsize": "59.127005456533816",
      "optimizer": "1.4548515899126917",
      "acc": "0.8883",
      "loss": "0.31959426827430726"
    },
    "21": {
      "name": 21,
      "learningrate": "0.0800595332840368",
      "dropout": "0.2004770432318813",
      "epoch": "51.434025450936346",
      "batchsize": "34.78832694112648",
      "optimizer": "1.2907203101867681",
      "acc": "0.888",
      "loss": "0.3213641731083393"
    },
    "22": {
      "name": 22,
      "learningrate": "0.06633909909397205",
      "dropout": "0.31817721839628077",
      "epoch": "67.8935224577289",
      "batchsize": "39.24178869147207",
      "optimizer": "1.1022962851312972",
      "acc": "0.8876",
      "loss": "0.3293027591228485"
    },
    "23": {
      "name": 23,
      "learningrate": "0.04317923805555852",
      "dropout": "0.20658296910850382",
      "epoch": "68.27616959662915",
      "batchsize": "33.266519002757036",
      "optimizer": "1.3162327891024659",
      "acc": "0.8875",
      "loss": "0.33910717113018035"
    },
    "24": {
      "name": 24,
      "learningrate": "0.08138772218533898",
      "dropout": "0.37545145927295553",
      "epoch": "73.19374843792845",
      "batchsize": "57.06879684222627",
      "optimizer": "3.0712562191122186",
      "acc": "0.8868",
      "loss": "0.3268063167333603"
    },
    "25": {
      "name": 25,
      "learningrate": "0.048825690530269666",
      "dropout": "0.32838373882034966",
      "epoch": "94.34775598585898",
      "batchsize": "47.41293585465996",
      "optimizer": "1.2346598984287982",
      "acc": "0.8868",
      "loss": "0.32643949564695357"
    },
    "26": {
      "name": 26,
      "learningrate": "0.0990209602677055",
      "dropout": "0.41546143634088867",
      "epoch": "98.75749723191097",
      "batchsize": "35.12377246307055",
      "optimizer": "0.8001450633670117",
      "acc": "0.8861",
      "loss": "0.3360849969625473"
    },
    "27": {
      "name": 27,
      "learningrate": "0.0043835269305566435",
      "dropout": "0.3053864343896438",
      "epoch": "98.96459777092686",
      "batchsize": "45.130341530249794",
      "optimizer": "0.7422752916957736",
      "acc": "0.8858",
      "loss": "0.33079707844257356"
    },
    "28": {
      "name": 28,
      "learningrate": "0.046596698019145344",
      "dropout": "0.47832313162981127",
      "epoch": "69.1503878769215",
      "batchsize": "63.92176775292613",
      "optimizer": "2.5526704175688026",
      "acc": "0.8848",
      "loss": "0.33381157064437866"
    },
    "29": {
      "name": 29,
      "learningrate": "0.042126630622736604",
      "dropout": "0.37232391373516704",
      "epoch": "51.4272047430306",
      "batchsize": "37.64000196502431",
      "optimizer": "1.4206208976132868",
      "acc": "0.8842",
      "loss": "0.3281648687362671"
    },
    "30": {
      "name": 30,
      "learningrate": "0.06381019485984903",
      "dropout": "0.43172766647623584",
      "epoch": "70.73492750711192",
      "batchsize": "50.60441902113932",
      "optimizer": "2.541882639255995",
      "acc": "0.8837",
      "loss": "0.3304464704632759"
    },
    "31": {
      "name": 31,
      "learningrate": "0.06956941637524042",
      "dropout": "0.4138254671461622",
      "epoch": "52.134580687116376",
      "batchsize": "62.73355413797757",
      "optimizer": "1.4346873930228377",
      "acc": "0.8827",
      "loss": "0.3327108326435089"
    },
    "32": {
      "name": 32,
      "learningrate": "0.022625498094600724",
      "dropout": "0.41588556985537223",
      "epoch": "84.07965015427564",
      "batchsize": "59.498248696740816",
      "optimizer": "1.254324565015633",
      "acc": "0.8825",
      "loss": "0.33546306643486024"
    },
    "33": {
      "name": 33,
      "learningrate": "0.020898343574155064",
      "dropout": "0.48353802931968404",
      "epoch": "95.23823501042989",
      "batchsize": "32.167863178384835",
      "optimizer": "1.323290104885095",
      "acc": "0.882",
      "loss": "0.33906485929489133"
    },
    "34": {
      "name": 34,
      "learningrate": "0.06964911426588956",
      "dropout": "0.45394499461750043",
      "epoch": "66.6015515496672",
      "batchsize": "60.732632506937975",
      "optimizer": "3.4563009886248777",
      "acc": "0.8819",
      "loss": "0.3372989969730377"
    },
    "35": {
      "name": 35,
      "learningrate": "0.06987369358491646",
      "dropout": "0.49281284702793077",
      "epoch": "86.47094235585453",
      "batchsize": "38.18905185265494",
      "optimizer": "0.6062183882435752",
      "acc": "0.8812",
      "loss": "0.34050492022037504"
    },
    "36": {
      "name": 36,
      "learningrate": "0.08868364440734368",
      "dropout": "0.39963448647362615",
      "epoch": "55.749231376769025",
      "batchsize": "52.186422644326086",
      "optimizer": "2.944830417859748",
      "acc": "0.8802",
      "loss": "0.3364148402094841"
    },
    "37": {
      "name": 37,
      "learningrate": "0.004313625240040281",
      "dropout": "0.3719393718946199",
      "epoch": "99.61356466098024",
      "batchsize": "62.18458542466897",
      "optimizer": "2.6806160424000547",
      "acc": "0.8785",
      "loss": "0.34164932116270064"
    },
    "38": {
      "name": 38,
      "learningrate": "0.09935527373547808",
      "dropout": "0.4746183165482798",
      "epoch": "59.98645047785601",
      "batchsize": "50.05671933641211",
      "optimizer": "1.2243140784602429",
      "acc": "0.878",
      "loss": "0.3423453841328621"
    },
    "39": {
      "name": 39,
      "learningrate": "0.002731636437083135",
      "dropout": "0.26541484899644324",
      "epoch": "87.84998545369645",
      "batchsize": "57.17075977695896",
      "optimizer": "3.09178950101267",
      "acc": "0.8762",
      "loss": "0.34770922281742095"
    },
    "40": {
      "name": 40,
      "learningrate": "0.01131288914311035",
      "dropout": "0.49394241198616057",
      "epoch": "68.21079989654424",
      "batchsize": "61.08848784234073",
      "optimizer": "0.5934887965261706",
      "acc": "0.8708",
      "loss": "0.3592505979537964"
    },
    "41": {
      "name": 41,
      "learningrate": "0.0006096662340063159",
      "dropout": "0.2832923162391892",
      "epoch": "75.88856873572601",
      "batchsize": "52.33311101983398",
      "optimizer": "2.305277397070152",
      "acc": "0.8679",
      "loss": "0.7859219764232636"
    },
    "42": {
      "name": 42,
      "learningrate": "0.008788810514407693",
      "dropout": "0.1347604506001321",
      "epoch": "90.50467275524812",
      "batchsize": "55.70969419586863",
      "optimizer": "0.4250701170939739",
      "acc": "0.8331",
      "loss": "0.5252333569049835"
    },
    "43": {
      "name": 43,
      "learningrate": "0.0026271005470089835",
      "dropout": "0.4433091617778584",
      "epoch": "82.68614238786256",
      "batchsize": "36.11898650081044",
      "optimizer": "1.86625317243129",
      "acc": "0.7549",
      "loss": "1.9495699792861938"
    },
    "44": {
      "name": 44,
      "learningrate": "0.006660169591340071",
      "dropout": "0.2907261661058423",
      "epoch": "89.78889234542163",
      "batchsize": "54.536126069069596",
      "optimizer": "2.02096482612918",
      "acc": "0.7533",
      "loss": "1.6284166471481323"
    },
    "45": {
      "name": 45,
      "learningrate": "0.01527105914173682",
      "dropout": "0.1470157883432606",
      "epoch": "81.25496720278653",
      "batchsize": "35.75112739053455",
      "optimizer": "2.260911516227022",
      "acc": "0.6591",
      "loss": "1.6767871064186097"
    },
    "46": {
      "name": 46,
      "learningrate": "0.016323181800483866",
      "dropout": "0.05131718288172066",
      "epoch": "63.026620428389414",
      "batchsize": "40.47018004614616",
      "optimizer": "-0.13246324139118082",
      "acc": "0.6431",
      "loss": "0.8742099081993103"
    },
    "47": {
      "name": 47,
      "learningrate": "0.009983175386269472",
      "dropout": "0.328789127675314",
      "epoch": "83.1878452630248",
      "batchsize": "60.98892016755489",
      "optimizer": "1.686346526595317",
      "acc": "0.636",
      "loss": "2.1238719974040987"
    },
    "48": {
      "name": 48,
      "learningrate": "0.019229069597082295",
      "dropout": "0.11750878283747461",
      "epoch": "64.55665487512961",
      "batchsize": "56.54433963309103",
      "optimizer": "-0.12164097144561259",
      "acc": "0.6345",
      "loss": "1.1989766835212707"
    },
    "49": {
      "name": 49,
      "learningrate": "0.014118914173156683",
      "dropout": "0.28612382618503523",
      "epoch": "53.847650806184205",
      "batchsize": "46.41637942312343",
      "optimizer": "2.2386969586336125",
      "acc": "0.5627",
      "loss": "2.444553839588165"
    },
    "50": {
      "name": 50,
      "learningrate": "0.03496638653167291",
      "dropout": "0.29227825652604644",
      "epoch": "85.0027964555039",
      "batchsize": "59.19498853666636",
      "optimizer": "2.208944880454211",
      "acc": "0.3935",
      "loss": "1.6513329706192017"
    },
    "51": {
      "name": 51,
      "learningrate": "0.020122372129345718",
      "dropout": "0.46515276688387536",
      "epoch": "73.89635118609978",
      "batchsize": "50.14535707034311",
      "optimizer": "2.0437459660021573",
      "acc": "0.3773",
      "loss": "2.107763731956482"
    },
    "52": {
      "name": 52,
      "learningrate": "0.014178290042446369",
      "dropout": "0.3246453745911948",
      "epoch": "94.96151703713934",
      "batchsize": "46.808327665077584",
      "optimizer": "-0.01810808596775937",
      "acc": "0.3468",
      "loss": "1.6662516214370728"
    },
    "53": {
      "name": 53,
      "learningrate": "0.020360018844815926",
      "dropout": "0.20678381366856524",
      "epoch": "97.27608429663442",
      "batchsize": "55.44229195240747",
      "optimizer": "0.11173887074899858",
      "acc": "0.2909",
      "loss": "1.5271853240966797"
    },
    "54": {
      "name": 54,
      "learningrate": "0.05338981730670552",
      "dropout": "0.23616686886010574",
      "epoch": "73.07864713573764",
      "batchsize": "54.76320830214273",
      "optimizer": "2.0011340875799175",
      "acc": "0.2588",
      "loss": "2.446003846168518"
    },
    "55": {
      "name": 55,
      "learningrate": "0.037981382004957924",
      "dropout": "0.1489540000453708",
      "epoch": "55.048180496244846",
      "batchsize": "37.18596234783314",
      "optimizer": "1.651781668161691",
      "acc": "0.2533",
      "loss": "1.8975741109848023"
    },
    "56": {
      "name": 56,
      "learningrate": "0.026279029169164563",
      "dropout": "0.2621389173765983",
      "epoch": "91.6029517588577",
      "batchsize": "55.640994075436566",
      "optimizer": "2.30089089114175",
      "acc": "0.2442",
      "loss": "2.4067732097625734"
    },
    "57": {
      "name": 57,
      "learningrate": "0.0454155103490648",
      "dropout": "0.21731539970947966",
      "epoch": "86.4923982925427",
      "batchsize": "45.5188096103514",
      "optimizer": "1.7083979213819873",
      "acc": "0.2277",
      "loss": "2.035468568611145"
    },
    "58": {
      "name": 58,
      "learningrate": "0.023016386205936296",
      "dropout": "0.4572821366301813",
      "epoch": "79.71179002792292",
      "batchsize": "42.44174137976694",
      "optimizer": "0.2892369036285811",
      "acc": "0.1995",
      "loss": "1.7946038551330565"
    },
    "59": {
      "name": 59,
      "learningrate": "0.04570010456419359",
      "dropout": "0.38847601987611713",
      "epoch": "52.674024325243735",
      "batchsize": "38.11455403160724",
      "optimizer": "2.2172559414994297",
      "acc": "0.1724",
      "loss": "2.1343631916046144"
    },
    "60": {
      "name": 60,
      "learningrate": "0.08167521252140299",
      "dropout": "0.19751677565494663",
      "epoch": "79.18291302832624",
      "batchsize": "43.28344400604462",
      "optimizer": "1.9364415145249376",
      "acc": "0.1652",
      "loss": "2.6520312839508056"
    },
    "61": {
      "name": 61,
      "learningrate": "0.035034561460902135",
      "dropout": "0.36869396437500046",
      "epoch": "75.91305394444835",
      "batchsize": "51.404779298949926",
      "optimizer": "1.8000933016402496",
      "acc": "0.1613",
      "loss": "2.3743408864974977"
    },
    "62": {
      "name": 62,
      "learningrate": "0.07119017443321297",
      "dropout": "0.27564007147150554",
      "epoch": "84.54800481522938",
      "batchsize": "61.310305656558526",
      "optimizer": "1.9694757632113178",
      "acc": "0.1458",
      "loss": "2.2542174461364746"
    },
    "63": {
      "name": 63,
      "learningrate": "0.06636973837324898",
      "dropout": "0.3528768126196698",
      "epoch": "73.27712866509812",
      "batchsize": "58.37962157588878",
      "optimizer": "1.5976668168053605",
      "acc": "0.1361",
      "loss": "2.2311943199157716"
    },
    "64": {
      "name": 64,
      "learningrate": "0.0634735781329808",
      "dropout": "0.42668314140643626",
      "epoch": "72.61084228224621",
      "batchsize": "63.96670969916606",
      "optimizer": "1.5165956106052474",
      "acc": "0.1233",
      "loss": "2.317253694152832"
    },
    "65": {
      "name": 65,
      "learningrate": "0.07103979561992219",
      "dropout": "0.49223903380631806",
      "epoch": "87.63172852285946",
      "batchsize": "48.84795963500942",
      "optimizer": "2.1695518328342906",
      "acc": "0.1",
      "loss": "2.3058032936096193"
    },
    "66": {
      "name": 66,
      "learningrate": "0.07298743627715386",
      "dropout": "0.4057699766888132",
      "epoch": "75.21392048074735",
      "batchsize": "37.89513179765152",
      "optimizer": "2.1596773213091685",
      "acc": "0.1",
      "loss": "2.320299674606323"
    },
    "67": {
      "name": 67,
      "learningrate": "0.07840558580509513",
      "dropout": "0.06634733157841825",
      "epoch": "92.52031965833666",
      "batchsize": "36.006330294213484",
      "optimizer": "-0.4990502234477501",
      "acc": "0.1",
      "loss": "2.3114095737457276"
    },
    "68": {
      "name": 68,
      "learningrate": "0.08805103468173009",
      "dropout": "0.13582505478802753",
      "epoch": "58.47203359227051",
      "batchsize": "45.81784169827675",
      "optimizer": "2.3773301142099164",
      "acc": "0.1",
      "loss": "2.317371611022949"
    },
    "69": {
      "name": 69,
      "learningrate": "0.06896687693926962",
      "dropout": "0.45782268662769",
      "epoch": "62.58047573582772",
      "batchsize": "58.09674352486769",
      "optimizer": "1.5248519706189474",
      "acc": "0.1",
      "loss": "2.309768198013306"
    },
    "70": {
      "name": 70,
      "learningrate": "0.09583065635425686",
      "dropout": "0.21647934158024779",
      "epoch": "98.26039607167868",
      "batchsize": "35.917269905017854",
      "optimizer": "0.2447721273486807",
      "acc": "0.1",
      "loss": "2.307654188537598"
    },
    "71": {
      "name": 71,
      "learningrate": "0.08052298062638755",
      "dropout": "0.3062417668109786",
      "epoch": "89.35777537026647",
      "batchsize": "55.10577131290387",
      "optimizer": "0.004307774278535792",
      "acc": "0.1",
      "loss": "2.308850347518921"
    },
    "72": {
      "name": 72,
      "learningrate": "0.09474038867889456",
      "dropout": "0.38557168262812447",
      "epoch": "98.95299234785416",
      "batchsize": "52.709498119366955",
      "optimizer": "-0.27996599351976315",
      "acc": "0.1",
      "loss": "2.3118807655334472"
    },
    "73": {
      "name": 73,
      "learningrate": "0.08088914530633241",
      "dropout": "0.3560765635461571",
      "epoch": "76.14443171842629",
      "batchsize": "56.99235709880762",
      "optimizer": "-0.24311135259324868",
      "acc": "0.1",
      "loss": "2.325455791473389"
    },
    "74": {
      "name": 74,
      "learningrate": "0.08681023791600058",
      "dropout": "0.1259287291065472",
      "epoch": "94.22085011962432",
      "batchsize": "44.18500015224862",
      "optimizer": "-0.2795905581713898",
      "acc": "0.1",
      "loss": "2.3097529220581055"
    },
    "75": {
      "name": 75,
      "learningrate": "0.054892010268196276",
      "dropout": "0.27133352935956373",
      "epoch": "92.4172797836604",
      "batchsize": "48.78863150075692",
      "optimizer": "-0.2599395779606417",
      "acc": "0.1",
      "loss": "2.3092895156860354"
    },
    "76": {
      "name": 76,
      "learningrate": "0.09171069321888731",
      "dropout": "0.08445681993806606",
      "epoch": "67.54018873707363",
      "batchsize": "61.63846932626489",
      "optimizer": "-0.36014388337497705",
      "acc": "0.1",
      "loss": "2.310109999847412"
    },
    "77": {
      "name": 77,
      "learningrate": "0.08921126255976523",
      "dropout": "0.0855837285709857",
      "epoch": "76.09121015162496",
      "batchsize": "50.63091064362275",
      "optimizer": "-0.1674637328637485",
      "acc": "0.1",
      "loss": "2.308726505661011"
    },
    "78": {
      "name": 78,
      "learningrate": "0.09448556408785452",
      "dropout": "0.366230549519976",
      "epoch": "52.48412353868291",
      "batchsize": "38.641606971062714",
      "optimizer": "0.0918127207621171",
      "acc": "0.1",
      "loss": "2.310788611602783"
    },
    "79": {
      "name": 79,
      "learningrate": "0.09235115085664732",
      "dropout": "0.42412147807963196",
      "epoch": "59.29024107942915",
      "batchsize": "33.12785964665245",
      "optimizer": "0.1890256960670973",
      "acc": "0.1",
      "loss": "2.3202739875793457"
    },
    "80": {
      "name": 80,
      "learningrate": "0.08878387165701192",
      "dropout": "0.3432287578712524",
      "epoch": "55.51320723048938",
      "batchsize": "43.527007324768306",
      "optimizer": "1.7215579284102267",
      "acc": "0.1",
      "loss": "2.3127624969482423"
    },
    "81": {
      "name": 81,
      "learningrate": "0.08288294947358525",
      "dropout": "0.12652701991748277",
      "epoch": "57.466850890547754",
      "batchsize": "57.65010755211972",
      "optimizer": "2.434624559678483",
      "acc": "0.1",
      "loss": "2.31408638381958"
    },
    "82": {
      "name": 82,
      "learningrate": "0.05098664323981596",
      "dropout": "0.49166326928425097",
      "epoch": "99.29684565959239",
      "batchsize": "41.86201599499479",
      "optimizer": "1.8881840155254026",
      "acc": "0.1",
      "loss": "2.311367557144165"
    },
    "83": {
      "name": 83,
      "learningrate": "0.09076669670577169",
      "dropout": "0.3218689248370293",
      "epoch": "63.44446986291734",
      "batchsize": "51.96751932520547",
      "optimizer": "2.241171798469699",
      "acc": "0.1",
      "loss": "2.310371725845337"
    },
    "84": {
      "name": 84,
      "learningrate": "0.09920928361468205",
      "dropout": "0.05385023558665743",
      "epoch": "77.71329334263426",
      "batchsize": "55.834774203949586",
      "optimizer": "0.21518912858169648",
      "acc": "0.1",
      "loss": "2.3135184158325197"
    },
    "85": {
      "name": 85,
      "learningrate": "0.08650393456939666",
      "dropout": "0.31343979489240864",
      "epoch": "51.202417800267355",
      "batchsize": "43.83999760766159",
      "optimizer": "0.2730537162669653",
      "acc": "0.1",
      "loss": "2.309070405960083"
    },
    "86": {
      "name": 86,
      "learningrate": "0.04993412427124511",
      "dropout": "0.3899723631490509",
      "epoch": "61.70702375149667",
      "batchsize": "60.148898093378776",
      "optimizer": "-0.10231688522718452",
      "acc": "0.1",
      "loss": "2.3043868419647215"
    },
    "87": {
      "name": 87,
      "learningrate": "0.05388292672692126",
      "dropout": "0.08180848634590229",
      "epoch": "95.99294919998701",
      "batchsize": "60.441977089293744",
      "optimizer": "2.0192928233592875",
      "acc": "0.1",
      "loss": "2.3060251262664795"
    },
    "88": {
      "name": 88,
      "learningrate": "0.05519279601980338",
      "dropout": "0.05104297998919793",
      "epoch": "95.18477629027839",
      "batchsize": "59.99705364473364",
      "optimizer": "1.9457439295902428",
      "acc": "0.1",
      "loss": "2.3090470703125"
    },
    "89": {
      "name": 89,
      "learningrate": "0.032071536686010337",
      "dropout": "0.4208303766702776",
      "epoch": "75.51253358674218",
      "batchsize": "32.814347564113675",
      "optimizer": "0.27438145218406884",
      "acc": "0.1",
      "loss": "2.3063573341369628"
    },
    "90": {
      "name": 90,
      "learningrate": "0.07996460937831029",
      "dropout": "0.47634871243945304",
      "epoch": "92.69954764688214",
      "batchsize": "33.09488189323096",
      "optimizer": "1.7441069692879214",
      "acc": "0.1",
      "loss": "2.321038579940796"
    },
    "91": {
      "name": 91,
      "learningrate": "0.07278759128665632",
      "dropout": "0.0670322728968452",
      "epoch": "52.085851188892384",
      "batchsize": "40.44456010022428",
      "optimizer": "1.8962851270295564",
      "acc": "0.1",
      "loss": "2.3051615768432616"
    },
    "92": {
      "name": 92,
      "learningrate": "0.0760206860897514",
      "dropout": "0.38478954730968773",
      "epoch": "64.82400062684484",
      "batchsize": "43.51711229607795",
      "optimizer": "2.0878264120159202",
      "acc": "0.1",
      "loss": "2.312735136795044"
    },
    "93": {
      "name": 93,
      "learningrate": "0.09590366300222737",
      "dropout": "0.11679973575352727",
      "epoch": "90.61406987573",
      "batchsize": "59.07510822441673",
      "optimizer": "-0.13384981530475404",
      "acc": "0.1",
      "loss": "2.3166458400726317"
    },
    "94": {
      "name": 94,
      "learningrate": "0.052120110275036775",
      "dropout": "0.3951589218953832",
      "epoch": "76.66674196216054",
      "batchsize": "47.62717163928076",
      "optimizer": "-0.14321815653846892",
      "acc": "0.1",
      "loss": "2.3071338401794432"
    },
    "95": {
      "name": 95,
      "learningrate": "0.049379927714992715",
      "dropout": "0.22823085796095904",
      "epoch": "84.22105401209834",
      "batchsize": "41.32720012912854",
      "optimizer": "0.30561411527129145",
      "acc": "0.1",
      "loss": "2.309408792877197"
    },
    "96": {
      "name": 96,
      "learningrate": "0.038335193005542216",
      "dropout": "0.2806302934327515",
      "epoch": "50.65006117452239",
      "batchsize": "47.33392166634414",
      "optimizer": "0.35715257388226895",
      "acc": "0.1",
      "loss": "2.308560799407959"
    },
    "97": {
      "name": 97,
      "learningrate": "0.06923322251083706",
      "dropout": "0.40890920625768357",
      "epoch": "63.899104304187894",
      "batchsize": "43.0823843700978",
      "optimizer": "-0.010046396896117304",
      "acc": "0.1",
      "loss": "2.3180462684631347"
    },
    "98": {
      "name": 98,
      "learningrate": "0.07123921393482192",
      "dropout": "0.20225004448299322",
      "epoch": "52.24259389471035",
      "batchsize": "52.06798099336566",
      "optimizer": "0.3186555965827189",
      "acc": "0.1",
      "loss": "2.317653454589844"
    },
    "99": {
      "name": 99,
      "learningrate": "0.07827164832208068",
      "dropout": "0.18220562668939316",
      "epoch": "82.32193116022704",
      "batchsize": "57.07131299263838",
      "optimizer": "-0.22264202567353975",
      "acc": "0.1",
      "loss": "2.3082010982513426"
    }
  }
}