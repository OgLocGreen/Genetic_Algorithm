{
  "0": {
    "0": {
      "name": 0,
      "learningrate": "0.0010028966533476473",
      "dropout": "0.3978768375194203",
      "epoch": "91.84221444671235",
      "batchsize": "50.772766415697504",
      "optimizer": "2.3753412429594114",
      "acc": "0.86112964",
      "loss": "0.6986242920005763"
    },
    "1": {
      "name": 1,
      "learningrate": "0.0022139519802706347",
      "dropout": "0.21602953736066427",
      "epoch": "62.14656346822772",
      "batchsize": "44.00841172166101",
      "optimizer": "0.3372878726115903",
      "acc": "0.8560926",
      "loss": "0.5926740684884566"
    },
    "2": {
      "name": 2,
      "learningrate": "0.009847808716690646",
      "dropout": "0.08396640533930702",
      "epoch": "99.40649531039051",
      "batchsize": "63.41112014670954",
      "optimizer": "0.7353295312382218",
      "acc": "0.8557963",
      "loss": "0.41815521346639706"
    },
    "3": {
      "name": 3,
      "learningrate": "0.001324103733539666",
      "dropout": "0.47465855051945555",
      "epoch": "70.04128080288987",
      "batchsize": "38.980090504061266",
      "optimizer": "1.8567839720611183",
      "acc": "0.8556296",
      "loss": "0.7108356204430262"
    },
    "4": {
      "name": 4,
      "learningrate": "0.0022340512912619095",
      "dropout": "0.14541882868486938",
      "epoch": "99.84686061002455",
      "batchsize": "34.99712573159515",
      "optimizer": "0.10830195998289072",
      "acc": "0.85555553",
      "loss": "0.9110089551210403"
    },
    "5": {
      "name": 5,
      "learningrate": "0.008019308145823092",
      "dropout": "0.22573363665404678",
      "epoch": "71.67575817108822",
      "batchsize": "37.84827113271897",
      "optimizer": "0.7855750593595962",
      "acc": "0.8546482",
      "loss": "0.4121833632544235"
    },
    "6": {
      "name": 6,
      "learningrate": "0.007939771860565293",
      "dropout": "0.22027126297744487",
      "epoch": "68.96956120614698",
      "batchsize": "39.31224016290818",
      "optimizer": "1.1970382753966449",
      "acc": "0.85444444",
      "loss": "0.41826331171283015"
    },
    "7": {
      "name": 7,
      "learningrate": "0.006790751132475762",
      "dropout": "0.11558628576926017",
      "epoch": "61.94641085877946",
      "batchsize": "52.06615915523791",
      "optimizer": "1.8417036698452804",
      "acc": "0.85411114",
      "loss": "1.2388906073073547"
    },
    "8": {
      "name": 8,
      "learningrate": "0.0027345958984198544",
      "dropout": "0.4533186263433023",
      "epoch": "96.47086140326701",
      "batchsize": "32.891450300299105",
      "optimizer": "0.33162256377926247",
      "acc": "0.85381484",
      "loss": "0.6300118147598373"
    },
    "9": {
      "name": 9,
      "learningrate": "0.004621609747537827",
      "dropout": "0.26631048507882815",
      "epoch": "84.33330792361909",
      "batchsize": "52.776866068924534",
      "optimizer": "1.867328728845366",
      "acc": "0.8537222",
      "loss": "1.2603173239978926"
    },
    "10": {
      "name": 10,
      "learningrate": "0.008195944122224684",
      "dropout": "0.07038664611025547",
      "epoch": "66.63159669944889",
      "batchsize": "34.699937537183686",
      "optimizer": "1.3074139594430023",
      "acc": "0.8537222",
      "loss": "0.422703782554026"
    },
    "11": {
      "name": 11,
      "learningrate": "0.006164316034418091",
      "dropout": "0.22660441675017684",
      "epoch": "73.79324239160536",
      "batchsize": "38.50090888061807",
      "optimizer": "0.7738671696715875",
      "acc": "0.8523704",
      "loss": "0.42586306412131697"
    },
    "12": {
      "name": 12,
      "learningrate": "0.005961751376968621",
      "dropout": "0.29808399592442997",
      "epoch": "89.11059349960723",
      "batchsize": "48.99118879456555",
      "optimizer": "1.0455465947761273",
      "acc": "0.8522222",
      "loss": "0.4250220113727782"
    },
    "13": {
      "name": 13,
      "learningrate": "0.004301287881400574",
      "dropout": "0.40446149748685734",
      "epoch": "93.21939503501281",
      "batchsize": "35.172102425181365",
      "optimizer": "2.4732187965468513",
      "acc": "0.8517037",
      "loss": "1.3631967811347159"
    },
    "14": {
      "name": 14,
      "learningrate": "0.007627897485265874",
      "dropout": "0.15760773344956985",
      "epoch": "55.208745646827936",
      "batchsize": "47.88278311067364",
      "optimizer": "1.0322244350535275",
      "acc": "0.8507778",
      "loss": "0.4326438532272975"
    },
    "15": {
      "name": 15,
      "learningrate": "0.006188926585788354",
      "dropout": "0.07122275956502792",
      "epoch": "70.4867232629162",
      "batchsize": "47.080596590489336",
      "optimizer": "0.6191524157633185",
      "acc": "0.84918517",
      "loss": "0.43498222542692117"
    },
    "16": {
      "name": 16,
      "learningrate": "0.005374698098294002",
      "dropout": "0.19929078540103862",
      "epoch": "51.55640085333607",
      "batchsize": "32.36927052034761",
      "optimizer": "0.7376600348495354",
      "acc": "0.8475185",
      "loss": "0.4410692730568073"
    },
    "17": {
      "name": 17,
      "learningrate": "0.0071371434412964094",
      "dropout": "0.1062741165564534",
      "epoch": "59.05681298441008",
      "batchsize": "56.791303443193655",
      "optimizer": "1.5173846671123472",
      "acc": "0.8473333",
      "loss": "1.1760402615092418"
    },
    "18": {
      "name": 18,
      "learningrate": "0.005564701846638688",
      "dropout": "0.07543251686872102",
      "epoch": "80.24643727822928",
      "batchsize": "62.86363431008227",
      "optimizer": "0.6327770420280617",
      "acc": "0.8471481",
      "loss": "0.443139809595214"
    },
    "19": {
      "name": 19,
      "learningrate": "0.007517793361959922",
      "dropout": "0.25339989203141083",
      "epoch": "53.64165442318952",
      "batchsize": "60.71749621517103",
      "optimizer": "2.0063664452362504",
      "acc": "0.8465",
      "loss": "0.9437272319269401"
    },
    "20": {
      "name": 20,
      "learningrate": "0.0055496706816268535",
      "dropout": "0.25063275437932675",
      "epoch": "58.60638150236738",
      "batchsize": "56.878078619733884",
      "optimizer": "0.4119258850390981",
      "acc": "0.84533334",
      "loss": "0.6562541746000449"
    },
    "21": {
      "name": 21,
      "learningrate": "0.008886740487123328",
      "dropout": "0.08819658668408745",
      "epoch": "81.3117084404278",
      "batchsize": "49.03118530322483",
      "optimizer": "2.6367189467466265",
      "acc": "0.8450185",
      "loss": "0.44589312540160286"
    },
    "22": {
      "name": 22,
      "learningrate": "0.0044418297284499544",
      "dropout": "0.26977232734996454",
      "epoch": "81.7288310025676",
      "batchsize": "56.2305211047466",
      "optimizer": "0.7638883807795617",
      "acc": "0.8449815",
      "loss": "0.4522144832743539"
    },
    "23": {
      "name": 23,
      "learningrate": "0.0029067429756522343",
      "dropout": "0.2692413219982034",
      "epoch": "96.58598612940315",
      "batchsize": "53.28640105977682",
      "optimizer": "1.6505783541796286",
      "acc": "0.84481484",
      "loss": "1.1344832064694277"
    },
    "24": {
      "name": 24,
      "learningrate": "0.002918590111661827",
      "dropout": "0.09132886867107334",
      "epoch": "51.95317871017474",
      "batchsize": "51.13465284236079",
      "optimizer": "2.1183454612490986",
      "acc": "0.8440741",
      "loss": "0.9064884599215455"
    },
    "25": {
      "name": 25,
      "learningrate": "0.002613638375299414",
      "dropout": "0.1647451448863228",
      "epoch": "89.28552613891057",
      "batchsize": "38.04097283607702",
      "optimizer": "1.5751904226578821",
      "acc": "0.8440741",
      "loss": "1.5091648513098006"
    },
    "26": {
      "name": 26,
      "learningrate": "0.005364698074880466",
      "dropout": "0.42612065643703795",
      "epoch": "71.12381993017834",
      "batchsize": "50.4570772019993",
      "optimizer": "0.7869285377443499",
      "acc": "0.8439815",
      "loss": "0.4471247765399792"
    },
    "27": {
      "name": 27,
      "learningrate": "0.008132273292119376",
      "dropout": "0.3933156915070915",
      "epoch": "95.29006723886816",
      "batchsize": "53.2650058473797",
      "optimizer": "0.01458967152298174",
      "acc": "0.84146297",
      "loss": "0.692879611339834"
    },
    "28": {
      "name": 28,
      "learningrate": "0.004671848816430157",
      "dropout": "0.4948991149510753",
      "epoch": "80.56564861055253",
      "batchsize": "32.56916112390685",
      "optimizer": "2.7506767287114924",
      "acc": "0.84040743",
      "loss": "0.4605886433036239"
    },
    "29": {
      "name": 29,
      "learningrate": "0.006299153730744507",
      "dropout": "0.06699965949781501",
      "epoch": "86.05067184185057",
      "batchsize": "37.64561210296543",
      "optimizer": "2.339868255257665",
      "acc": "0.84",
      "loss": "1.7961761190372485"
    },
    "30": {
      "name": 30,
      "learningrate": "0.00780125406089616",
      "dropout": "0.10693172255182115",
      "epoch": "73.05674397023088",
      "batchsize": "42.042404166738784",
      "optimizer": "2.396214026968271",
      "acc": "0.8399815",
      "loss": "1.5865502291719118"
    },
    "31": {
      "name": 31,
      "learningrate": "0.006572247917297092",
      "dropout": "0.3933842224078783",
      "epoch": "74.9130130579284",
      "batchsize": "44.11762320616642",
      "optimizer": "2.455904947285641",
      "acc": "0.8390926",
      "loss": "1.0885671842495601"
    },
    "32": {
      "name": 32,
      "learningrate": "0.003918321965328382",
      "dropout": "0.09936410408132737",
      "epoch": "67.65653216409825",
      "batchsize": "37.39301243056681",
      "optimizer": "0.289204617832337",
      "acc": "0.83903706",
      "loss": "0.9690228009731682"
    },
    "33": {
      "name": 33,
      "learningrate": "0.004919900112746168",
      "dropout": "0.49614708267573393",
      "epoch": "97.38529148485611",
      "batchsize": "45.00762627513407",
      "optimizer": "2.8933631275466754",
      "acc": "0.83853704",
      "loss": "0.4656910270055135"
    },
    "34": {
      "name": 34,
      "learningrate": "0.008384364340025697",
      "dropout": "0.4848395972597062",
      "epoch": "55.48030466268",
      "batchsize": "52.18298127853983",
      "optimizer": "2.8264451983800463",
      "acc": "0.83514816",
      "loss": "0.48062267595750313"
    },
    "35": {
      "name": 35,
      "learningrate": "0.005134285981396468",
      "dropout": "0.40615893023183897",
      "epoch": "90.61365454430299",
      "batchsize": "54.78959509383799",
      "optimizer": "2.7409987231362525",
      "acc": "0.83435184",
      "loss": "0.4834696040683322"
    },
    "36": {
      "name": 36,
      "learningrate": "0.0035101564201651713",
      "dropout": "0.0710353236393323",
      "epoch": "50.97147187914566",
      "batchsize": "58.175953909841574",
      "optimizer": "1.2001989451383275",
      "acc": "0.8315741",
      "loss": "0.4962945744108271"
    },
    "37": {
      "name": 37,
      "learningrate": "0.009330425129688746",
      "dropout": "0.4802177313461729",
      "epoch": "75.88910223141329",
      "batchsize": "59.82475361964881",
      "optimizer": "2.253136884280205",
      "acc": "0.83062965",
      "loss": "1.1812927925697079"
    },
    "38": {
      "name": 38,
      "learningrate": "0.008969668351556449",
      "dropout": "0.08628714772598846",
      "epoch": "67.40521353355709",
      "batchsize": "59.421732074724034",
      "optimizer": "2.4073524080234963",
      "acc": "0.8300741",
      "loss": "1.627603967341008"
    },
    "39": {
      "name": 39,
      "learningrate": "0.006317570362470418",
      "dropout": "0.47810940636473814",
      "epoch": "51.827113446947706",
      "batchsize": "41.400348560851",
      "optimizer": "0.011240959615218649",
      "acc": "0.8296667",
      "loss": "0.5663232056697209"
    },
    "40": {
      "name": 40,
      "learningrate": "0.0020738194048887494",
      "dropout": "0.2831855999376324",
      "epoch": "84.10059732378241",
      "batchsize": "58.13605556853348",
      "optimizer": "1.3629454646890182",
      "acc": "0.8255741",
      "loss": "0.5197561733457777"
    },
    "41": {
      "name": 41,
      "learningrate": "0.008808618130981223",
      "dropout": "0.3350274714970748",
      "epoch": "78.14528245440792",
      "batchsize": "50.0398789243549",
      "optimizer": "0.3351596368768589",
      "acc": "0.8254815",
      "loss": "0.7237299146740525"
    },
    "42": {
      "name": 42,
      "learningrate": "0.0023939408572953885",
      "dropout": "0.4405627460517574",
      "epoch": "54.625345345703565",
      "batchsize": "36.385249649760524",
      "optimizer": "0.6628532768077987",
      "acc": "0.8254074",
      "loss": "0.5179867134270845"
    },
    "43": {
      "name": 43,
      "learningrate": "0.004260856155823743",
      "dropout": "0.4950329500353933",
      "epoch": "57.82375684325836",
      "batchsize": "41.532940787020614",
      "optimizer": "2.916084932758037",
      "acc": "0.82170373",
      "loss": "0.5186006018232416"
    },
    "44": {
      "name": 44,
      "learningrate": "0.009346096945525323",
      "dropout": "0.47674981149208023",
      "epoch": "71.73640876491751",
      "batchsize": "35.80419446155592",
      "optimizer": "2.29272946670587",
      "acc": "0.8199259",
      "loss": "1.6649142258388026"
    },
    "45": {
      "name": 45,
      "learningrate": "0.002442970071855516",
      "dropout": "0.4840197666883208",
      "epoch": "57.792802854019804",
      "batchsize": "56.573716254047625",
      "optimizer": "1.0685087366972013",
      "acc": "0.81803703",
      "loss": "0.543389804981373"
    },
    "46": {
      "name": 46,
      "learningrate": "0.0012188758461503693",
      "dropout": "0.14231939535921234",
      "epoch": "77.65986193587808",
      "batchsize": "36.854380516894906",
      "optimizer": "1.373402125323282",
      "acc": "0.81546295",
      "loss": "0.5462560454916071"
    },
    "47": {
      "name": 47,
      "learningrate": "0.002563438730666812",
      "dropout": "0.0945372958987579",
      "epoch": "55.21722007178569",
      "batchsize": "62.25162973798639",
      "optimizer": "2.823728867757497",
      "acc": "0.80127776",
      "loss": "0.5976670575406816"
    },
    "48": {
      "name": 48,
      "learningrate": "0.001840641500531845",
      "dropout": "0.17254093794224665",
      "epoch": "57.29729199596079",
      "batchsize": "51.967159933640986",
      "optimizer": "2.777179312174562",
      "acc": "0.7917778",
      "loss": "0.6250366442291825"
    },
    "49": {
      "name": 49,
      "learningrate": "0.0009911732795707495",
      "dropout": "0.28065671626633126",
      "epoch": "57.2921759526733",
      "batchsize": "63.090356544086944",
      "optimizer": "0.623191547583007",
      "acc": "0.7893889",
      "loss": "0.6418665954978378"
    }
  },
  "1": {
    "0": {
      "name": 0,
      "learningrate": "0.0009096273951845504",
      "dropout": "0.17303",
      "epoch": "55.19196",
      "batchsize": "47.87344",
      "optimizer": "1.838443447130005",
      "acc": "0.8632407",
      "loss": "0.5766397627636238"
    },
    "1": {
      "name": 1,
      "learningrate": "0.0014",
      "dropout": "0.26373",
      "epoch": "96.60563",
      "batchsize": "53.30576",
      "optimizer": "0.34803538011195045",
      "acc": "0.86094445",
      "loss": "0.6532952744574458"
    },
    "2": {
      "name": 2,
      "learningrate": "0.0008382523083661968",
      "dropout": "0.12836",
      "epoch": "99.40469",
      "batchsize": "58.14771",
      "optimizer": "0.3387583723323314",
      "acc": "0.8609259",
      "loss": "0.6251172200419285"
    },
    "3": {
      "name": 3,
      "learningrate": "0.0012564756456310438",
      "dropout": "0.12585",
      "epoch": "99.41166",
      "batchsize": "62.86194",
      "optimizer": "0.06663804344486501",
      "acc": "0.8602222",
      "loss": "0.7446667894583058"
    },
    "4": {
      "name": 4,
      "learningrate": "0.0022139519802706347",
      "dropout": "0.21602953736066427",
      "epoch": "62.14656346822772",
      "batchsize": "44.00841172166101",
      "optimizer": "0.3372878726115903",
      "acc": "0.86005557",
      "loss": "0.6180005007419321"
    },
    "5": {
      "name": 5,
      "learningrate": "0.00302",
      "dropout": "0.10554",
      "epoch": "61.94856",
      "batchsize": "63.43301",
      "optimizer": "2.2366254199894726",
      "acc": "0.8598889",
      "loss": "0.9041055682789948"
    },
    "6": {
      "name": 6,
      "learningrate": "0.001669993050606651",
      "dropout": "0.46098",
      "epoch": "70.49793",
      "batchsize": "47.08239",
      "optimizer": "1.7141231938756532",
      "acc": "0.8589444",
      "loss": "0.7182451294616417"
    },
    "7": {
      "name": 7,
      "learningrate": "0.0014542959421646436",
      "dropout": "0.10034",
      "epoch": "59.05043",
      "batchsize": "56.79208",
      "optimizer": "1.738556546590159",
      "acc": "0.8562593",
      "loss": "0.7451012644149639"
    },
    "8": {
      "name": 8,
      "learningrate": "0.001516249243696522",
      "dropout": "0.14943",
      "epoch": "77.67042",
      "batchsize": "36.89497",
      "optimizer": "1.678585019425471",
      "acc": "0.8562037",
      "loss": "1.0163094558815162"
    },
    "9": {
      "name": 9,
      "learningrate": "0.0024760284809103535",
      "dropout": "0.13189",
      "epoch": "99.40129",
      "batchsize": "52.07566",
      "optimizer": "0.39747076672864223",
      "acc": "0.85555553",
      "loss": "0.8395796424867931"
    },
    "10": {
      "name": 10,
      "learningrate": "0.00598",
      "dropout": "0.39381",
      "epoch": "96.48543",
      "batchsize": "32.88271",
      "optimizer": "1.4587800332489027",
      "acc": "0.8554074",
      "loss": "0.4136266889086476"
    },
    "11": {
      "name": 11,
      "learningrate": "0.0035056930005265994",
      "dropout": "0.26678",
      "epoch": "96.61413",
      "batchsize": "53.28849",
      "optimizer": "2.335650142240847",
      "acc": "0.8552222",
      "loss": "1.1509039568183599"
    },
    "12": {
      "name": 12,
      "learningrate": "0.0017055246624981656",
      "dropout": "0.1367",
      "epoch": "77.67978",
      "batchsize": "36.85214",
      "optimizer": "0.08539946099497964",
      "acc": "0.8543519",
      "loss": "0.768335667912055"
    },
    "13": {
      "name": 13,
      "learningrate": "0.0024395698121187108",
      "dropout": "0.06756",
      "epoch": "61.92739",
      "batchsize": "63.44207",
      "optimizer": "0.28621525650354196",
      "acc": "0.8543519",
      "loss": "0.7071616299113742"
    },
    "14": {
      "name": 14,
      "learningrate": "0.00625",
      "dropout": "0.09441",
      "epoch": "80.22664",
      "batchsize": "52.07693",
      "optimizer": "2.411137280856396",
      "acc": "0.85407406",
      "loss": "1.4470688223911932"
    },
    "15": {
      "name": 15,
      "learningrate": "0.00413333685217049",
      "dropout": "0.26714",
      "epoch": "96.59416",
      "batchsize": "53.3011",
      "optimizer": "0.3152876760123795",
      "acc": "0.8532407",
      "loss": "0.7529174558100877"
    },
    "16": {
      "name": 16,
      "learningrate": "0.00766",
      "dropout": "0.21228",
      "epoch": "68.96016",
      "batchsize": "39.29926",
      "optimizer": "0.9355955726624057",
      "acc": "0.85283333",
      "loss": "0.42151311733104563"
    },
    "17": {
      "name": 17,
      "learningrate": "0.005060634285717864",
      "dropout": "0.08398",
      "epoch": "99.83139",
      "batchsize": "34.9887",
      "optimizer": "2.0201206290374154",
      "acc": "0.85246295",
      "loss": "1.84499899595355"
    },
    "18": {
      "name": 18,
      "learningrate": "0.0051183808844047565",
      "dropout": "0.12817",
      "epoch": "99.39562",
      "batchsize": "58.13381",
      "optimizer": "2.481892021315753",
      "acc": "0.85172224",
      "loss": "1.6036678173682757"
    },
    "19": {
      "name": 19,
      "learningrate": "0.0056",
      "dropout": "0.21211",
      "epoch": "68.97389",
      "batchsize": "39.29997",
      "optimizer": "1.302572547278798",
      "acc": "0.8501667",
      "loss": "0.43227831605187167"
    },
    "20": {
      "name": 20,
      "learningrate": "0.0065236681934803566",
      "dropout": "0.29434",
      "epoch": "84.09323",
      "batchsize": "62.87761",
      "optimizer": "0.9065738254457933",
      "acc": "0.84996295",
      "loss": "0.42992275560343707"
    },
    "21": {
      "name": 21,
      "learningrate": "0.0054979619542860955",
      "dropout": "0.10815",
      "epoch": "81.31895",
      "batchsize": "51.13781",
      "optimizer": "0.8271704517659799",
      "acc": "0.84966666",
      "loss": "0.4335495892365773"
    },
    "22": {
      "name": 22,
      "learningrate": "0.00515",
      "dropout": "0.07256",
      "epoch": "70.05902",
      "batchsize": "38.98097",
      "optimizer": "2.141476859700183",
      "acc": "0.849463",
      "loss": "1.5412422368921064"
    },
    "23": {
      "name": 23,
      "learningrate": "0.008156866865597289",
      "dropout": "0.08814",
      "epoch": "51.95362",
      "batchsize": "49.03662",
      "optimizer": "0.7296471850302796",
      "acc": "0.84903705",
      "loss": "0.43479879775753727"
    },
    "24": {
      "name": 24,
      "learningrate": "0.005591861200904111",
      "dropout": "0.11027",
      "epoch": "81.31772",
      "batchsize": "51.15159",
      "optimizer": "0.7678465917140682",
      "acc": "0.84903705",
      "loss": "0.4395467402581815"
    },
    "25": {
      "name": 25,
      "learningrate": "0.004648603018318579",
      "dropout": "0.20928",
      "epoch": "71.68629",
      "batchsize": "37.84536",
      "optimizer": "0.8546559489489859",
      "acc": "0.8478889",
      "loss": "0.4385786642321834"
    },
    "26": {
      "name": 26,
      "learningrate": "0.006177698820156487",
      "dropout": "0.22381",
      "epoch": "73.80692",
      "batchsize": "38.50569",
      "optimizer": "1.766575754669268",
      "acc": "0.84746295",
      "loss": "1.2684607534364418"
    },
    "27": {
      "name": 27,
      "learningrate": "0.008330389071561525",
      "dropout": "0.27745",
      "epoch": "84.10132",
      "batchsize": "62.87232",
      "optimizer": "0.36683495999394333",
      "acc": "0.84727776",
      "loss": "0.7180794466193076"
    },
    "28": {
      "name": 28,
      "learningrate": "0.00872301713236897",
      "dropout": "0.14615",
      "epoch": "77.67615",
      "batchsize": "36.86576",
      "optimizer": "0.10395290420172631",
      "acc": "0.8458889",
      "loss": "0.7937310988792666"
    },
    "29": {
      "name": 29,
      "learningrate": "0.006147706011276493",
      "dropout": "0.10311",
      "epoch": "59.05209",
      "batchsize": "56.7695",
      "optimizer": "1.4591534540370867",
      "acc": "0.8458889",
      "loss": "0.44982471560548853"
    },
    "30": {
      "name": 30,
      "learningrate": "0.00726",
      "dropout": "0.39204",
      "epoch": "91.85523",
      "batchsize": "50.7854",
      "optimizer": "2.36291",
      "acc": "0.84374076",
      "loss": "1.2611781398642947"
    },
    "31": {
      "name": 31,
      "learningrate": "0.0044",
      "dropout": "0.23791",
      "epoch": "81.73281",
      "batchsize": "56.23",
      "optimizer": "1.1770674406516553",
      "acc": "0.8436852",
      "loss": "0.4531606775080716"
    },
    "32": {
      "name": 32,
      "learningrate": "0.004174339600585162",
      "dropout": "0.10034",
      "epoch": "80.24348",
      "batchsize": "52.06647",
      "optimizer": "1.1286819842994935",
      "acc": "0.8436852",
      "loss": "0.45327512245266527"
    },
    "33": {
      "name": 33,
      "learningrate": "0.00989657640327044",
      "dropout": "0.08418",
      "epoch": "99.4113",
      "batchsize": "52.0809",
      "optimizer": "0.06121308896035982",
      "acc": "0.8426667",
      "loss": "0.8984463956863792"
    },
    "34": {
      "name": 34,
      "learningrate": "0.00912",
      "dropout": "0.08173",
      "epoch": "95.30541",
      "batchsize": "53.25251",
      "optimizer": "1.5215994218534883",
      "acc": "0.84242594",
      "loss": "2.156398782023125"
    },
    "35": {
      "name": 35,
      "learningrate": "0.0033025385532588054",
      "dropout": "0.14029",
      "epoch": "77.65097",
      "batchsize": "36.90452",
      "optimizer": "2.176392742954809",
      "acc": "0.8415",
      "loss": "1.5112155936318967"
    },
    "36": {
      "name": 36,
      "learningrate": "0.006478553639909028",
      "dropout": "0.08644",
      "epoch": "81.29786",
      "batchsize": "51.14495",
      "optimizer": "2.6846095272191794",
      "acc": "0.84135187",
      "loss": "0.46267675492940125"
    },
    "37": {
      "name": 37,
      "learningrate": "0.00759",
      "dropout": "0.24749",
      "epoch": "81.73411",
      "batchsize": "56.22446",
      "optimizer": "2.6289592451622985",
      "acc": "0.8399815",
      "loss": "0.46102079337173035"
    },
    "38": {
      "name": 38,
      "learningrate": "0.008013659060969748",
      "dropout": "0.17577",
      "epoch": "55.1994",
      "batchsize": "47.86818",
      "optimizer": "1.993734024717084",
      "acc": "0.83887035",
      "loss": "1.1908521984396157"
    },
    "39": {
      "name": 39,
      "learningrate": "0.008484248990323583",
      "dropout": "0.09447",
      "epoch": "59.05065",
      "batchsize": "56.79631",
      "optimizer": "2.770426476055823",
      "acc": "0.8368704",
      "loss": "0.47178590541415744"
    },
    "40": {
      "name": 40,
      "learningrate": "0.00726",
      "dropout": "0.39204",
      "epoch": "91.85523",
      "batchsize": "50.7854",
      "optimizer": "2.448781735471941",
      "acc": "0.8336296",
      "loss": "1.3567619242226636"
    },
    "41": {
      "name": 41,
      "learningrate": "0.00813",
      "dropout": "0.23495",
      "epoch": "53.63542",
      "batchsize": "60.72378",
      "optimizer": "2.5505731893757617",
      "acc": "0.833037",
      "loss": "0.4891514667758235"
    },
    "42": {
      "name": 42,
      "learningrate": "0.005747712502696376",
      "dropout": "0.27854",
      "epoch": "84.09539",
      "batchsize": "62.87491",
      "optimizer": "2.8461657623691785",
      "acc": "0.83155555",
      "loss": "0.49133176435364617"
    },
    "43": {
      "name": 43,
      "learningrate": "0.003217215778172137",
      "dropout": "0.07746",
      "epoch": "61.92437",
      "batchsize": "63.43089",
      "optimizer": "0.5446065970506361",
      "acc": "0.83122224",
      "loss": "0.4968664972384771"
    },
    "44": {
      "name": 44,
      "learningrate": "0.0026029468726242503",
      "dropout": "0.10336",
      "epoch": "59.04671",
      "batchsize": "56.7829",
      "optimizer": "0.7779673518633751",
      "acc": "0.82827777",
      "loss": "0.5055273856940092"
    },
    "45": {
      "name": 45,
      "learningrate": "0.0028794457241423403",
      "dropout": "0.40316",
      "epoch": "51.96888",
      "batchsize": "49.03607",
      "optimizer": "0.8959974455815332",
      "acc": "0.82562965",
      "loss": "0.5141983971684068"
    },
    "46": {
      "name": 46,
      "learningrate": "0.0017000518178140037",
      "dropout": "0.28201",
      "epoch": "84.0922",
      "batchsize": "62.87197",
      "optimizer": "1.0616455881084002",
      "acc": "0.8211111",
      "loss": "0.5336953621175554"
    },
    "47": {
      "name": 47,
      "learningrate": "0.00095",
      "dropout": "0.465",
      "epoch": "51.9744",
      "batchsize": "49.01716",
      "optimizer": "2.629723719778233",
      "acc": "0.74662966",
      "loss": "0.7616044242293747"
    }
  }
}